<?xml version="1.0" encoding="UTF-8" ?>

<pretext xmlns:xi="http://www.w3.org/2001/XInclude" xml:lang="en-US">

  <docinfo>
    <macros>
    </macros>
  </docinfo>

  <book xml:id="intro-data-science">
    <title>Introduction to Data Science</title>

    <!-- Preface -->
    <preface xml:id="preface">
      <title>Preface</title>
      
      <p>
        This is the website for the <em>Data Wrangling and Visualization with R</em> part of <em>Introduction to Data Science</em>.
      </p>
      
      <p>
        The website for the <em>Statistics and Prediction Algorithms Through Case Studies</em> part is <url href="http://rafalab.dfci.harvard.edu/dsbook-part-2/">here</url>.
      </p>
      
      <p>
        We make announcements related to the book on Twitter. For updates follow <url href="https://twitter.com/rafalab">@rafalab</url>.
      </p>
      
      <p>
        This book started out as the class notes used in the HarvardX <url href="https://www.edx.org/professional-certificate/harvardx-data-science">Data Science Series</url>.
      </p>
      
      <p>
        The Quarto files used to generate the book are available on <url href="https://github.com/rafalab/dsbook-part-1">GitHub</url>. Note that, the graphical theme used for plots throughout the book can be recreated using the <c>ds_theme_set()</c> function from the <c>dslabs</c> package.
      </p>
      
      <p>
        This work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International <url href="https://creativecommons.org/licenses/by-nc-sa/4.0">CC BY-NC-SA 4.0</url>.
      </p>
      
      <p>
        A hardcopy version of the book is available from <url href="https://www.routledge.com/Introduction-to-Data-Science-Data-Wrangling-and-Visualization-with-R/Irizarry/p/book/9781032116556">CRC Press</url>.
      </p>
      
      <p>
        A free PDF of the October 24, 2019 version of the book is available from <url href="https://leanpub.com/datasciencebook">Leanpub</url>.
      </p>
      
    </preface>
    
    <!-- Acknowledgments -->
    <acknowledgement xml:id="acknowledgments">
      <title>Acknowledgments</title>
      
      <p>
        This book is dedicated to all the people involved in building and maintaining R and the R packages we use in this book. A special thanks to the developers and maintainers of base R, the tidyverse, data.table, and the caret package.
      </p>
      
      <p>
        A special thanks to Jenna Landy for her careful editing and helpful advice on this book; to David Robinson for generously answering many questions about the tidyverse and aiding in my understanding of it; and to Amy Gill for dozens of comments, edits, and suggestions. Also, many thanks to Stephanie Hicks who twice served as a co-instructor in my data science classes and Yihui Xie who patiently put up with my many questions related to markdown. Thanks also to Karl Broman, from whom I borrowed ideas for the Data Visualization and Productivity Tools parts. Thanks to Peter Aldhous from whom I borrowed ideas for the principles of data visualization section and Jenny Bryan for writing <em>Happy Git and GitHub for the useR</em>, which influenced our Git chapters. Also, many thanks to Jeff Leek, Roger Peng, and Brian Caffo, whose online classes inspired the way this book is divided, to Garrett Grolemund and Hadley Wickham for making the markdown code for their R for Data Science book open, and the editors, John Kimmel and Lara Spieker, for their support. Finally, thanks to Alex Nones for proofreading the manuscript during its various stages.
      </p>
      
      <p>
        This book was conceived during the teaching of several applied statistics courses, starting over fifteen years ago. The teaching assistants working with me throughout the years made important indirect contributions to this book. The material was further refined during a HarvardX series coordinated by Heather Sternshein and Zofia Gajdos. We thank them for their contributions. We are also grateful to all the students whose questions and comments helped us improve the book. The courses were partially funded by NIH grant R25GM114818. We are very grateful to the National Institutes of Health for its support.
      </p>
      
      <p>
        A special thanks goes to all those who edited the book via GitHub pull requests or made suggestions by creating an <em>issue</em> or sending an email: <c>nickyfoto</c> (Huang Qiang), <c>desautm</c> (Marc-André Désautels), <c>michaschwab</c> (Michail Schwab), <c>alvarolarreategui</c> (Alvaro Larreategui), <c>jakevc</c> (Jake VanCampen), <c>omerta</c> (Guillermo Lengemann), <c>espinielli</c> (Enrico Spinielli), <c>asimumba</c> (Aaron Simumba), <c>braunschweig</c> (Maldewar), <c>gwierzchowski</c> (Grzegorz Wierzchowski), <c>technocrat</c> (Richard Careaga), <c>atzakas</c>, <c>defeit</c> (David Emerson Feit), <c>shiraamitchell</c> (Shira Mitchell), <c>Nathalie-S</c>, <c>andreashandel</c> (Andreas Handel), <c>berkowitze</c> (Elias Berkowitz), <c>Dean-Webb</c> (Dean Webber), <c>mohayusuf</c>, <c>jimrothstein</c>, <c>mPloenzke</c> (Matthew Ploenzke), <c>NicholasDowand</c> (Nicholas Dow), <c>kant</c> (Darío Hereñú), <c>debbieyuster</c> (Debbie Yuster), <c>tuanchauict</c> (Tuan Chau), <c>phzeller</c>, <c>BTJ01</c> (BradJ), <c>glsnow</c> (Greg Snow), <c>mberlanda</c> (Mauro Berlanda), <c>wfan9</c>, <c>larswestvang</c> (Lars Westvang), <c>jj999</c> (Jan Andrejkovic), <c>Kriegslustig</c> (Luca Nils Schmid), <c>odahhani</c>, <c>aidanhorn</c> (Aidan Horn), <c>atraxler</c> (Adrienne Traxler), <c>alvegorova</c>, <c>wycheong</c> (Won Young Cheong), <c>med-hat</c> (Medhat Khalil), <c>kengustafson</c>, <c>Yowza63</c>, <c>ryan-heslin</c> (Ryan Heslin), <c>raffaem</c>, <c>tim8west</c>, <c>jooleer</c>, <c>pauluhn</c> (Paul), <c>tci1</c>, <c>beanb2</c> (Brennan Bean), <c>edasdemirlab</c> (Erdi Dasdemir), <c>jimnicholls</c> (Jim Nicholls), <c>JimKay1941</c> (Jim Kay), <c>devpowerplatform</c> (QuantScripter), <c>carvalhais</c> (André Carvalhais), <c>hbmaclean</c>, <c>GENHEN</c>, <c>whatchalookingat</c>, David D. Kane, El Mustapha El Abbassi, Vadim Zipunnikov, Anna Quaglieri, Chris Dong, Bowen Gu, Rick Schoenberg, and Robert Gentleman.
      </p>
      
    </acknowledgement>

    <!-- Introduction -->
    <chapter xml:id="introduction">
      <title>Introduction</title>
      
      <p>
        The demand for skilled data science practitioners in industry, academia, and government is rapidly growing. This book introduces skills that can help you tackle real-world data analysis challenges. These include R programming, data wrangling with <term>dplyr</term>, data visualization with <term>ggplot2</term>, file organization with UNIX/Linux shell, version control with Git and GitHub, and reproducible document preparation with Quarto and <term>knitr</term>. The book is divided into four parts: <term>R</term>, <term>Data Visualization</term>, <term>Data Wrangling</term>, and <term>Productivity Tools</term>. Each part has several chapters meant to be presented as one lecture and includes dozens of exercises distributed across chapters.
      </p>
      
      <section xml:id="case-studies">
        <title>Case studies</title>
        
        <p>
          Throughout the book, we use motivating case studies. In each case study, we try to realistically mimic a data scientist's experience. For each of the skills covered, we start by asking specific questions and answer these through data analysis. We learn the concepts as a means to answer the questions. Examples of the case studies included in the book are:
        </p>
        
        <table xml:id="table-case-studies">
          <title>Case Studies in the Book</title>
          <tabular>
            <row header="yes">
              <cell>Case Study</cell>
              <cell>Concept</cell>
            </row>
            <row>
              <cell>US murder rates by state</cell>
              <cell>R Basics</cell>
            </row>
            <row>
              <cell>Student heights</cell>
              <cell>Statistical Summaries</cell>
            </row>
            <row>
              <cell>Trends in world health and economics</cell>
              <cell>Data Visualization</cell>
            </row>
            <row>
              <cell>The impact of vaccines on infectious disease rates</cell>
              <cell>Data Visualization</cell>
            </row>
            <row>
              <cell>Reported student heights</cell>
              <cell>Data Wrangling</cell>
            </row>
          </tabular>
        </table>
        
      </section>
      
      <section xml:id="who-will-find-useful">
        <title>Who will find this book useful?</title>
        
        <p>
          This book is meant to be a textbook for a first course in Data Science. No previous knowledge of R is necessary, although some experience with programming may be helpful. To be a successful data analyst implementing these skill requires understanding advanced statistical concepts, such as those covered in <url href="http://rafalab.dfci.harvard.edu/dsbook-part-2/">Advanced Data Science</url>. If you read and understand all the chapters and complete all the exercises in this book, and understand statistical concepts, you will be well-positioned to perform basic data analysis tasks and you will be prepared to learn the more advanced concepts and skills needed to become an expert.
        </p>
        
      </section>
      
      <section xml:id="what-does-cover">
        <title>What does this book cover?</title>
        
        <p>
          We start by going over the <term>basics of R</term>, the <term>tidyverse</term>, and the <term>data.table</term> package. You learn R throughout the book, but in the first part we go over the building blocks needed to keep learning.
        </p>
        
        <p>
          The growing availability of informative datasets and software tools has led to increased reliance on <term>data visualizations</term> in many fields. In the second part we demonstrate how to use <term>ggplot2</term> to generate graphs and describe important data visualization principles.
        </p>
        
        <p>
          The third part uses several examples to familiarize the reader with <term>data wrangling</term>. Among the specific skills we learn are web scraping, using regular expressions, and joining and reshaping data tables. We do this using <term>tidyverse</term> tools.
        </p>
        
        <p>
          In the final part, we provide a brief introduction to the <term>productivity tools</term> we use on a day-to-day basis in data science projects. These are RStudio, UNIX/Linux shell, Git and GitHub, Quarto, and <term>knitr</term>.
        </p>
        
      </section>
      
      <section xml:id="what-not-covered">
        <title>What is not covered by this book?</title>
        
        <p>
          This book focuses on the computing skills necessary for the data analysis aspects of data science. As mentioned, we do not cover statistical concepts. We also do not cover aspects related to data management or engineering. Although R programming is an essential part of the book, we do not teach more advanced computer science topics such as data structures, optimization, and algorithm theory. Similarly, we do not cover topics such as web services, interactive graphics, parallel computing, and data streaming processing.
        </p>
        
      </section>
      
    </chapter>

    <!-- Part 1: R -->
    <part xml:id="part-r">
      <title>R</title>

      <chapter xml:id="ch-getting-started">
        <title>Getting started</title>
        
        <section xml:id="sec-why-r">
          <title>Why R?</title>
          
          <p>
            R is not a programming language like C or Java. It was not created by software engineers for software development. Instead, it was developed by statisticians as an interactive environment for data analysis. You can read the full history in the paper <url href="https://pdfs.semanticscholar.org/9b48/46f192aa37ca122cfabb1ed1b59866d8bfda.pdf">A Brief History of S</url>. The interactivity is an indispensable feature in data science because, as you will soon learn, the ability to quickly explore data is a necessity for success in this field. However, like in other programming languages, you can save your work as scripts that can be easily executed at any moment. These scripts serve as a record of the analysis you performed, a key feature that facilitates reproducible work. If you are an expert programmer, you should not expect R to follow the conventions you are used to since you will be disappointed. If you are patient, you will come to appreciate the unequal power of R when it comes to data analysis and, specifically, data visualization.
          </p>
          
          <p>
            Other attractive features of R are:
          </p>
          
          <ol>
            <li>R is free and <url href="https://opensource.org/history">open source</url>.</li>
            <li>It runs on all major platforms: Windows, Mac Os, UNIX/Linux.</li>
            <li>Scripts and data objects can be shared seamlessly across platforms.</li>
            <li>There is a large, growing, and active community of R users and, as a result, there are numerous <url href="https://stats.stackexchange.com/questions/138/free-resources-for-learning-r">resources for learning</url> and <url href="https://www.r-project.org/help.html">asking questions</url>.</li>
            <li>It is easy for others to contribute add-ons which enables developers to share software implementations of new data science methodologies. This gives R users early access to the latest methods and to tools which are developed for a wide variety of disciplines, including ecology, molecular biology, social sciences, and geography, just to name a few examples.</li>
          </ol>
          
        </section>
        
        <section xml:id="sec-r-console">
          <title>The R console</title>
          
          <p>
            Interactive data analysis usually occurs on the <em>R console</em> that executes commands as you type them. There are several ways to gain access to an R console. One way is to simply start R on your computer. The console looks something like this:
          </p>
          
          <figure xml:id="fig-r-console">
            <caption>The R console</caption>
            <image source="R/img/R_console.png" width="70%"/>
          </figure>
          
          <p>
            As a quick example, try using the console to calculate a 15% tip on a meal that cost $19.71:
          </p>
          
          <program language="r">
            <input>
0.15 * 19.71
            </input>
          </program>
          
          <p>
            <alert>Note that in this book, grey boxes are used to show R code typed into the R console. The symbol <c>#&gt;</c> is used to denote what the R console outputs.</alert>
          </p>
          
        </section>
        
        <section xml:id="sec-scripts">
          <title>Scripts</title>
          
          <p>
            One of the great advantages of R over point-and-click analysis software is that you can save your work as scripts. You can edit and save these scripts using a text editor. The material in this book was developed using the interactive <em>integrated development environment</em> (IDE) <url href="https://posit.co/">RStudio</url>. RStudio includes an editor with many R specific features, a console to execute your code, and other useful panes, including one to show figures.
          </p>
          
          <figure xml:id="fig-rstudio">
            <caption>RStudio interface</caption>
            <image source="R/img/rstudio.png" width="70%"/>
          </figure>
          
          <p>
            Most web-based R consoles also provide a pane to edit scripts, but not all permit you to save the scripts for later use.
          </p>
          
          <p>
            All the R scripts used to generate this book can be found on <url href="https://github.com/rafalab/dsbook-part-1">GitHub</url>.
          </p>
          
        </section>
        
        <section xml:id="sec-rstudio">
          <title>RStudio</title>
          
          <p>
            RStudio will be our launching pad for data science projects. It not only provides an editor for us to create and edit our scripts but also provides many other useful tools. In this section, we go over some of the basics.
          </p>
          
          <subsection xml:id="subsec-panes">
            <title>The panes</title>
            
            <p>
              When you start RStudio for the first time, you will see three panes. The left pane shows the R console. On the right, the top pane includes tabs such as <em>Environment</em> and <em>History</em>, while the bottom pane shows five tabs: <em>File</em>, <em>Plots</em>, <em>Packages</em>, <em>Help</em>, and <em>Viewer</em> (these tabs may change in new versions). You can click on each tab to move across the different features. For example, to start a new script, you can click on File, then New File, then R Script.
            </p>
            
            <figure xml:id="fig-rstudio-panes">
              <caption>RStudio panes</caption>
              <image source="productivity/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_22_03_2018_16_21_42.png" width="70%"/>
            </figure>
            
            <p>
              This starts a new pane on the left and it is here where you can start writing your script.
            </p>
            
            <figure xml:id="fig-rstudio-script">
              <caption>RStudio with script pane</caption>
              <image source="productivity/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_22_03_2018_16_21_49.png" width="70%"/>
            </figure>
            
          </subsection>
          
          <subsection xml:id="subsec-key-bindings">
            <title>Key bindings</title>
            
            <p>
              Many tasks we perform with the mouse can be achieved with a combination of key strokes instead. These keyboard versions for performing tasks are referred to as <em>key bindings</em>. For example, we just showed how to use the mouse to start a new script, but you can also use a key binding: Ctrl+Shift+N on Windows and command+shift+N on the Mac.
            </p>
            
            <p>
              Although in this tutorial we often show how to use the mouse, <alert>we highly recommend that you memorize key bindings for the operations you use most</alert>. RStudio provides a useful cheat sheet with the most widely used commands. You can get it from RStudio directly:
            </p>
            
            <figure xml:id="fig-rstudio-cheatsheet">
              <caption>RStudio keyboard shortcuts cheat sheet</caption>
              <image source="productivity/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_22_03_2018_16_22_20.png" width="70%"/>
            </figure>
            
            <p>
              You might want to keep this handy so you can look up key-bindings when you find yourself performing repetitive point-and-clicking.
            </p>
            
          </subsection>
          
          <subsection xml:id="subsec-running-commands">
            <title>Running commands while editing scripts</title>
            
            <p>
              There are many editors specifically made for coding. These are useful because color and indentation are automatically added to make code more readable. RStudio is one of these editors, and it was specifically developed for R. One of the main advantages provided by RStudio over other editors is that we can test our code easily as we edit our scripts. Below we show an example.
            </p>
            
            <p>
              Let's start by opening a new script as we did before. A next step is to give the script a name. We can do this through the editor by saving the current new unnamed script. To do this, click on the save icon or use the key binding Ctrl+S on Windows and command+S on the Mac.
            </p>
            
            <p>
              When you ask for the document to be saved for the first time, RStudio will prompt you for a name. A good convention is to use a descriptive name, with lower case letters, no spaces, only hyphens to separate words, and then followed by the suffix <c>.R</c>. We will call this script <c>my-first-script.R</c>.
            </p>
            
            <figure xml:id="fig-rstudio-save">
              <caption>Saving a script in RStudio</caption>
              <image source="productivity/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_22_03_2018_16_27_44.png" width="70%"/>
            </figure>
            
            <p>
              Now we are ready to start editing our first script. The first lines of code in an R script are dedicated to loading the libraries we will use. Another useful RStudio feature is that once we type <c>library()</c> it starts auto-completing with libraries that we have installed. Note what happens when we type <c>library(ti)</c>:
            </p>
            
            <figure xml:id="fig-rstudio-autocomplete">
              <caption>RStudio auto-completion</caption>
              <image source="productivity/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_22_03_2018_16_29_47.png" width="70%"/>
            </figure>
            
            <p>
              Another feature you may have noticed is that when you type <c>library(</c> the second parenthesis is automatically added. This will help you avoid one of the most common errors in coding: forgetting to close a parenthesis.
            </p>
            
            <p>
              Now we can continue to write code. As an example, we will make a graph showing murder totals versus population totals by state. Once you are done writing the code needed to make this plot, you can try it out by <em>executing</em> the code. To do this, click on the <em>Run</em> button on the upper right side of the editing pane. You can also use the key binding: Ctrl+Shift+Enter on Windows or command+shift+return on the Mac.
            </p>
            
            <p>
              Once you run the code, you will see it appear in the R console and, in this case, the generated plot appears in the plots console. Note that the plot console has a useful interface that permits you to click back and forward across different plots, zoom in to the plot, or save the plots as files.
            </p>
            
            <figure xml:id="fig-rstudio-run">
              <caption>Running code in RStudio</caption>
              <image source="productivity/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_22_03_2018_16_45_18.png" width="70%"/>
            </figure>
            
            <p>
              To run one line at a time instead of the entire script, you can use Control-Enter on Windows and command-return on the Mac.
            </p>
            
          </subsection>
          
          <subsection xml:id="subsec-global-options">
            <title>Changing global options</title>
            
            <p>
              You can change the look and functionality of RStudio quite a bit.
            </p>
            
            <p>
              To change the global options you click on <em>Tools</em> then <em>Global Options...</em>.
            </p>
            
            <p>
              As an example we show how to make a change that we <alert>highly recommend</alert>. This is to change the <em>Save workspace to .RData on exit</em> to <em>Never</em> and uncheck the <em>Restore .RData into workspace at start</em>. By default, when you exit R saves all the objects you have created into a file called .RData. This is done so that when you restart the session in the same folder, it will load these objects. We find that this causes confusion especially when we share code with colleagues and assume they have this .RData file. To change these options, make your <em>General</em> settings look like this:
            </p>
            
            <figure xml:id="fig-rstudio-options">
              <caption>RStudio global options</caption>
              <image source="productivity/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_22_03_2018_16_56_08.png" width="40%"/>
            </figure>
            
          </subsection>
          
        </section>
        
        <section xml:id="sec-installing-r-packages">
          <title>Installing R packages</title>
          
          <p>
            The functionality provided by a fresh install of R is only a small fraction of what is possible. In fact, we refer to what you get after your first install as <em>base R</em>. The extra functionality comes from add-ons available from developers. There are currently hundreds of these available from CRAN and many others shared via other repositories such as GitHub. However, because not everybody needs all available functionality, R instead makes different components available via <em>packages</em>. R makes it very easy to install packages from within R. For example, to install the <alert>dslabs</alert> package, which we use to share datasets and code related to this book, you would type:
          </p>
          
          <program language="r">
            <input>
install.packages("dslabs")
            </input>
          </program>
          
          <p>
            In RStudio, you can navigate to the <em>Tools</em> tab and select install packages. We can then load the package into our R sessions using the <c>library</c> function:
          </p>
          
          <program language="r">
            <input>
library(dslabs)
            </input>
          </program>
          
          <p>
            As you go through this book, you will see that we load packages without installing them. This is because once you install a package, it remains installed and only needs to be loaded with <c>library</c>. The package remains loaded until we quit the R session. If you try to load a package and get an error, it probably means you need to install it first.
          </p>
          
          <p>
            We can install more than one package at once by feeding a character vector to this function:
          </p>
          
          <program language="r">
            <input>
install.packages(c("tidyverse", "dslabs"))
            </input>
          </program>
          
          <p>
            One advantage of using RStudio is that it auto-completes package names once you start typing, which is helpful when you do not remember the exact spelling of the package.
          </p>
          
          <p>
            Note that installing <alert>tidyverse</alert> actually installs several packages. This commonly occurs when a package has <em>dependencies</em>, or uses functions from other packages. When you load a package using <c>library</c>, you also load its dependencies.
          </p>
          
          <p>
            Once packages are installed, you can load them into R and you do not need to install them again, unless you install a fresh version of R. Remember packages are installed in R not RStudio.
          </p>
          
          <p>
            It is helpful to keep a list of all the packages you need for your work in a script because if you need to perform a fresh install of R, you can re-install all your packages by simply running a script.
          </p>
          
          <p>
            You can see all the packages you have installed using the following function:
          </p>
          
          <program language="r">
            <input>
installed.packages()
            </input>
          </program>
          
        </section>
        
      </chapter>

      <chapter xml:id="ch-r-basics"><title>R basics</title>
      
      <section xml:id="motivating-example-us-gun-murders"><title>Motivating example: US Gun Murders</title>
      
      <p>Imagine you live in Europe and are offered a job in a US company with many locations across all states. It is a great job, but news with headlines such as <alert>US Gun Homicide Rate Higher Than Other Developed Countries</alert><fn><url href="http://abcnews.go.com/blogs/headlines/2012/12/us-gun-ownership-homicide-rate-higher-than-other-developed-countries/"/></fn> have you worried. Charts like this may concern you even more:</p>
      
      <program language="r"><input>
      ## img_path &lt;- "img"
      ##from http://abcnews.go.com/images/International/homocides_g8_countries_640x360_wmain.jpg
      ##knitr::include_graphics(file.path(img_path,"homocides_g8_countries_640x360_wmain.jpg"))
      library(tidyverse)
      library(ggplot2)
      library(ggflags) # from GitHub repo jimjam-slam/ggflags
      library(countrycode)
      library(dslabs)
      
      dat &lt;- tibble(country = toupper(c("US", "Italy", "Canada", "UK", "Japan", "Germany", "France", "Russia")),
                    count = c(3.2, 0.71, 0.5, 0.1, 0, 0.2, 0.1, 0),
                    label = c(as.character(c(3.2, 0.71, 0.5, 0.1, 0, 0.2, 0.1)), "No Data"),
                   code = c("us", "it", "ca", "gb", "jp", "de", "fr", "ru"))
      
      
      dat |&gt; 
        mutate(country = reorder(country, -count)) |&gt;
        ggplot(aes(country, count, label = label)) +
        geom_bar(stat = "identity", fill = "darkred") +
        geom_text(nudge_y = 0.2, color = "darkred", size = 5) +
        geom_flag(y = -.5, aes(country = code), size = 12) +
        scale_y_continuous(breaks = c(0, 1, 2, 3, 4), limits = c(0,4)) +
        geom_text(aes(6.25, 3.8, label = "Source UNODC Homicide Statistics")) + 
        ggtitle(toupper("Homicide Per 100,000 in G-8 Countries")) + 
        xlab("") + 
        ylab("# of gun-related homicides\nper 100,000 people") +
        ggthemes::theme_economist() +
        theme(axis.text.x = element_text(size = 8, vjust = -12),
              axis.ticks.x = element_blank(),
              axis.line.x = element_blank(),
              plot.margin = unit(c(1,1,1,1), "cm")) 
      </input></program>
      
      <p>Or even worse, this version from <url href="https://everytownresearch.org">everytown.org</url><fn><url href="https://everytownresearch.org"/></fn>:</p>
      
      <program language="r"><input>
      # from https://everytownresearch.org/wp-content/uploads/2016/07/GunTrends_murders_per_1000.png
      # knitr::include_graphics(file.path(img_path,"GunTrends_murders_per_1000.png"))
      
      dat &lt;- tibble(country = toupper(c("United States", "Canada", "Portugal", "Ireland", "Italy", "Belgium", "Finland", "France", "Netherlands", "Denmark", "Sweden", "Slovakia", "Austria", "New Zealand", "Australia", "Spain", "Czech Republic", "Hungary", "Germany", "United Kingdom", "Norway", "Japan", "Republic of Korea")),
                    count = c(3.61, 0.5, 0.48, 0.35, 0.35, 0.33, 0.26, 0.20, 0.20, 0.20, 0.19, 0.19, 0.18, 0.16, 0.16, 0.15, 0.12, 0.10, 0.06, 0.04, 0.04, 0.01, 0.01))
      
      dat |&gt; 
        mutate(country = reorder(country, count)) |&gt;
        ggplot(aes(country, count, label = count)) +   
        geom_bar(stat = "identity", fill = "darkred", width = 0.5) +
        geom_text(nudge_y = 0.2,  size = 3) +
        xlab("") + ylab("") + 
        ggtitle(toupper("Gun Homicides per 100,000 residents")) + 
        theme_minimal() +
        theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
              axis.text.x = element_blank(),
              axis.ticks.length = unit(-0.4, "cm")) + 
        coord_flip() 
      rm(dat)
      </input></program>
      
      <p>But then you remember that the US is a large and diverse country with 50 very different states as well as the District of Columbia (DC).</p>
      
      <program language="r"><input>
      fifty_states &lt;- map_data("state")
      murders |&gt; mutate(murder_rate = total/population*10^5,
                        state = tolower(state), 
                        colors = factor(ceiling(pmin(murder_rate, 9)))) |&gt;
        ggplot(aes(map_id = state)) + 
        geom_map(aes(fill = colors), color = "black", map = fifty_states) + 
        expand_limits(x = fifty_states$long, y = fifty_states$lat) +
        coord_map() +
        scale_x_continuous(breaks = NULL) + 
        scale_y_continuous(breaks = NULL) +
        labs(x = "", y = "") +
        theme(panel.background = element_blank()) + 
        scale_fill_brewer(guide = "none") +
        theme_minimal()
      rm(fifty_states)
      </input></program>
      
      <p>California, for example, has a larger population than Canada, and 20 US states have populations larger than that of Norway. In some respects, the variability across states in the US is akin to the variability across countries in Europe. Furthermore, although not included in the charts above, the murder rates in Lithuania, Ukraine, and Russia are higher than 4 per 100,000. So perhaps the news reports that worried you are too superficial. You have options of where to live and want to determine the safety of each particular state. We will gain some insights by examining data related to gun homicides in the US during 2010 using R.</p>
      
      <p>Before we get started with our example, we need to cover logistics as well as some of the very basic building blocks that are required to gain more advanced R skills. Be aware that the usefulness of some of these building blocks may not be immediately obvious, but later in the book you will appreciate having mastered these skills.</p>
      
      </section>
      
      <section xml:id="the-very-basics"><title>The very basics</title>
      
      <p>Before we get started with the motivating dataset, we need to cover the very basics of R.</p>
      
      <subsection xml:id="objects"><title>Objects</title>
      
      <p>Suppose a high school student asks us for help solving several quadratic equations of the form <m>ax^2+bx+c = 0</m>. The quadratic formula gives us the solutions:</p>
      
      <me>\frac{-b - \sqrt{b^2 - 4ac}}{2a}\,\, \mbox{ and } \frac{-b + \sqrt{b^2 - 4ac}}{2a}</me>
      
      <p>which of course change depending on the values of <m>a</m>, <m>b</m>, and <m>c</m>. One advantage of programming languages is that we can define variables and write expressions with these variables, similar to how we do so in math, but obtain a numeric solution. We will write out general code for the quadratic equation below, but if we are asked to solve <m>x^2 + x -1 = 0</m>, then we define the coefficients:</p>
      
      <program language="r"><input>
      coef_a &lt;- 1
      coef_b &lt;- 1
      coef_c &lt;- -1
      </input></program>
      
      <p>which stores the values for later use. We use <c>&lt;-</c> to assign values to the variables. We can also assign values using <c>=</c> instead of <c>&lt;-</c>, but we recommend against using <c>=</c> to avoid confusion.</p>
      
      <p>Copy and paste the code above into your console to define the three variables. Note that R does not print anything when we make this assignment. This means the objects were defined successfully. Had you made a mistake, you would have received an error message.</p>
      
      <p>To see the value stored in a variable, we simply ask R to evaluate <c>coef_a</c> and it shows the stored value:</p>
      
      <program language="r"><input>
      coef_a
      </input></program>
      
      <p>A more explicit way to ask R to show us the value stored in <c>coef_a</c> is using <c>print</c> like this:</p>
      
      <program language="r"><input>
      print(coef_a)
      </input></program>
      
      <p>We use the term <em>object</em> to describe stuff that is stored in R. Variables are examples, but objects can also be more complicated entities such as functions, which are described later.</p>
      
      </subsection>
      
      <subsection xml:id="the-workspace"><title>The workspace</title>
      
      <p>As we define objects in the console, we are actually changing the <em>workspace</em>. You can see all the variables saved in your workspace by typing:</p>
      
      <program language="r"><input>
      #| eval: false
      ls()
      </input></program>
      
      <p>In RStudio, the <em>Environment</em> tab shows the values:</p>
      
      <figure><image source="R/img/rstudio-environment.png"/></figure>
      
      <p>We should see <c>coef_a</c>, <c>coef_b</c>, and <c>coef_c</c>. If you try to recover the value of a variable that is not in your workspace, you receive an error. For example, if you type <c>x</c> you will receive the following message: <c>Error: object 'x' not found</c>.</p>
      
      <p>Now since these values are saved in variables, to obtain a solution to our equation, we use the quadratic formula:</p>
      
      <program language="r"><input>
      (-coef_b + sqrt(coef_b^2 - 4*coef_a*coef_c))/(2*coef_a)
      (-coef_b - sqrt(coef_b^2 - 4*coef_a*coef_c))/(2*coef_a)
      </input></program>
      
      </subsection>
      
      <subsection xml:id="prebuilt-functions"><title>Prebuilt functions</title>
      
      <p>Once you define variables, the data analysis process can usually be described as a series of <em>functions</em> applied to the data. R includes several predefined functions and most of the analysis pipelines we construct make extensive use of these.</p>
      
      <p>We already used or discussed the <c>install.packages</c>, <c>library</c>, and <c>ls</c> functions. We also used the function <c>sqrt</c> to solve the quadratic equation above. There are many more prebuilt functions and even more can be added through packages. These functions do not appear in the workspace because you did not define them, but they are available for immediate use.</p>
      
      <p>In general, we need to use parentheses to evaluate a function. If you type <c>ls</c>, the function is not evaluated and instead R shows you the code that defines the function. If you type <c>ls()</c> the function is evaluated and, as seen above, we see objects in the workspace.</p>
      
      <p>Unlike <c>ls</c>, most functions require one or more <em>arguments</em>. Below is an example of how we assign an object to the argument of the function <c>log</c>. Remember that we earlier defined <c>coef_a</c> to be 1:</p>
      
      <program language="r"><input>
      log(8)
      log(coef_a) 
      </input></program>
      
      <p>You can find out what the function expects and what it does by reviewing the very useful manuals included in R. You can get help by using the <c>help</c> function like this:</p>
      
      <program language="r"><input>
      help("log")
      </input></program>
      
      <p>For most functions, we can also use this shorthand:</p>
      
      <program language="r"><input>
      ?log
      </input></program>
      
      <p>The help page will show you what arguments the function is expecting. For example, <c>log</c> needs <c>x</c> and <c>base</c> to run. However, some arguments are required and others are optional. You can determine which arguments are optional by noting in the help document that a default value is assigned with <c>=</c>. Defining these is optional. For example, the base of the function <c>log</c> defaults to <c>base = exp(1)</c> making <c>log</c> the natural log by default.</p>
      
      <p>If you want a quick look at the arguments without opening the help system, you can type:</p>
      
      <program language="r"><input>
      args(log)
      </input></program>
      
      <p>You can change the default values by simply assigning another object:</p>
      
      <program language="r"><input>
      log(8, base = 2)
      </input></program>
      
      <p>Note that we have not been specifying the argument <c>x</c> as such:</p>
      
      <program language="r"><input>
      log(x = 8, base = 2)
      </input></program>
      
      <p>The above code works, but we can save ourselves some typing: if no argument name is used, R assumes you are entering arguments in the order shown in the help file or by <c>args</c>. So by not using the names, it assumes the arguments are <c>x</c> followed by <c>base</c>:</p>
      
      <program language="r"><input>
      log(8, 2)
      </input></program>
      
      <p>If using the arguments' names, then we can include them in whatever order we want:</p>
      
      <program language="r"><input>
      log(base = 2, x = 8)
      </input></program>
      
      <p>To specify arguments, we must use <c>=</c>, and cannot use <c>&lt;-</c>.</p>
      
      <p>There are some exceptions to the rule that functions need the parentheses to be evaluated. Among these, the most commonly used are the arithmetic and relational operators. For example:</p>
      
      <program language="r"><input>
      2^3
      </input></program>
      
      <p>You can see the arithmetic operators by typing:</p>
      
      <program language="r"><input>
      help("+") 
      </input></program>
      
      <p>or</p>
      
      <program language="r"><input>
      ?"+"
      </input></program>
      
      <p>and the relational operators by typing:</p>
      
      <program language="r"><input>
      help("&gt;") 
      </input></program>
      
      <p>or</p>
      
      <program language="r"><input>
      ?"&gt;"
      </input></program>
      
      </subsection>
      
      <subsection xml:id="prebuilt-objects"><title>Prebuilt objects</title>
      
      <p>There are several datasets that are included for users to practice and test out functions. You can see all the available datasets by typing:</p>
      
      <program language="r"><input>
      #| eval: false
      
      data()
      </input></program>
      
      <p>This shows you the object name for these datasets. These datasets are objects that can be used by simply typing the name. For example, if you type:</p>
      
      <program language="r"><input>
      co2
      </input></program>
      
      <p>R will show you Mauna Loa atmospheric CO2 concentration data.</p>
      
      <p>Other prebuilt objects are mathematical quantities, such as the constant <m>\pi</m> and <m>\infty</m>:</p>
      
      <program language="r"><input>
      pi
      Inf + 1
      </input></program>
      
      </subsection>
      
      <subsection xml:id="variable-names"><title>Variable names</title>
      
      <p>We used <c>coef_a</c>, <c>coef_b</c>, and <c>coef_c</c> as variable names, but variable names can be almost anything. When writing code in R, it's important to choose variable names that are both meaningful and avoid conflicts with existing functions or reserved words in the language. For example, we did not use <c>a</c>, <c>b</c> and <c>c</c> to avoid a conflict with the <c>c()</c> function in R, described in <xref ref="sec-creating-vectors"/>. If you were to name a variable <c>c</c>, you would not receive an error or warning, but the conflict can lead to unexpected behavior and bugs that are hard to diagnose.</p>
      
      <p>Some basic rules in R are that variable names have to start with a letter, can't contain spaces, and should not be variables that are predefined in R, such as <c>c</c>.</p>
      
      <p>A nice convention to follow is to use meaningful words that describe what is stored, use only lower case, and use underscores as a substitute for spaces. For the quadratic equations, we could use something like this for the two roots:</p>
      
      <program language="r"><input>
      r_1 &lt;- (-coef_b + sqrt(coef_b^2 - 4*coef_a*coef_c))/(2*coef_a)
      r_2 &lt;- (-coef_b - sqrt(coef_b^2 - 4*coef_a*coef_c))/(2*coef_a)
      </input></program>
      
      <p>For more advice, we highly recommend studying Hadley Wickham's <url href="http://adv-r.had.co.nz/Style.html">style guide</url>.</p>
      
      </subsection>
      
      <subsection xml:id="saving-your-workspace"><title>Saving your workspace</title>
      
      <p>Values remain in the workspace until you end your session or erase them with the function <c>rm</c>. But workspaces also can be saved for later use. In fact, when you quit R, the program asks you if you want to save your workspace. If you do save it, the next time you start R, the program will restore the workspace.</p>
      
      <p>We actually recommend against saving the workspace this way because, as you start working on different projects, it will become harder to keep track of what is saved. Instead, we recommend you assign the workspace a specific name. You can do this by using the function <c>save</c> or <c>save.image</c>. To load, use the function <c>load</c>. When saving a workspace, we recommend the suffix <c>rda</c> or <c>RData</c>. In RStudio, you can also do this by navigating to the <em>Session</em> tab and choosing <em>Save Workspace as</em>. You can later load it using the <em>Load Workspace</em> options in the same tab. You can read the help pages on <c>save</c>, <c>save.image</c>, and <c>load</c> to learn more.</p>
      
      </subsection>
      
      <subsection xml:id="why-use-scripts"><title>Why use scripts?</title>
      
      <p>To solve another equation such as <m>3x^2 + 2x -1</m>, we can copy and paste the code above and then redefine the variables and recompute the solution:</p>
      
      <program language="r"><input>
      coef_a &lt;- 3
      coef_b &lt;- 2
      coef_c &lt;- -1
      (-coef_b + sqrt(coef_b^2 - 4*coef_a*coef_c))/(2*coef_a)
      (-coef_b - sqrt(coef_b^2 - 4*coef_a*coef_c))/(2*coef_a)
      </input></program>
      
      <p>By creating and saving a script with the code above, we would not need to retype everything each time and, instead, simply change the variable values. Try writing the script above into an editor and notice how easy it is to change the variables and receive an answer.</p>
      
      </subsection>
      
      <subsection xml:id="commenting-your-code"><title>Commenting your code</title>
      
      <p>If a line of R code starts with the symbol <c>#</c>, it is a comment and is not evaluated. We can use this to write reminders of why we wrote particular code. For example, in the script above we could add:</p>
      
      <program language="r"><input>
      ## Code to compute solution to quadratic equation
      
      ## Define the variables
      coef_a &lt;- 3 
      coef_b &lt;- 2
      coef_c &lt;- -1
      
      ## Now compute the solution
      (-coef_b + sqrt(coef_b^2 - 4*coef_a*coef_c))/(2*coef_a)
      (-coef_b - sqrt(coef_b^2 - 4*coef_a*coef_c))/(2*coef_a)
      </input></program>
      
      <note>
      <p>You are ready to do exercises 1-5.</p>
      </note>
      
      </subsection>
      
      </section>
      
      <section xml:id="data-types"><title>Data types</title>
      
      <p>Variables in R can be of different types. For example, we need to distinguish numbers from character strings and tables from simple lists of numbers. The function <c>class</c> helps us determine what type of object we have:</p>
      
      <program language="r"><input>
      a &lt;- 2
      class(a)
      </input></program>
      
      <p>To work efficiently in R, it is important to learn the different types of variables and what we can do with these.</p>
      
      <subsection xml:id="sec-data-frames"><title>Data frames</title>
      
      <p>Up to now, the variables we have defined are just one number. This is not very useful for storing data. The most common way of storing a dataset in R is in a <em>data frame</em>. Conceptually, we can think of a data frame as a table with rows representing observations and the different variables reported for each observation defining the columns. Data frames are particularly useful for datasets because we can combine different data types into one object.</p>
      
      <p>A large proportion of data analysis challenges start with data stored in a data frame. For example, we stored the data for our motivating example in a data frame. You can access this dataset by loading the <alert>dslabs</alert> library which provides the <c>murders</c> dataset:</p>
      
      <program language="r"><input>
      #| cache: false
      
      library(dslabs)
      </input></program>
      
      <p>To see that this is in fact a data frame, we type:</p>
      
      <program language="r"><input>
      class(murders)
      </input></program>
      
      </subsection>
      
      <subsection xml:id="examining-objects"><title>Examining objects</title>
      
      <p>The function <c>str</c> is useful for finding out more about the structure of an object:</p>
      
      <program language="r"><input>
      # change str to make sure it stays within margins
      str &lt;- function(x) utils::str(x, strict.width = 'wrap')
      </input></program>
      
      <program language="r"><input>
      str(murders)
      </input></program>
      
      <program language="r"><input>
      # remove str we defined
      rm(str)
      </input></program>
      
      <p>This tells us much more about the object. We see that the table has 51 rows (50 states plus DC) and five variables. We can show the first six lines using the function <c>head</c>:</p>
      
      <program language="r"><input>
      head(murders)
      </input></program>
      
      <p>In this dataset, each state is considered an observation and five variables are reported for each state.</p>
      
      <p>Before we go any further in answering our original question about different states, let's learn more about the components of this object.</p>
      
      </subsection>
      
      <subsection xml:id="the-accessor-"><title>The accessor: `$`</title>
      
      <p>For our analysis, we will need to access the different variables represented by columns included in this data frame. To do this, we use the accessor operator <c>$</c> in the following way:</p>
      
      <program language="r"><input>
      murders$population
      </input></program>
      
      <p>But how did we know to use <c>population</c>? Previously, by applying the function <c>str</c> to the object <c>murders</c>, we revealed the names for each of the five variables stored in this table. We can quickly access the variable names using:</p>
      
      <program language="r"><input>
      names(murders)
      </input></program>
      
      <p>It is important to know that the order of the entries in <c>murders$population</c> preserves the order of the rows in our data table. This will later permit us to manipulate one variable based on the results of another. For example, we will be able to order the state names by the number of murders.</p>
      
      <note>
      <p>R comes with a very nice auto-complete functionality that saves us the trouble of typing out all the names. Try typing <c>murders$p</c> then hitting the <em>tab</em> key on your keyboard. This functionality and many other useful auto-complete features are available when working in RStudio.</p>
      </note>
      
      </subsection>
      
      <subsection xml:id="vectors"><title>Vectors</title>
      
      <p>The object <c>murders$population</c> is not one number but several. We call these types of objects <em>vectors</em>. A single number is technically a vector of length 1, but in general we use the term vectors to refer to objects with several entries. The function <c>length</c> tells you how many entries are in the vector:</p>
      
      <program language="r"><input>
      pop &lt;- murders$population
      length(pop)
      </input></program>
      
      <p>This particular vector is <em>numeric</em> since population sizes are numbers:</p>
      
      <program language="r"><input>
      class(pop)
      </input></program>
      
      <p>In a numeric vector, every entry must be a number.</p>
      
      <p>To store character strings, vectors can also be of class <em>character</em>. For example, the state names are characters:</p>
      
      <program language="r"><input>
      class(murders$state)
      </input></program>
      
      <p>As with numeric vectors, all entries in a character vector need to be a character.</p>
      
      <p>Another important type of vectors are <em>logical vectors</em>. These must be either <c>TRUE</c> or <c>FALSE</c>.</p>
      
      <program language="r"><input>
      z &lt;- 3 == 2
      z
      class(z)
      </input></program>
      
      <p>Here the <c>==</c> is a relational operator asking if 3 is equal to 2. In R, if you just use one <c>=</c>, you actually assign a variable, but if you use two <c>==</c> you test for equality.</p>
      
      <p>You can see the other <em>relational operators</em> by typing:</p>
      
      <program language="r"><input>
      ?Comparison
      </input></program>
      
      <p>In future sections, you will see how useful relational operators can be.</p>
      
      <p>We discuss more important features of vectors after the next set of exercises.</p>
      
      <note>
      <p>Mathematically, the values in <c>pop</c> are integers and there is an integer class in R. However, by default, numbers are assigned class numeric even when they are round integers. For example, <c>class(1)</c> returns numeric. You can turn them into class integer with the <c>as.integer()</c> function or by adding an <c>L</c> like this: <c>1L</c>. Note the class by typing: <c>class(1L)</c></p>
      </note>
      
      </subsection>
      
      <subsection xml:id="sec-factors"><title>Factors</title>
      
      <p>In the <c>murders</c> dataset, we might expect the region to also be a character vector. However, it is not:</p>
      
      <program language="r"><input>
      class(murders$region)
      </input></program>
      
      <p>It is a <em>factor</em>. Factors are useful for storing categorical data. We can see that there are only 4 regions by using the <c>levels</c> function:</p>
      
      <program language="r"><input>
      levels(murders$region)
      </input></program>
      
      <p>In the background, R stores these <em>levels</em> as integers and keeps a map to keep track of the labels. This is more memory efficient than storing all the characters.</p>
      
      <p>Note that the levels have an order that is different from the order of appearance in the factor object. The default in R is for the levels to follow alphabetical order. However, often we want the levels to follow a different order. You can specify an order through the <c>levels</c> argument when creating the factor with the <c>factor</c> function. For example, in the murders dataset regions are ordered from east to west. The function <c>reorder</c> lets us change the order of the levels of a factor variable based on a summary computed on a numeric vector. We will demonstrate this with a simple example, and will see more advanced ones in the Data Visualization part of the book.</p>
      
      <p>Suppose we want the levels of region ordered by the total number of murders rather than alphabetically If there are values associated with each level, we can use the <c>reorder</c> function and specify a data summary to determine the order. The following code takes the sum of the total murders in each region, and reorders the factor following these sums.</p>
      
      <program language="r"><input>
      region &lt;- murders$region
      value &lt;- murders$total
      region &lt;- reorder(region, value, FUN = sum)
      levels(region)
      </input></program>
      
      <p>The new order is in agreement with the fact that the Northeast has the least murders and the South has the most.</p>
      
      <note>
      <p>Factors can be a source of confusion since sometimes they behave like characters and sometimes they do not. As a result, confusing factors and characters are a common source of bugs.</p>
      </note>
      
      </subsection>
      
      <subsection xml:id="lists"><title>Lists</title>
      
      <p>Data frames are a special case of <em>lists</em>. Lists are useful because you can store any combination of different types. You can create a list using the <c>list</c> function like this:</p>
      
      <program language="r"><input>
      record &lt;- list(name = "John Doe",
                   student_id = 1234,
                   grades = c(95, 82, 91, 97, 93),
                   final_grade = "A")
      </input></program>
      
      <p>The function <c>c</c> is described in <xref ref="sec-vectors"/>.</p>
      
      <p>This list includes a character, a number, a vector with five numbers, and another character.</p>
      
      <program language="r"><input>
      record
      class(record)
      </input></program>
      
      <p>As with data frames, you can extract the components of a list with the accessor <c>$</c>.</p>
      
      <program language="r"><input>
      record$student_id
      </input></program>
      
      <p>We can also use double square brackets (<c>[[</c>) like this:</p>
      
      <program language="r"><input>
      record[["student_id"]]
      </input></program>
      
      <p>You should get used to the fact that in R, there are often several ways to do the same thing, such as accessing entries.</p>
      
      <p>You might also encounter lists without variable names.</p>
      
      <program language="r"><input>
      record2 &lt;- list("John Doe", 1234)
      record2
      </input></program>
      
      <p>If a list does not have names, you cannot extract the elements with <c>$</c>, but you can still use the brackets method and instead of providing the variable name, you provide the list index, like this:</p>
      
      <program language="r"><input>
      record2[[1]]
      </input></program>
      
      <p>We won't be using lists until later, but you might encounter one in your own exploration of R. For this reason, we show you some basics here.</p>
      
      </subsection>
      
      <subsection xml:id="sec-matrices"><title>Matrices</title>
      
      <p>Matrices are another type of object that are common in R. Matrices are similar to data frames in that they are two-dimensional: they have rows and columns. However, like numeric, character and logical vectors, entries in matrices have to be all the same type. For this reason data frames are much more useful for storing data, since we can have characters, factors, and numbers in them.</p>
      
      <p>Yet matrices have a major advantage over data frames: we can perform matrix algebra operations, a powerful type of mathematical technique. We do not describe these operations in this book, but much of what happens in the background when you perform a data analysis involves matrices. We only cover matrices briefly here since some of the functions we will learn return matrices. However, if you plan to perform more advanced work, we highly recommend learning more as they are widely used in data analysis.</p>
      
      <p><!--We cover matrices in more detail in Chapter @sec-matrix-algebra but describe them briefly here since some of the functions we will learn return matrices. --></p>
      
      <p>We can define a matrix using the <c>matrix</c> function. We need to specify the data in the matrix as well as the number of rows and columns.</p>
      
      <program language="r"><input>
      mat &lt;- matrix(1:12, 4, 3)
      mat
      </input></program>
      
      <p>The shorthand using <c>:</c> is described in <xref ref="sec-vectors"/>.</p>
      
      <p>You can access specific entries in a matrix using square brackets (<c>[</c>). If you want the second row, third column, you use:</p>
      
      <program language="r"><input>
      mat[2, 3]
      </input></program>
      
      <p>If you want the entire second row, you leave the column spot empty:</p>
      
      <program language="r"><input>
      mat[2, ]
      </input></program>
      
      <p>Notice that this returns a vector, not a matrix.</p>
      
      <p>Similarly, if you want the entire third column, you leave the row spot empty:</p>
      
      <program language="r"><input>
      mat[, 3]
      </input></program>
      
      <p>This is also a vector, not a matrix.</p>
      
      <p>You can access more than one column or more than one row if you like. This will give you a new matrix.</p>
      
      <program language="r"><input>
      mat[, 2:3]
      </input></program>
      
      <p>You can subset both rows and columns:</p>
      
      <program language="r"><input>
      mat[1:2, 2:3]
      </input></program>
      
      <p>We can convert matrices into data frames using the function <c>as.data.frame</c>:</p>
      
      <program language="r"><input>
      as.data.frame(mat)
      </input></program>
      
      <p>You can also use single square brackets (<c>[</c>) to access rows and columns of a data frame:</p>
      
      <program language="r"><input>
      murders[25, 1]
      murders[2:3, ]
      </input></program>
      
      <note>
      <p>You are ready to do exercises 6-11.</p>
      </note>
      
      </subsection>
      
      </section>
      
      <section xml:id="sec-vectors"><title>Vectors</title>
      
      <p>In R, the most basic objects available to store data are <em>vectors</em>. As we have seen, complex datasets can usually be broken down into components that are vectors. For example, in a data frame, each column is a vector. Here we learn more about this important class.</p>
      
      <subsection xml:id="sec-creating-vectors"><title>Creating vectors</title>
      
      <p>We can create vectors using the function <c>c</c>, which stands for <em>concatenate</em>. We use <c>c</c> to concatenate entries in the following way:</p>
      
      <program language="r"><input>
      codes &lt;- c(380, 124, 818)
      codes
      </input></program>
      
      <p>We can also create character vectors. We use the quotes to denote that the entries are characters rather than variable names.</p>
      
      <program language="r"><input>
      country &lt;- c("italy", "canada", "egypt")
      </input></program>
      
      <p>In R you can also use single quotes:</p>
      
      <program language="r"><input>
      country &lt;- c('italy', 'canada', 'egypt')
      </input></program>
      
      <p>But be careful not to confuse the single quote ' with the <em>backtick</em> &#96;.</p>
      
      <p>By now you should know that if you type:</p>
      
      <program language="r"><input>
      country &lt;- c(italy, canada, egypt)
      </input></program>
      
      <p>you receive an error because the variables <c>italy</c>, <c>canada</c>, and <c>egypt</c> are not defined. If we do not use the quotes, R looks for variables with those names and returns an error.</p>
      
      </subsection>
      
      <subsection xml:id="names"><title>Names</title>
      
      <p>Sometimes it is useful to name the entries of a vector. For example, when defining a vector of country codes, we can use the names to connect the two:</p>
      
      <program language="r"><input>
      codes &lt;- c(italy = 380, canada = 124, egypt = 818)
      codes
      </input></program>
      
      <p>The object <c>codes</c> continues to be a numeric vector:</p>
      
      <program language="r"><input>
      class(codes)
      </input></program>
      
      <p>but with names:</p>
      
      <program language="r"><input>
      names(codes)
      </input></program>
      
      <p>If the use of strings without quotes looks confusing, know that you can use the quotes as well:</p>
      
      <program language="r"><input>
      codes &lt;- c("italy" = 380, "canada" = 124, "egypt" = 818)
      codes
      </input></program>
      
      <p>There is no difference between this function call and the previous one. This is one of the many ways in which R is quirky compared to other languages.</p>
      
      <p>We can also assign names using the <c>names</c> functions:</p>
      
      <program language="r"><input>
      codes &lt;- c(380, 124, 818)
      country &lt;- c("italy","canada","egypt")
      names(codes) &lt;- country
      codes
      </input></program>
      
      </subsection>
      
      <subsection xml:id="sequences"><title>Sequences</title>
      
      <p>Another useful function for creating vectors generates sequences:</p>
      
      <program language="r"><input>
      seq(1, 10)
      </input></program>
      
      <p>The first argument defines the start, and the second defines the end which is included. The default is to go up in increments of 1, but a third argument lets us tell it how much to jump by:</p>
      
      <program language="r"><input>
      seq(1, 10, 2)
      </input></program>
      
      <p>If we want consecutive integers, we can use the following shorthand:</p>
      
      <program language="r"><input>
      1:10
      </input></program>
      
      <p>When we use these functions, R produces integers, not numerics, because they are typically used to index something:</p>
      
      <program language="r"><input>
      class(1:10)
      </input></program>
      
      <p>However, if we create a sequence including non-integers, the class changes:</p>
      
      <program language="r"><input>
      class(seq(1, 10, 0.5))
      </input></program>
      
      </subsection>
      
      <subsection xml:id="subsetting"><title>Subsetting</title>
      
      <p>We use square brackets to access specific elements of a vector. For the vector <c>codes</c> we defined above, we can access the second element using:</p>
      
      <program language="r"><input>
      codes[2]
      </input></program>
      
      <p>You can get more than one entry by using a multi-entry vector as an index:</p>
      
      <program language="r"><input>
      codes[c(1,3)]
      </input></program>
      
      <p>The sequences defined above are particularly useful if we want to access, say, the first two elements:</p>
      
      <program language="r"><input>
      codes[1:2]
      </input></program>
      
      <p>If the elements have names, we can also access the entries using these names. Below are two examples.</p>
      
      <program language="r"><input>
      codes["canada"]
      codes[c("egypt","italy")]
      </input></program>
      
      </subsection>
      
      </section>
      
      <section xml:id="coercion"><title>Coercion</title>
      
      <p>In general, <em>coercion</em> is an attempt by R to be flexible with data types. When an entry does not match the expected, some of the prebuilt R functions try to guess what was meant before throwing an error. This can also lead to confusion. Failing to understand <em>coercion</em> can drive programmers crazy when attempting to code in R since it behaves quite differently from most other languages in this regard. Let's learn about it with some examples.</p>
      
      <p>We said that vectors must be all of the same type. So if we try to combine, say, numbers and characters, you might expect an error:</p>
      
      <program language="r"><input>
      x &lt;- c(1, "canada", 3)
      </input></program>
      
      <p>But we don't get one, not even a warning! What happened? Look at <c>x</c> and its class:</p>
      
      <program language="r"><input>
      x
      class(x)
      </input></program>
      
      <p>R <em>coerced</em> the data into characters. It guessed that because you put a character string in the vector, you meant the 1 and 3 to actually be character strings <c>"1"</c> and <c>"3"</c>. The fact that not even a warning is issued is an example of how coercion can cause many unnoticed errors in R.</p>
      
      <p>R also offers functions to change from one type to another. For example, you can turn numbers into characters with:</p>
      
      <program language="r"><input>
      x &lt;- 1:5
      y &lt;- as.character(x)
      y
      </input></program>
      
      <p>You can turn it back with <c>as.numeric</c>:</p>
      
      <program language="r"><input>
      as.numeric(y)
      </input></program>
      
      <p>This function is actually quite useful since datasets that include numbers as character strings are common.</p>
      
      </section>
      
      <section xml:id="not-availables-na"><title>Not availables (NA)</title>
      
      <p>When a function tries to coerce one type to another and encounters an impossible case, it usually gives us a warning and turns the entry into a special value called an <c>NA</c> for "not available". For example:</p>
      
      <program language="r"><input>
      x &lt;- c("1", "b", "3")
      as.numeric(x)
      </input></program>
      
      <p>R does not have any guesses for what number you want when you type <c>b</c>, so it does not try.</p>
      
      <p>As a data scientist you will encounter the <c>NA</c>s often as they are generally used for missing data, a common problem in real-world datasets.</p>
      
      <note>
      <p>You are ready to do exercises 12-23.</p>
      </note>
      
      </section>
      
      <section xml:id="sorting"><title>Sorting</title>
      
      <p>Now that we have mastered some basic R knowledge, let's try to gain some insights into the safety of different states in the context of gun murders.</p>
      
      <subsection xml:id="sort"><title>`sort`</title>
      
      <p>Say we want to rank the states from least to most gun murders. The function <c>sort</c> sorts a vector in increasing order. We can therefore see the largest number of gun murders by typing:</p>
      
      <program language="r"><input>
      library(dslabs)
      sort(murders$total)
      </input></program>
      
      <p>However, this does not give us information about which states have which murder totals. For example, we don't know which state had the maximum number of murders.</p>
      
      </subsection>
      
      <subsection xml:id="order"><title>`order`</title>
      
      <p>The function <c>order</c> is closer to what we want. It takes a vector as input and returns the vector of indexes that sorts the input vector. This may sound confusing so let's look at a simple example. We can create a vector and sort it:</p>
      
      <program language="r"><input>
      x &lt;- c(31, 4, 15, 92, 65)
      sort(x)
      </input></program>
      
      <p>Rather than sort the input vector, the function <c>order</c> returns the index that sorts input vector:</p>
      
      <program language="r"><input>
      index &lt;- order(x)
      x[index]
      </input></program>
      
      <p>This is the same output as that returned by <c>sort(x)</c>. If we look at this index, we see why it works:</p>
      
      <program language="r"><input>
      x
      order(x)
      </input></program>
      
      <p>The second entry of <c>x</c> is the smallest, so <c>order(x)</c> starts with <c>2</c>. The next smallest is the third entry, so the second entry is <c>3</c> and so on.</p>
      
      <p>How does this help us order the states by murders? First, remember that the entries of vectors you access with <c>$</c> follow the same order as the rows in the table. For example, these two vectors containing state names and abbreviations, respectively, are matched by their order:</p>
      
      <program language="r"><input>
      murders$state[1:6]
      murders$abb[1:6]
      </input></program>
      
      <p>This means we can order the state names by their total murders. We first obtain the index that orders the vectors according to murder totals and then index the state names vector:</p>
      
      <program language="r"><input>
      ind &lt;- order(murders$total) 
      murders$abb[ind] 
      </input></program>
      
      <p>According to the above, California had the most murders.</p>
      
      </subsection>
      
      <subsection xml:id="max-and-whichmax"><title>`max` and `which.max`</title>
      
      <p>If we are only interested in the entry with the largest value, we can use <c>max</c> for the value:</p>
      
      <program language="r"><input>
      max(murders$total)
      </input></program>
      
      <p>and <c>which.max</c> for the index of the largest value:</p>
      
      <program language="r"><input>
      i_max &lt;- which.max(murders$total)
      murders$state[i_max]
      </input></program>
      
      <p>For the minimum, we can use <c>min</c> and <c>which.min</c> in the same way.</p>
      
      <p>Does this mean California is the most dangerous state? In an upcoming section, we argue that we should be considering rates instead of totals. Before doing that, we introduce one last order-related function: <c>rank</c>.</p>
      
      </subsection>
      
      <subsection xml:id="rank"><title>`rank`</title>
      
      <p>Although not as frequently used as <c>order</c> and <c>sort</c>, the function <c>rank</c> is also related to order and can be useful. For any given vector it returns a vector with the rank of the first entry, second entry, etc., of the input vector. Here is a simple example:</p>
      
      <program language="r"><input>
      x &lt;- c(31, 4, 15, 92, 65)
      rank(x)
      </input></program>
      
      <p>To summarize, let's look at the results of the three functions we have introduced:</p>
      
      <program language="r"><input>
      tmp &lt;- data.frame(original=x, sort=sort(x), order=order(x), rank=rank(x))
      if(knitr::is_html_output()){
        knitr::kable(tmp, "html") |&gt;
          kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
      } else{
        knitr::kable(tmp, "latex", booktabs = TRUE) |&gt;
          kableExtra::kable_styling(font_size = 8)
      }
      </input></program>
      
      <note>
      <p>You are ready to do exercises 24-31</p>
      </note>
      
      </subsection>
      
      </section>
      
      <section xml:id="vector-arithmetics"><title>Vector arithmetics</title>
      
      <p>California had the most murders, but does this mean it is the most dangerous state? What if it just has many more people than any other state? We can quickly confirm that California indeed has the largest population:</p>
      
      <program language="r"><input>
      library(dslabs)
      murders$state[which.max(murders$population)]
      </input></program>
      
      <p>with over 37 million inhabitants. It is therefore unfair to compare the totals if we are interested in learning how safe the state is. What we really should be computing is the murders per capita. The reports we describe in the motivating section used murders per 100,000 as the unit. To compute this quantity, the powerful vector arithmetic capabilities of R come in handy.</p>
      
      <subsection xml:id="rescaling-a-vector"><title>Rescaling a vector</title>
      
      <p>In R, arithmetic operations on vectors occur <em>element-wise</em>. For a quick example, suppose we have height in inches:</p>
      
      <program language="r"><input>
      inches &lt;- c(69, 62, 66, 70, 70, 73, 67, 73, 67, 70)
      </input></program>
      
      <p>and want to convert to centimeters. Notice what happens when we multiply <c>inches</c> by 2.54:</p>
      
      <program language="r"><input>
      inches * 2.54
      </input></program>
      
      <p>In the line above, we multiplied each element by 2.54. Similarly, if for each entry we want to compute how many inches taller or shorter than 69 inches, the average height for males, we can subtract it from every entry like this:</p>
      
      <program language="r"><input>
      inches - 69
      </input></program>
      
      </subsection>
      
      <subsection xml:id="two-vectors"><title>Two vectors</title>
      
      <p>If we have two vectors of the same length, and we sum them in R, they will be added entry by entry as follows:</p>
      
      <me>\begin{pmatrix}
      a\\
      b\\
      c\\
      d
      \end{pmatrix}
      +
      \begin{pmatrix}
      e\\
      f\\
      g\\
      h
      \end{pmatrix}
      =
      \begin{pmatrix}
      a +e\\
      b + f\\
      c + g\\
      d + h
      \end{pmatrix}</me>
      
      <p>The same holds for other mathematical operations, such as <c>-</c>, <c>*</c> and <c>/</c>.</p>
      
      <p>This implies that to compute the murder rates we can simply type:</p>
      
      <program language="r"><input>
      murder_rate &lt;- murders$total / murders$population * 100000
      </input></program>
      
      <p>Once we do this, we notice that California is no longer near the top of the list. In fact, we can use what we have learned to order the states by murder rate:</p>
      
      <program language="r"><input>
      murders$abb[order(murder_rate)]
      </input></program>
      
      </subsection>
      
      <subsection xml:id="beware-of-recycling"><title>Beware of recycling</title>
      
      <p>Another common source of unnoticed errors in R is the use of <em>recycling</em>. We saw that vectors are added elementwise. So if the vectors don't match in length, it is natural to assume that we should get an error. But we don't. Notice what happens:</p>
      
      <program language="r"><input>
      x &lt;- c(1, 2, 3)
      y &lt;- c(10, 20, 30, 40, 50, 60, 70)
      x + y
      </input></program>
      
      <p>We do get a warning, but no error. For the output, R has recycled the numbers in <c>x</c>. Notice the last digit of numbers in the output.</p>
      
      <note>
      <p>You are now ready to do exercises 32-34.</p>
      </note>
      
      </subsection>
      
      </section>
      
      <section xml:id="indexing"><title>Indexing</title>
      
      <p>R provides a powerful and convenient way of indexing vectors. We can, for example, subset a vector based on properties of another vector. In this section, we continue working with our US murders example, which we can load like this:</p>
      
      <program language="r"><input>
      library(dslabs)
      </input></program>
      
      <subsection xml:id="subsetting-with-logicals"><title>Subsetting with logicals</title>
      
      <p>We have now calculated the murder rate using:</p>
      
      <program language="r"><input>
      murder_rate &lt;- murders$total / murders$population * 100000 
      </input></program>
      
      <p>Imagine you are moving from Italy where, according to an ABC news report, the murder rate is only 0.71 per 100,000. You would prefer to move to a state with a similar murder rate. Another powerful feature of R is that we can use logicals to index vectors. If we compare a vector to a single number, it actually performs the test for each entry. The following is an example related to the question above:</p>
      
      <program language="r"><input>
      ind &lt;- murder_rate &lt; 0.71
      </input></program>
      
      <p>If we instead want to know if a value is less or equal, we can use:</p>
      
      <program language="r"><input>
      ind &lt;- murder_rate &lt;= 0.71
      </input></program>
      
      <p>Note that we get back a logical vector with <c>TRUE</c> for each entry smaller than or equal to 0.71. To see which states these are, we can leverage the fact that vectors can be indexed with logicals.</p>
      
      <program language="r"><input>
      murders$state[ind]
      </input></program>
      
      <p>In order to count how many are TRUE, the function <c>sum</c> returns the sum of the entries of a vector and logical vectors get <em>coerced</em> to numeric with <c>TRUE</c> coded as 1 and <c>FALSE</c> as 0. Thus we can count the states using:</p>
      
      <program language="r"><input>
      sum(ind)
      </input></program>
      
      </subsection>
      
      <subsection xml:id="logical-operators"><title>Logical operators</title>
      
      <p>Suppose we like the mountains and we want to move to a safe state in the western region of the country. We want the murder rate to be at most 1. In this case, we want two different things to be true. Here we can use the logical operator <em>and</em>, which in R is represented with <c>&amp;</c>. This operation results in <c>TRUE</c> only when both logicals are <c>TRUE</c>. To see this, consider this example:</p>
      
      <program language="r"><input>
      TRUE &amp; TRUE
      TRUE &amp; FALSE
      FALSE &amp; FALSE
      </input></program>
      
      <p>For our example, we can form two logicals:</p>
      
      <program language="r"><input>
      west &lt;- murders$region == "West"
      safe &lt;- murder_rate &lt;= 1
      </input></program>
      
      <p>and we can use the <c>&amp;</c> to get a vector of logicals that tells us which states satisfy both conditions:</p>
      
      <program language="r"><input>
      ind &lt;- safe &amp; west
      murders$state[ind]
      </input></program>
      
      </subsection>
      
      <subsection xml:id="which"><title>`which`</title>
      
      <p>Suppose we want to look up California's murder rate. For this type of operation, it is convenient to convert vectors of logicals into indexes instead of keeping long vectors of logicals. The function <c>which</c> tells us which entries of a logical vector are TRUE. So we can type:</p>
      
      <program language="r"><input>
      ind &lt;- which(murders$state == "California")
      murder_rate[ind]
      </input></program>
      
      </subsection>
      
      <subsection xml:id="match"><title>`match`</title>
      
      <p>If instead of just one state we want to find out the murder rates for several states, say New York, Florida, and Texas, we can use the function <c>match</c>. This function tells us which indexes of a second vector match each of the entries of a first vector:</p>
      
      <program language="r"><input>
      ind &lt;- match(c("New York", "Florida", "Texas"), murders$state)
      ind
      </input></program>
      
      <p>Now we can look at the murder rates:</p>
      
      <program language="r"><input>
      murder_rate[ind]
      </input></program>
      
      </subsection>
      
      <subsection xml:id="in"><title>`%in%`</title>
      
      <p>If rather than an index we want a logical that tells us whether or not each element of a first vector is in a second, we can use the function <c>%in%</c>. Let's imagine you are not sure if Boston, Dakota, and Washington are states. You can find out like this:</p>
      
      <program language="r"><input>
      c("Boston", "Dakota", "Washington") %in% murders$state
      </input></program>
      
      <p>Note that we will be using <c>%in%</c> often throughout the book.</p>
      
      <p>There is a connection between <c>match</c> and <c>%in%</c> through <c>which</c>. To see this, notice that the following two lines produce the same index (although in different order):</p>
      
      <program language="r"><input>
      match(c("New York", "Florida", "Texas"), murders$state)
      which(murders$state %in% c("New York", "Florida", "Texas"))
      </input></program>
      
      <note>
      <p>You are now ready to do exercises 35-42.</p>
      </note>
      
      </subsection>
      
      </section>
      
      <section xml:id="basic-plots"><title>Basic plots</title>
      
      <p>In a later chapter on ggplot2, we describe an add-on package that provides a powerful approach to producing plots in R. We then have an entire part on Data Visualization in which we provide many examples. Here we briefly describe some of the functions that are available in a basic R installation.</p>
      
      <subsection xml:id="plot"><title>`plot`</title>
      
      <p>The <c>plot</c> function can be used to make scatterplots. Here is a plot of total murders versus population.</p>
      
      <program language="r"><input>
      x &lt;- murders$population / 10^6
      y &lt;- murders$total
      plot(x, y)
      </input></program>
      
      <program language="r"><input>
      rafalib::mypar()
      x &lt;- murders$population / 10^6
      y &lt;- murders$total
      plot(x, y)
      </input></program>
      
      <p>For a quick plot that avoids accessing variables twice, we can use the <c>with</c> function:</p>
      
      <program language="r"><input>
      with(murders, plot(population, total))
      </input></program>
      
      <p>The function <c>with</c> lets us use the <c>murders</c> column names in the <c>plot</c> function. It also works with any data frames and any function.</p>
      
      </subsection>
      
      <subsection xml:id="hist"><title>`hist`</title>
      
      <p>We will describe histograms as they relate to distributions in the Data Visualization part of the book. Here we will simply note that histograms are a powerful graphical summary of a list of numbers that gives you a general overview of the types of values you have. We can make a histogram of our murder rates by simply typing:</p>
      
      <program language="r"><input>
      x &lt;- with(murders, total / population * 100000)
      hist(x)
      </input></program>
      
      <program language="r"><input>
      rafalib::mypar()
      x &lt;- with(murders, total / population * 100000)
      hist(x)
      </input></program>
      
      <p>We can see that there is a wide range of values with most of them between 2 and 3 and one very extreme case with a murder rate of more than 15:</p>
      
      <program language="r"><input>
      murders$state[which.max(x)]
      </input></program>
      
      </subsection>
      
      <subsection xml:id="boxplot"><title>`boxplot`</title>
      
      <p>Boxplots will also be described in the Data Visualization part of the book. They provide a more terse summary than histograms, but they are easier to stack with other boxplots. For example, here we can use them to compare the different regions:</p>
      
      <program language="r"><input>
      murders$rate &lt;- with(murders, total / population * 100000)
      boxplot(rate~region, data = murders)
      </input></program>
      
      <program language="r"><input>
      rafalib::mypar()
      murders$rate &lt;- with(murders, total / population * 100000)
      boxplot(rate~region, data = murders)
      </input></program>
      
      <p>We can see that the South has higher murder rates than the other three regions.</p>
      
      </subsection>
      
      <subsection xml:id="image"><title>`image`</title>
      
      <p>The image function displays the values in a matrix using color. Here is a quick example:</p>
      
      <program language="r"><input>
      x &lt;- matrix(1:120, 12, 10)
      image(x)
      </input></program>
      
      <program language="r"><input>
      rafalib::mypar()
      x &lt;- matrix(1:120, 12, 10)
      image(x)
      </input></program>
      
      <note>
      <p>You are now ready to do exercises 43-45.</p>
      </note>
      
      </subsection>
      
      </section>
      
      <section xml:id="exercises"><title>Exercises</title>
      
      <ol>
      <li><p>What is the sum of the first 100 positive integers? The formula for the sum of integers 1 through n is <m>n(n+1)/2</m>. Define <m>n=100</m> and then use R to compute the sum of 1 through 100 using the formula. What is the sum?</p></li>
      
      <li><p>Now use the same formula to compute the sum of the integers from 1 through 1000.</p></li>
      
      <li>
      <p>Look at the result of typing the following code into R:</p>
      
      <program language="r"><input>
      n &lt;- 1000
      x &lt;- seq(1, n)
      sum(x)
      </input></program>
      
      <p>Based on the result, what do you think the functions <c>seq</c> and <c>sum</c> do? You can use <c>help</c>.</p>
      
      <p>a.  <c>sum</c> creates a list of numbers and <c>seq</c> adds them up. b.  <c>seq</c> creates a list of numbers and <c>sum</c> adds them up. c.  <c>seq</c> creates a random list and <c>sum</c> computes the sum of 1 through 1,000. d.  <c>sum</c> always returns the same number.</p>
      </li>
      
      <li><p>In math and programming, we say that we evaluate a function when we replace the argument with a given value. So if we type <c>sqrt(4)</c>, we evaluate the <c>sqrt</c> function. In R, you can evaluate a function inside another function. The evaluations happen from the inside out. Use one line of code to compute the log, in base 10, of the square root of 100.</p></li>
      
      <li>
      <p>Which of the following will always return the numeric value stored in <c>x</c>? You can try out examples and use the help system if you want.</p>
      
      <p>a.  <c>log(10^x)</c> b.  <c>log10(x^10)</c> c.  <c>log(exp(x))</c> d.  <c>exp(log(x, base = 2))</c></p>
      </li>
      
      <li>
      <p>Make sure the US murders dataset is loaded. Use the function <c>str</c> to examine the structure of the <c>murders</c> object. Which of the following best describes the variables represented in this data frame?</p>
      
      <p>a.  The 51 states. b.  The murder rates for all 50 states and DC. c.  The state name, the abbreviation of the state name, the state's region, and the state's population and total number of murders for 2010. d.  <c>str</c> shows no relevant information.</p>
      </li>
      
      <li><p>What are the column names used by the data frame for these five variables?</p></li>
      
      <li><p>Use the accessor <c>$</c> to extract the state abbreviations and assign them to the object <c>a</c>. What is the class of this object?</p></li>
      
      <li><p>Now use the square brackets to extract the state abbreviations and assign them to the object <c>b</c>. Use the <c>identical</c> function to determine if <c>a</c> and <c>b</c> are the same.</p></li>
      
      <li>
      <p>We saw that the <c>region</c> column stores a factor. You can corroborate this by typing:</p>
      
      <program language="r"><input>
      class(murders$region)
      </input></program>
      
      <p>With one line of code, use the functions <c>levels</c> and <c>length</c> to determine the number of regions defined by this dataset.</p>
      </li>
      
      <li><p>The function <c>table</c> takes a vector and returns the frequency of each element. You can quickly see how many states are in each region by applying this function. Use this function in one line of code to create a table of number of states per region.</p></li>
      
      <li><p>Use the function <c>c</c> to create a vector with the average high temperatures in January for Beijing, Lagos, Paris, Rio de Janeiro, San Juan, and Toronto, which are 35, 88, 42, 84, 81, and 30 degrees Fahrenheit. Call the object <c>temp</c>.</p></li>
      
      <li><p>Now create a vector with the city names and call the object <c>city</c>.</p></li>
      
      <li><p>Use the <c>names</c> function and the objects defined in the previous exercises to associate the temperature data with its corresponding city.</p></li>
      
      <li><p>Use the <c>[</c> and <c>:</c> operators to access the temperature of the first three cities on the list.</p></li>
      
      <li><p>Use the <c>[</c> operator to access the temperature of Paris and San Juan.</p></li>
      
      <li><p>Use the <c>:</c> operator to create a sequence of numbers <m>12,13,14,\dots,73</m>.</p></li>
      
      <li><p>Create a vector containing all the positive odd numbers smaller than 100.</p></li>
      
      <li><p>Create a vector of numbers that starts at 6, does not pass 55, and adds numbers in increments of 4/7: 6, 6 + 4/7, 6 + 8/7, and so on. How many numbers does the list have? Hint: use <c>seq</c> and <c>length</c>.</p></li>
      
      <li><p>What is the class of the following object <c>a &lt;- seq(1, 10, 0.5)</c>?</p></li>
      
      <li><p>What is the class of the following object <c>a &lt;- seq(1, 10)</c>?</p></li>
      
      <li><p>The class of <c>class(a&lt;-1)</c> is numeric, not integer. R defaults to numeric and to force an integer, you need to add the letter <c>L</c>. Confirm that the class of <c>1L</c> is integer.</p></li>
      
      <li>
      <p>Define the following vector:</p>
      
      <program language="r"><input>
      x &lt;- c("1", "3", "5")
      </input></program>
      
      <p>and coerce it to get integers.</p>
      </li>
      
      <li><p>For exercises 24-31 we will use the US murders dataset. Make sure you load it prior to starting. Use the <c>$</c> operator to access the population size data and store it as the object <c>pop</c>. Then use the <c>sort</c> function to redefine <c>pop</c> so that it is sorted. Finally, use the <c>[</c> operator to report the smallest population size.</p></li>
      
      <li><p>Now instead of the smallest population size, find the index of the entry with the smallest population size. Hint: use <c>order</c> instead of <c>sort</c>.</p></li>
      
      <li><p>We can actually perform the same operation as in the previous exercise using the function <c>which.min</c>. Write one line of code that does this.</p></li>
      
      <li><p>Now we know how small the smallest state is and we know which row represents it. Which state is it? Define a variable <c>states</c> to be the state names from the <c>murders</c> data frame. Report the name of the state with the smallest population.</p></li>
      
      <li>
      <p>You can create a data frame using the <c>data.frame</c> function. Here is a quick example:</p>
      
      <program language="r"><input>
      temp &lt;- c(35, 88, 42, 84, 81, 30)
      city &lt;- c("Beijing", "Lagos", "Paris", "Rio de Janeiro", 
                "San Juan", "Toronto")
      city_temps &lt;- data.frame(name = city, temperature = temp)
      </input></program>
      
      <p>Use the <c>rank</c> function to determine the population rank of each state from smallest population size to biggest. Save these ranks in an object called <c>ranks</c>, then create a data frame with the state name and its rank. Call the data frame <c>my_df</c>.</p>
      </li>
      
      <li><p>Repeat the previous exercise, but this time order <c>my_df</c> so that the states are ordered from least populous to most populous. Hint: create an object <c>ind</c> that stores the indexes needed to order the population values. Then use the bracket operator <c>[</c> to re-order each column in the data frame.</p></li>
      
      <li>
      <p>The <c>na_example</c> vector represents a series of counts. You can quickly examine the object using:</p>
      
      <program language="r"><input>
      str(na_example)
      </input></program>
      
      <p>However, when we compute the average with the function <c>mean</c>, we obtain an <c>NA</c>:</p>
      
      <program language="r"><input>
      mean(na_example)
      </input></program>
      
      <p>The <c>is.na</c> function returns a logical vector that tells us which entries are <c>NA</c>. Assign this logical vector to an object called <c>ind</c> and determine how many <c>NA</c>s does <c>na_example</c> have.</p>
      </li>
      
      <li><p>Now compute the average again, but only for the entries that are not <c>NA</c>. Hint: remember the <c>!</c> operator, which turns <c>FALSE</c> into <c>TRUE</c> and vice versa.</p></li>
      
      <li>
      <p>In exercises 28 we created the <c>temp</c> data frame:</p>
      
      <program language="r"><input>
      temp &lt;- c(35, 88, 42, 84, 81, 30)
      city &lt;- c("Beijing", "Lagos", "Paris", "Rio de Janeiro", 
                "San Juan", "Toronto")
      city_temps &lt;- data.frame(name = city, temperature = temp)
      </input></program>
      
      <p>Remake the data frame using the code above, but add a line that converts the temperature from Fahrenheit to Celsius. The conversion is <m>C = \frac{5}{9} \times (F - 32)</m>.</p>
      </li>
      
      <li><p>What is the following sum <m>1+1/2^2 + 1/3^2 + \dots 1/100^2</m>? Hint: thanks to Euler, we know it should be close to <m>\pi^2/6</m>.</p></li>
      
      <li><p>Compute the per 100,000 murder rate for each state and store it in the object <c>murder_rate</c>. Then compute the average murder rate for the US using the function <c>mean</c>. What is the average?</p></li>
      
      <li>
      <p>For remaining exercises 35-42, start by loading the library and data.</p>
      
      <program language="r"><input>
      library(dslabs)
      </input></program>
      
      <p>Compute the per 100,000 murder rate for each state and store it in an object called <c>murder_rate</c>. Then use logical operators to create a logical vector named <c>low</c> that tells us which entries of <c>murder_rate</c> are lower than 1.</p>
      </li>
      
      <li><p>Now use the results from the previous exercise and the function <c>which</c> to determine the indices of <c>murder_rate</c> associated with values lower than 1.</p></li>
      
      <li><p>Use the results from the previous exercise to report the names of the states with murder rates lower than 1.</p></li>
      
      <li><p>Now extend the code from the exercise to report the states in the Northeast with murder rates lower than 1. Hint: use the previously defined logical vector <c>low</c> and the logical operator <c>&amp;</c>.</p></li>
      
      <li><p>In a previous exercise we computed the murder rate for each state and the average of these numbers. How many states are below the average?</p></li>
      
      <li><p>Use the match function to identify the states with abbreviations AK, MI, and IA. Hint: start by defining an index of the entries of <c>murders$abb</c> that match the three abbreviations, then use the <c>[</c> operator to extract the states.</p></li>
      
      <li><p>Use the <c>%in%</c> operator to create a logical vector that answers the question: which of the following are actual abbreviations: MA, ME, MI, MO, MU?</p></li>
      
      <li><p>Extend the code you used in exercise 41 to report the one entry that is <alert>not</alert> an actual abbreviation. Hint: use the <c>!</c> operator, which turns <c>FALSE</c> into <c>TRUE</c> and vice versa, then <c>which</c> to obtain an index.</p></li>
      
      <li>
      <p>We made a plot of total murders versus population and noted a strong relationship. Not surprisingly, states with larger populations had more murders.</p>
      
      <program language="r"><input>
      population_in_millions &lt;- murders$population/10^6
      total_gun_murders &lt;- murders$total
      plot(population_in_millions, total_gun_murders)
      </input></program>
      
      <p>Keep in mind that many states have populations below 5 million and are bunched up. We may gain further insights from making this plot in the log scale. Transform the variables using the <c>log10</c> transformation and then plot them.</p>
      </li>
      
      <li><p>Create a histogram of the state populations.</p></li>
      
      <li><p>Generate boxplots of the state populations by region.</p></li>
      
      </ol>
      
      </section>
      
      </chapter>

      <chapter xml:id="ch-programming-basics">
        <title>Programming basics</title>
        
        <p>We teach R because it greatly facilitates data analysis, the main topic of this book. By coding in R, we can efficiently perform exploratory data analysis, build data analysis pipelines, and prepare data visualization to communicate results. However, R is not just a data analysis environment but a programming language. Advanced R programmers can develop complex packages and even improve R itself, but we do not cover advanced programming in this book. Nonetheless, in this section, we introduce three key programming concepts: conditional expressions, for-loops, and functions. These are not just key building blocks for advanced programming, but are sometimes useful during data analysis. We also note that there are several functions that are widely used to program in R but that we will not cover in this book. These include <c>split</c>, <c>cut</c>, <c>do.call</c>, and <c>Reduce</c>. These are worth learning if you plan to become an expert R programmer.</p>
        
        <section xml:id="sec-conditionals">
          <title>Conditional expressions</title>
          
          <p>Conditional expressions are one of the basic features of programming. They are used for what is called <em>flow control</em>. The most common conditional expression is the if-else statement. In R, we can actually perform quite a bit of data analysis without conditionals. However, they do come up occasionally, and you will need them once you start writing your own functions and packages.</p>
          
          <p>Here is a very simple example showing the general structure of an if-else statement. The basic idea is to print the reciprocal of <c>a</c> unless <c>a</c> is 0:</p>
          
          <program language="r">
            <input>
a &lt;- 0

if (a != 0) {
  print(1/a)
} else{
  print("No reciprocal for 0.")
}
            </input>
          </program>
          
          <p>Let's look at one more example using the US murders data frame:</p>
          
          <program language="r">
            <input>
library(dslabs)
murder_rate &lt;- murders$total / murders$population*100000
            </input>
          </program>
          
          <p>Here is a very simple example that tells us the state with the lowest murder rate if it is lower than 0.5 per 100,000. The if-else statement protects us from the case in which no state satisfies the condition.</p>
          
          <program language="r">
            <input>
ind &lt;- which.min(murder_rate)

if (murder_rate[ind] &lt; 0.5) {
  print(murders$state[ind]) 
} else{
  print("No state has murder rate that low")
}
            </input>
          </program>
          
          <p>If we try it again with a rate of 0.25, we get a different answer:</p>
          
          <program language="r">
            <input>
if (murder_rate[ind] &lt; 0.25) {
  print(murders$state[ind]) 
} else{
  print("No state has a murder rate that low.")
}
            </input>
          </program>
          
          <p>A related function that is very useful is <c>ifelse</c>. This function takes three arguments: a logical and two possible answers. If the logical is <c>TRUE</c>, the value in the second argument is returned and if <c>FALSE</c>, the value in the third argument is returned. Here is an example:</p>
          
          <program language="r">
            <input>
a &lt;- 0
ifelse(a &gt; 0, 1/a, NA)
            </input>
          </program>
          
          <p>The function is particularly useful because it works on vectors. It examines each entry of the logical vector and returns elements from the vector provided in the second argument, if the entry is <c>TRUE</c>, or elements from the vector provided in the third argument, if the entry is <c>FALSE</c>.</p>
          
          <program language="r">
            <input>
a &lt;- c(0, 1, 2, -4, 5)
result &lt;- ifelse(a &gt; 0, 1/a, NA)
            </input>
          </program>
          
          <p>Here is an example of how this function can be readily used to replace all the missing values in a vector with zeros:</p>
          
          <program language="r">
            <input>
no_nas &lt;- ifelse(is.na(na_example), 0, na_example) 
sum(is.na(no_nas))
            </input>
          </program>
          
          <p>Two other useful functions are <c>any</c> and <c>all</c>. The <c>any</c> function takes a vector of logicals and returns <c>TRUE</c> if any of the entries is <c>TRUE</c>. The <c>all</c> function takes a vector of logicals and returns <c>TRUE</c> if all of the entries are <c>TRUE</c>. Here is an example:</p>
          
          <program language="r">
            <input>
z &lt;- c(TRUE, TRUE, FALSE)
any(z)
all(z)
            </input>
          </program>
          
          <note>
            <p>You are ready to do exercises 1-3.</p>
          </note>
          
        </section>
        
        <section xml:id="sec-defining-functions">
          <title>Defining functions</title>
          
          <p>As you become more experienced, you will find yourself needing to perform the same operations over and over. A simple example is computing averages. We can compute the average of a vector <c>x</c> using the <c>sum</c> and <c>length</c> functions: <c>sum(x)/length(x)</c>. Because we do this repeatedly, it is much more efficient to write a function that performs this operation. This particular operation is so common that someone already wrote the <c>mean</c> function and it is included in base R. However, you will encounter situations in which the function does not already exist, so R permits you to write your own. A simple version of a function that computes the average can be defined like this:</p>
          
          <program language="r">
            <input>
avg &lt;- function(x){
  s &lt;- sum(x)
  n &lt;- length(x)
  s/n
}
            </input>
          </program>
          
          <p>Now <c>avg</c> is a function that computes the mean:</p>
          
          <program language="r">
            <input>
x &lt;- 1:100
identical(mean(x), avg(x))
            </input>
          </program>
          
          <p>Notice that variables defined inside a function are not saved in the workspace. So while we use <c>s</c> and <c>n</c> when we call <c>avg</c>, the values are created and changed only during the call. Here is an illustrative example:</p>
          
          <program language="r">
            <input>
s &lt;- 3
avg(1:10)
s
            </input>
          </program>
          
          <p>Note how <c>s</c> is still 3 after we call <c>avg</c>.</p>
          
          <p>In general, functions are objects, so we assign them to variable names with <c>&lt;-</c>. The function <c>function</c> tells R you are about to define a function. The general form of a function definition looks like this:</p>
          
          <program language="r">
            <input>
my_function &lt;- function(VARIABLE_NAME){
  perform operations on VARIABLE_NAME and calculate VALUE
  VALUE
}
            </input>
          </program>
          
          <p>The functions you define can have multiple arguments as well as default values. For example, we can define a function that computes either the arithmetic or geometric average depending on a user defined variable like this:</p>
          
          <program language="r">
            <input>
avg &lt;- function(x, arithmetic = TRUE){
  n &lt;- length(x)
  ifelse(arithmetic, sum(x)/n, prod(x)^(1/n))
}
            </input>
          </program>
          
          <p>We will learn more about how to create functions through experience as we face more complex tasks.</p>
          
          <note>
            <p>You are ready to do exercises 4-7.</p>
          </note>
          
        </section>
        
        <section xml:id="sec-namespaces">
          <title>Namespaces</title>
          
          <p>Once you start becoming more of an R expert user, you will likely need to load several add-on packages for some of your analysis. Once you start doing this, it is likely that two packages use the same name for two different functions. And often these functions do completely different things. In fact, you have already encountered this because both <alert>dplyr</alert> and the R-base <alert>stats</alert> package define a <c>filter</c> function. There are five other examples in <alert>dplyr</alert>. We know this because when we first load <alert>dplyr</alert> we see the following message:</p>
          
          <pre>
The following objects are masked from 'package:stats':

    filter, lag

The following objects are masked from 'package:base':

    intersect, setdiff, setequal, union
          </pre>
          
          <p>Now when we type <c>filter</c> it uses the <alert>dplyr</alert> one. But what if we want to use the <alert>stats</alert> version?</p>
          
          <p>These functions live in different <em>namespaces</em>. R will follow a certain order when searching for a function in these <em>namespaces</em>. You can see the order by typing:</p>
          
          <program language="r">
            <input>
search()
            </input>
          </program>
          
          <p>The first entry in this list is the global environment which includes all the objects you define.</p>
          
          <p>So what if we want to use the <alert>stats</alert> <c>filter</c> instead of the <alert>dplyr</alert> filter but <alert>dplyr</alert> appears first in the search list? You can force the use of a specific namespace by using double colons (<c>::</c>) like this:</p>
          
          <program language="r">
            <input>
stats::filter
            </input>
          </program>
          
          <p>If we want to be absolutely sure that we use the <alert>dplyr</alert> <c>filter</c>, we can use</p>
          
          <program language="r">
            <input>
dplyr::filter
            </input>
          </program>
          
          <p>Also note that if we want to use a function in a package without loading the entire package, we can use the double colon as well.</p>
          
          <note>
            <title>Tip</title>
            <p>If you want to see all the packages that have function called, for example <c>filter</c>, you can use double questions marks: <c>??filter</c>.</p>
          </note>
          
          <p>For more on this more advanced topic we recommend the R packages book<fn><url href="http://r-pkgs.had.co.nz/namespace.html"/></fn>.</p>
          
        </section>
        
        <section xml:id="sec-for-loops">
          <title>For-loops</title>
          
          <p>The formula for the sum of the series <m>1+2+\dots+n</m> is <m>S_n = n(n+1)/2</m>. What if we weren't sure that was the right function? How could we check? Using what we learned about functions we can create one that computes <m>S_n</m>:</p>
          
          <program language="r">
            <input>
compute_s_n &lt;- function(n) { 
  sum(1:n)
}
            </input>
          </program>
          
          <p>How can we compute <m>S_n</m> for various values of <m>n</m>, say <m>n=1,\dots,25</m>? Do we write 25 lines of code calling <c>compute_s_n</c>? No, that is what for-loops are for in programming. In this case, we are performing exactly the same task over and over, and the only thing that is changing is the value of <m>n</m>. For-loops let us define the range that our variable takes (in our example <m>n=1,\dots,10</m>), then change the value and evaluate expression as you <em>loop</em>.</p>
          
          <p>Perhaps the simplest example of a for-loop is this useless piece of code:</p>
          
          <program language="r">
            <input>
for (i in 1:5) {
  print(i)
}
            </input>
          </program>
          
          <p>Here is the for-loop we would write for our <m>S_n</m> example:</p>
          
          <program language="r">
            <input>
m &lt;- 25
s_n &lt;- vector(length = m) # create an empty vector
for (n in 1:m) {
  s_n[n] &lt;- compute_s_n(n)
}
            </input>
          </program>
          
          <p>In each iteration <m>n=1</m>, <m>n=2</m>, etc..., we compute <m>S_n</m> and store it in the <m>n</m>th entry of <c>s_n</c>.</p>
          
          <p>Now we can create a plot to search for a pattern:</p>
          
          <program language="r">
            <input>
n &lt;- 1:m
plot(n, s_n)
            </input>
          </program>
          
          <p>If you noticed that it appears to be a quadratic, you are on the right track because the formula is <m>n(n+1)/2</m>.</p>
          
        </section>
        
        <section xml:id="sec-vectorization">
          <title>Vectorization and functionals</title>
          
          <p>Although for-loops are an important concept to understand, in R we rarely use them. As you learn more R, you will realize that <em>vectorization</em> is preferred over for-loops since it results in shorter and clearer code. We already saw examples in the Vector Arithmetic section. A <em>vectorized</em> function is a function that will apply the same operation on each of the vectors.</p>
          
          <program language="r">
            <input>
x &lt;- 1:10
sqrt(x)
y &lt;- 1:10
x*y
            </input>
          </program>
          
          <p>To make this calculation, there is no need for for-loops. However, not all functions work this way. For instance, the function we just wrote, <c>compute_s_n</c>, does not work element-wise since it is expecting a scalar. This piece of code does not run the function on each entry of <c>n</c>:</p>
          
          <program language="r">
            <input>
n &lt;- 1:25
compute_s_n(n)
            </input>
          </program>
          
          <p><em>Functionals</em> are functions that help us apply the same function to each entry in a vector, matrix, data frame, or list. Here we cover the functional that operates on numeric, logical, and character vectors: <c>sapply</c>.</p>
          
          <p>The function <c>sapply</c> permits us to perform element-wise operations on any function. Here is how it works:</p>
          
          <program language="r">
            <input>
x &lt;- 1:10
sapply(x, sqrt)
            </input>
          </program>
          
          <p>Each element of <c>x</c> is passed on to the function <c>sqrt</c> and the result is returned. These results are concatenated. In this case, the result is a vector of the same length as the original <c>x</c>. This implies that the for-loop above can be written as follows:</p>
          
          <program language="r">
            <input>
n &lt;- 1:25
s_n &lt;- sapply(n, compute_s_n)
            </input>
          </program>
          
          <p>Other functionals are <c>apply</c>, <c>lapply</c>, <c>tapply</c>, <c>mapply</c>, <c>vapply</c>, and <c>replicate</c>. We mostly use <c>sapply</c>, <c>apply</c>, and <c>replicate</c> in this book, but we recommend familiarizing yourselves with the others as they can be very useful.</p>
          
          <note>
            <p>You are ready to do exercises 8-11.</p>
          </note>
          
        </section>
        
        <section xml:id="sec-programming-basics-exercises">
          <title>Exercises</title>
          
          <ol>
            <li>
              <p>What will this conditional expression return?</p>
              <program language="r">
                <input>
x &lt;- c(1,2,-3,4)

if(all(x&gt;0)){
  print("All Postives")
} else{
  print("Not all positives")
}
                </input>
              </program>
            </li>
            
            <li>
              <p>Which of the following expressions is always <c>FALSE</c> when at least one entry of a logical vector <c>x</c> is TRUE?</p>
              <ol marker="a">
                <li><c>all(x)</c></li>
                <li><c>any(x)</c></li>
                <li><c>any(!x)</c></li>
                <li><c>all(!x)</c></li>
              </ol>
            </li>
            
            <li><p>The function <c>nchar</c> tells you how many characters long a character vector is. Write a line of code that assigns to the object <c>new_names</c> the state abbreviation when the state name is longer than 8 characters.</p></li>
            
            <li><p>Create a function <c>sum_n</c> that for any given value, say <m>n</m>, computes the sum of the integers from 1 to n (inclusive). Use the function to determine the sum of integers from 1 to 5,000.</p></li>
            
            <li><p>Create a function <c>altman_plot</c> that takes two arguments, <c>x</c> and <c>y</c>, and plots the difference against the sum.</p></li>
            
            <li>
              <p>After running the code below, what is the value of <c>x</c>?</p>
              <program language="r">
                <input>
x &lt;- 3
my_func &lt;- function(y){
  x &lt;- 5
  y+5
}
                </input>
              </program>
            </li>
            
            <li><p>Write a function <c>compute_s_n</c> that for any given <m>n</m> computes the sum <m>S_n = 1^2 + 2^2 + 3^2 + \dots n^2</m>. Report the value of the sum when <m>n=10</m>.</p></li>
            
            <li><p>Define an empty numerical vector <c>s_n</c> of size 25 using <c>s_n &lt;- vector("numeric", 25)</c> and store in the results of <m>S_1, S_2, \dots S_{25}</m> using a for-loop.</p></li>
            
            <li><p>Repeat exercise 8, but this time use <c>sapply</c>.</p></li>
            
            <li><p>Plot <m>S_n</m> versus <m>n</m>. Use points defined by <m>n=1,\dots,25</m>.</p></li>
            
            <li><p>Confirm that the formula for this sum is <m>S_n= n(n+1)(2n+1)/6</m>.</p></li>
          </ol>
          
        </section>
        
      </chapter>

      <chapter xml:id="ch-tidyverse">
        <title>The tidyverse</title>
        
        <p>Up to now we have been manipulating vectors by reordering and subsetting them through indexing. However, once we start more advanced analyses, the preferred unit for data storage is not the vector but the data frame. In this chapter we learn to work directly with data frames, which greatly facilitate the organization of information. We will be using data frames for the majority of this book. We will focus on a specific data format referred to as <em>tidy</em> and on specific collection of packages that are particularly helpful for working with <em>tidy</em> data referred to as the <em>tidyverse</em>.</p>
        
        <p>We can load all the tidyverse packages at once by installing and loading the <alert>tidyverse</alert> package:</p>
        
        <program language="r">
          <input>
library(tidyverse)
          </input>
        </program>
        
        <p>We will learn how to implement the tidyverse approach throughout the book, but before delving into the details, in this chapter we introduce some of the most widely used tidyverse functionality, starting with the <alert>dplyr</alert> package for manipulating data frames and the <alert>purrr</alert> package for working with functions. Note that the tidyverse also includes a graphing package, <alert>ggplot2</alert>, which we introduce later in the Data Visualization part of the book, the <alert>readr</alert> package discussed in the chapter on importing data, and many others. In this chapter, we first introduce the concept of <em>tidy data</em> and then demonstrate how we use the tidyverse to work with data frames in this format.</p>
        
        <section xml:id="sec-tidy-data">
          <title>Tidy data</title>
          
          <p>We say that a data table is in <em>tidy</em> format if each row represents one observation and columns represent the different variables available for each of these observations. The <c>murders</c> dataset is an example of a tidy data frame.</p>
          
          <program language="r">
            <input>
library(dslabs)
head(murders)
            </input>
          </program>
          
          <p>Each row represent a state with each of the five columns providing a different variable related to these states: name, abbreviation, region, population, and total murders.</p>
          
          <p>To see how the same information can be provided in different formats, consider the following example showing fertility rates for two countries across the years. This is a tidy dataset because each row represents one observation with the three variables being country, year, and fertility rate. However, this dataset originally came in another format and was reshaped for the <alert>dslabs</alert> package. Originally, the data was in a wide format where each row included several observations and one of the variables, year, was stored in the header. For the tidyverse packages to be optimally used, data need to be reshaped into <em>tidy</em> format, which you will learn to do in the Data Wrangling part of the book. Until then, we will use example datasets that are already in tidy format.</p>
          
          <p>Although not immediately obvious, as you go through the book you will start to appreciate the advantages of working in a framework in which functions use tidy formats for both inputs and outputs. You will see how this permits the data analyst to focus on more important aspects of the analysis rather than the format of the data.</p>
          
          <note>
            <p>You are ready to do exercises 1-4.</p>
          </note>
          
        </section>
        
        <section xml:id="sec-refining-data-frames">
          <title>Refining data frames</title>
          
          <p>The <alert>dplyr</alert> package from the <alert>tidyverse</alert> introduces functions that perform some of the most common operations when working with data frames and uses names for these functions that are relatively easy to remember. For instance, to change the data table by adding a new column, we use <c>mutate</c>. To filter the data table to a subset of rows, we use <c>filter</c>. Finally, to subset the data by selecting specific columns, we use <c>select</c>.</p>
          
          <subsection xml:id="subsec-adding-columns">
            <title>Adding columns</title>
            
            <p>We want all the necessary information for our analysis to be included in the data frame. The first task is to add the murder rates to our murders data frame. The function <c>mutate</c> takes the data frame as a first argument and the name and values of the variable as a second argument using the convention <c>name = values</c>. So, to add murder rates, we use:</p>
            
            <program language="r">
              <input>
murders &lt;- mutate(murders, rate = total/population*100000)
              </input>
            </program>
            
            <p>Notice that here we used <c>total</c> and <c>population</c> inside the function, which are objects that are <alert>not</alert> defined in our workspace. But why don't we get an error?</p>
            
            <p>This is one of <alert>dplyr</alert>'s main features. Functions in this package, such as <c>mutate</c>, know to look for variables in the data frame provided in the first argument. In the call to mutate above, <c>total</c> will have the values in <c>murders$total</c>. This approach makes the code much more readable.</p>
            
            <p>We can see that the new column is added:</p>
            
            <program language="r">
              <input>
head(murders)
              </input>
            </program>
            
          </subsection>
          
          <subsection xml:id="subsec-row-wise-subsetting">
            <title>Row-wise subsetting</title>
            
            <p>Now suppose that we want to filter the data frame to only show the entries for which the murder rate is lower than 0.71. To do this we use the <c>filter</c> function, which takes the data frame as the first argument and then a conditional statement as the second. Like <c>mutate</c>, we can use the unquoted variable names from <c>murders</c> inside the function and it will know we mean the columns and not objects in the workspace.</p>
            
            <program language="r">
              <input>
filter(murders, rate &lt;= 0.71)
              </input>
            </program>
            
          </subsection>
          
          <subsection xml:id="sec-tidyverse-col-subset">
            <title>Column-wise subsetting</title>
            
            <p>Although our data frame only has six columns, some data frames include hundreds. If we want to view just a few, we can use the <alert>dplyr</alert> <c>select</c> function. In the code below we select three columns, assign this to a new object and then filter the new object:</p>
            
            <program language="r">
              <input>
new_dataframe &lt;- select(murders, state, region, rate)
filter(new_dataframe, rate &lt;= 0.71)
              </input>
            </program>
            
            <p>In the call to <c>select</c>, the first argument <c>murders</c> is an object, but <c>state</c>, <c>region</c>, and <c>rate</c> are variable names.</p>
            
            <p><alert>dplyr</alert> offers a series of helper functions to select columns based on their content. For example, the following code uses the function <c>where</c> to keep only the numeric columns:</p>
            
            <program language="r">
              <input>
new_dataframe &lt;- select(murders, where(is.numeric))
names(new_dataframe)
              </input>
            </program>
            
            <p>The helper functions <c>starts_with</c>, <c>ends_with</c>, <c>contains</c>, <c>matches</c>, and <c>num_range</c> can be used to select columns based on their names. Here is an example showing all the rows that start with <c>r</c>:</p>
            
            <program language="r">
              <input>
new_dataframe &lt;- select(murders, starts_with("r"))
names(new_dataframe)
              </input>
            </program>
            
            <p>The helper function <c>everything</c> selects all columns.</p>
            
          </subsection>
          
          <subsection xml:id="subsec-transforming-variables">
            <title>Transforming variables</title>
            
            <p>The function <c>mutate</c> can also be used to transform variables. For example, the following code takes the log transformation of the population variable:</p>
            
            <program language="r">
              <input>
mutate(murders, population = log10(population))
              </input>
            </program>
            
            <p>Often, we need to apply the same transformation to several variables. The function <c>across</c> facilitates the operation. For example if want to log transform both population and total murders we can use:</p>
            
            <program language="r">
              <input>
mutate(murders, across(c(population, total), log10))
              </input>
            </program>
            
            <p>The helper functions come in handy when using across. An example is if we want to apply the same transformation to all numeric variables:</p>
            
            <program language="r">
              <input>
mutate(murders, across(where(is.numeric), log10))
              </input>
            </program>
            
            <p>or all character variables:</p>
            
            <program language="r">
              <input>
mutate(murders, across(where(is.character), tolower))
              </input>
            </program>
            
            <note>
              <p>You are ready to do exercises 5-11.</p>
            </note>
            
          </subsection>
          
        </section>
        
        <section xml:id="sec-the-pipe">
          <title>The pipe</title>
          
          <p>In R we can perform a series of operations, for example <c>select</c> and then <c>filter</c>, by sending the results of one function to another using what is called the <em>pipe operator</em>: <c>%&gt;%</c>. Since R version 4.1.0, you can also use <c>|&gt;</c>. Some details are included below.</p>
          
          <p>We wrote code in the previous section to show three variables (state, region, rate) for states that have murder rates below 0.71. To do this, we defined the intermediate object <c>new_dataframe</c>. In <alert>dplyr</alert> we can write code that looks more like a description of what we want to do without intermediate objects:</p>
          
          <me>
            \mbox{original data }
            \rightarrow \mbox{ select }
            \rightarrow \mbox{ filter }
          </me>
          
          <p>For such an operation, we can use the pipe <c>|&gt;</c>. The code looks like this:</p>
          
          <program language="r">
            <input>
murders |&gt; select(state, region, rate) |&gt; filter(rate &lt;= 0.71)
            </input>
          </program>
          
          <p>In general, the pipe <em>sends</em> the result of the left side of the pipe to be the first argument of the function on the right side of the pipe. Here is a very simple example:</p>
          
          <program language="r">
            <input>
16 |&gt; sqrt()
            </input>
          </program>
          
          <p>We can continue to pipe values along:</p>
          
          <program language="r">
            <input>
16 |&gt; sqrt() |&gt; log2()
            </input>
          </program>
          
          <p>The above statement is equivalent to <c>log2(sqrt(16))</c>.</p>
          
          <p>Remember that the pipe sends values to the first argument, so we can define other arguments as if the first argument is already defined:</p>
          
          <program language="r">
            <input>
16 |&gt; sqrt() |&gt; log(base = 2)
            </input>
          </program>
          
          <p>Therefore, when using the pipe with data frames and <alert>dplyr</alert>, we no longer need to specify the required first argument since the <alert>dplyr</alert> functions we have described all take the data as the first argument. In the code we wrote:</p>
          
          <program language="r">
            <input>
murders |&gt; select(state, region, rate) |&gt; filter(rate &lt;= 0.71)
            </input>
          </program>
          
          <p><c>murders</c> is the first argument of the <c>select</c> function, and the new data frame (formerly <c>new_dataframe</c>) is the first argument of the <c>filter</c> function.</p>
          
          <p>Note that the pipe works well with functions where the first argument is the input data. Functions in <alert>tidyverse</alert> packages like <alert>dplyr</alert> have this format and can be used easily with the pipe.</p>
          
        </section>
        
        <section xml:id="sec-summarizing-data">
          <title>Summarizing data</title>
          
          <p>An important part of exploratory data analysis is summarizing data. The average and standard deviation are two examples of widely used summary statistics. More informative summaries can often be achieved by first splitting data into groups. In this section, we cover two new <alert>dplyr</alert> verbs that make these computations easier: <c>summarize</c> and <c>group_by</c>. We learn to access resulting values using the <c>pull</c> function.</p>
          
          <subsection xml:id="sec-summarize">
            <title>The summarize function</title>
            
            <p>The <c>summarize</c> function in <alert>dplyr</alert> provides a way to compute summary statistics with intuitive and readable code. We start with a simple example based on heights. The <c>heights</c> dataset includes heights and sex reported by students in an in-class survey.</p>
            
            <program language="r">
              <input>
library(dplyr)
library(dslabs)
              </input>
            </program>
            
            <p>The following code computes the average and standard deviation for females:</p>
            
            <program language="r">
              <input>
s &lt;- heights |&gt; 
  filter(sex == "Female") |&gt;
  summarize(average = mean(height), standard_deviation = sd(height))
s
              </input>
            </program>
            
            <p>This takes our original data frame as input, filters it to keep only females, and then produces a new summarized table with just the average and the standard deviation of heights. We get to choose the names of the columns of the resulting table. For example, above we decided to use <c>average</c> and <c>standard_deviation</c>, but we could have used other names just the same.</p>
            
            <p>Because the resulting table stored in <c>s</c> is a data frame, we can access the components with the accessor <c>$</c>:</p>
            
            <program language="r">
              <input>
s$average
s$standard_deviation
              </input>
            </program>
            
            <p>As with most other <alert>dplyr</alert> functions, <c>summarize</c> is aware of the variable names and we can use them directly. So when inside the call to the <c>summarize</c> function we write <c>mean(height)</c>, the function is accessing the column with the name "height" and then computing the average of the resulting numeric vector. We can compute any other summary that operates on vectors and returns a single value.</p>
            
            <p>For another example of how we can use the <c>summarize</c> function, let's compute the average murder rate for the United States. Remember our data table includes total murders and population size for each state and we have already used <alert>dplyr</alert> to add a murder rate column:</p>
            
            <program language="r">
              <input>
murders &lt;- murders |&gt; mutate(rate = total/population*100000)
              </input>
            </program>
            
            <p>Remember that the US murder rate is <alert>not</alert> the average of the state murder rates:</p>
            
            <program language="r">
              <input>
murders |&gt;
  summarize(rate = mean(rate))
              </input>
            </program>
            
            <p>This is because in the computation above, the small states are given the same weight as the large ones. The US murder rate is the total number of murders in the US divided by the total US population. So the correct computation is:</p>
            
            <program language="r">
              <input>
us_murder_rate &lt;- murders |&gt;
  summarize(rate = sum(total)/sum(population)*100000)
us_murder_rate
              </input>
            </program>
            
            <p>This computation counts larger states proportionally to their size which results in a larger value.</p>
            
          </subsection>
          
          <subsection xml:id="subsec-multiple-summaries">
            <title>Multiple summaries</title>
            
            <p>Suppose we want three summaries from the same variable such as the median, minimum, and maximum heights. We can use <c>summarize</c> like this:</p>
            
            <program language="r">
              <input>
heights |&gt; summarize(median = median(height), min = min(height), max = max(height))
              </input>
            </program>
            
            <p>But we can obtain these three values with just one line using the <c>quantile</c> function: <c>quantile(x, c(0.5, 0, 1))</c> returns the median (50th percentile), the min (0th percentile), and max (100th percentile) of the vector <c>x</c>. Here we can't use <c>summarize</c> because it expects one value per row. Instead we have to use the <c>reframe</c> function:</p>
            
            <program language="r">
              <input>
heights |&gt; reframe(quantiles = quantile(height, c(0.5, 0, 1)))
              </input>
            </program>
            
            <p>However, if we want a column per summary, as the <c>summarize</c> call above, we have to define a function that returns a data frame like this:</p>
            
            <program language="r">
              <input>
median_min_max &lt;- function(x){
  qs &lt;- quantile(x, c(0.5, 0, 1))
  data.frame(median = qs[1], min = qs[2], max = qs[3])
}
              </input>
            </program>
            
            <p>Then we can call <c>summarize</c> as above:</p>
            
            <program language="r">
              <input>
heights |&gt; summarize(median_min_max(height))
              </input>
            </program>
            
          </subsection>
          
          <subsection xml:id="sec-group-by">
            <title>Group then summarize with group_by</title>
            
            <p>A common operation in data exploration is to first split data into groups and then compute summaries for each group. For example, we may want to compute the average and standard deviation for men's and women's heights separately. The <c>group_by</c> function helps us do this.</p>
            
            <p>If we type this:</p>
            
            <program language="r">
              <input>
heights |&gt; group_by(sex)
              </input>
            </program>
            
            <p>The result does not look very different from <c>heights</c>, except we see <c>Groups: sex [2]</c> when we print the object. Although not immediately obvious from its appearance, this is now a special data frame called a <em>grouped data frame</em>, and <alert>dplyr</alert> functions, in particular <c>summarize</c>, will behave differently when acting on this object. Conceptually, you can think of this table as many tables, with the same columns but not necessarily the same number of rows, stacked together in one object. When we summarize the data after grouping, this is what happens:</p>
            
            <program language="r">
              <input>
heights |&gt; 
  group_by(sex) |&gt;
  summarize(average = mean(height), standard_deviation = sd(height))
              </input>
            </program>
            
            <p>The <c>summarize</c> function applies the summarization to each group separately.</p>
            
            <p>For another example, let's compute the median, minimum, and maximum murder rate in the four regions of the country using the <c>median_min_max</c> defined above:</p>
            
            <program language="r">
              <input>
murders |&gt; 
  group_by(region) |&gt;
  summarize(median_min_max(rate))
              </input>
            </program>
            
          </subsection>
          
          <subsection xml:id="subsec-pull">
            <title>Extracting variables with pull</title>
            
            <p>The <c>us_murder_rate</c> object defined earlier represents just one number. Yet we are storing it in a data frame:</p>
            
            <program language="r">
              <input>
class(us_murder_rate)
              </input>
            </program>
            
            <p>since, as most <alert>dplyr</alert> functions, <c>summarize</c> always returns a data frame.</p>
            
            <p>This might be problematic if we want to use this result with functions that require a numeric value. Here we show a useful trick for accessing values stored in data when using pipes: when a data object is piped that object and its columns can be accessed using the <c>pull</c> function. To get a number from the original data table with one additional line of code we can type:</p>
            
            <program language="r">
              <input>
us_murder_rate &lt;- murders |&gt; 
  summarize(rate = sum(total)/sum(population)*100000) |&gt;
  pull(rate)

us_murder_rate
              </input>
            </program>
            
            <p>which is now a numeric:</p>
            
            <program language="r">
              <input>
class(us_murder_rate)
              </input>
            </program>
            
          </subsection>
          
        </section>
        
        <section xml:id="sec-sorting">
          <title>Sorting</title>
          
          <p>When examining a dataset, it is often convenient to sort the data frame by the different columns. We know about the <c>order</c> and <c>sort</c> function, but for ordering entire data frames, the <alert>dplyr</alert> function <c>arrange</c> is useful. For example, here we order the states by population size:</p>
          
          <program language="r">
            <input>
murders |&gt; arrange(population) |&gt; head()
            </input>
          </program>
          
          <p>With <c>arrange</c> we get to decide which column to sort by. To see the states sorted by murder rates, for example, we would use <c>arrange(rate)</c> instead.</p>
          
          <p>Note that the default behavior is to order in ascending order. In <alert>dplyr</alert>, the function <c>desc</c> transforms a vector so that it is in descending order. To sort the data frame by murder rates in descending order, we can type:</p>
          
          <program language="r">
            <input>
murders |&gt; arrange(desc(rate))
            </input>
          </program>
          
          <subsection xml:id="subsec-nested-sorting">
            <title>Nested sorting</title>
            
            <p>If we are ordering by a column with ties, we can use a second column to break the tie. Similarly, a third column can be used to break ties between first and second and so on. Here we order by <c>region</c>, then within region we order by murder rate:</p>
            
            <program language="r">
              <input>
murders |&gt; 
  arrange(region, rate) |&gt; 
  head()
              </input>
            </program>
            
          </subsection>
          
          <subsection xml:id="subsec-top-n">
            <title>The top n</title>
            
            <p>In the code above, we have used the function <c>head</c> to avoid having the page fill up with the entire dataset. For instance, using <c>arrange(desc(rate))</c> followed by <c>head</c> would show the 6 states with the largest murder rates, in order. Instead, to view a specific number of observations with the highest murder rates, we can use the <c>slice_max</c> function. This function takes a data frame as it's first argument, the number of rows to show in the second, and the variable to filter by in the third. Here is an example of how to see the top 5 rows:</p>
            
            <program language="r">
              <input>
murders |&gt; slice_max(rate, n = 5)
              </input>
            </program>
            
            <p>The function <c>slice_min</c> does the same, but for the smallest values.</p>
            
            <note>
              <p>You are ready to do exercises 12-19.</p>
            </note>
            
          </subsection>
          
        </section>
        
        <section xml:id="sec-tibbles">
          <title>Tibbles</title>
          
          <p>To work with the tidyverse, data must be stored in data frames. We introduced the data frame in an earlier chapter and have been using the <c>murders</c> data frame throughout the book. In a previous section we introduced the <c>group_by</c> function, which permits stratifying data before computing summary statistics. But where is the group information stored in the data frame?</p>
          
          <program language="r">
            <input>
murders |&gt; group_by(region)
            </input>
          </program>
          
          <p>Notice that there are no columns with this information. But, if you look closely at the output above, you see the line <c>A tibble</c> followed by dimensions. We can learn the class of the returned object using:</p>
          
          <program language="r">
            <input>
murders |&gt; group_by(region) |&gt; class()
            </input>
          </program>
          
          <p>The <c>tbl</c>, pronounced "tibble", is a special kind of data frame. The functions <c>group_by</c> and <c>summarize</c> always return this type of data frame. The <c>group_by</c> function returns a special kind of <c>tbl</c>, the <c>grouped_df</c>. We will say more about these later. For consistency, the <alert>dplyr</alert> manipulation verbs (<c>select</c>, <c>filter</c>, <c>mutate</c>, and <c>arrange</c>) preserve the class of the input: if they receive a regular data frame they return a regular data frame, while if they receive a tibble they return a tibble. But tibbles are the preferred format in the tidyverse and as a result tidyverse functions that produce a data frame from scratch return a tibble. For example, in a later chapter we will see that tidyverse functions used to import data create tibbles.</p>
          
          <subsection xml:id="subsec-tibbles-vs-data-frames">
            <title>Tibbles versus data frames</title>
            
            <p>Tibbles are very similar to data frames. In fact, you can think of them as a modern version of data frames. Nonetheless there are some important differences which we describe next.</p>
            
            <p><alert>(1) Tibbles display better</alert></p>
            
            <p>The print method for tibbles is more readable than that of a data frame. To see this, compare the outputs of typing <c>murders</c> and the output of murders if we convert it to a tibble. We can do this using <c>as_tibble(murders)</c>. If using RStudio, output for a tibble adjusts to your window size. To see this, change the width of your R console and notice how more/less columns are shown.</p>
            
            <p>If you subset the columns of a data frame, you may get back an object that is not a data frame, such as a vector or scalar. For example:</p>
            
            <program language="r">
              <input>
class(murders[,4])
              </input>
            </program>
            
            <p>is not a data frame. With tibbles this does not happen:</p>
            
            <program language="r">
              <input>
class(as_tibble(murders)[,4])
              </input>
            </program>
            
            <p>This is useful in the tidyverse since functions require data frames as input.</p>
            
            <p>With tibbles, if you want to access the vector that defines a column, and not get back a data frame, you need to use the accessor <c>$</c>:</p>
            
            <program language="r">
              <input>
class(as_tibble(murders)$population)
              </input>
            </program>
            
            <p>A related feature is that tibbles will give you a warning if you try to access a column that does not exist. If we accidentally write <c>Population</c> instead of <c>population</c> this:</p>
            
            <program language="r">
              <input>
murders$Population
              </input>
            </program>
            
            <p>returns a <c>NULL</c> with no warning, which can make it harder to debug. In contrast, if we try this with a tibble we get an informative warning:</p>
            
            <program language="r">
              <input>
as_tibble(murders)$Population
              </input>
            </program>
            
            <p><alert>(2) Tibbles can have complex entries</alert></p>
            
            <p>While data frame columns need to be vectors of numbers, strings, or logical values, tibbles can have more complex objects, such as lists or functions. Also, we can create tibbles with functions:</p>
            
            <program language="r">
              <input>
tibble(id = c(1, 2, 3), func = c(mean, median, sd))
              </input>
            </program>
            
            <p><alert>(3) Tibbles can be grouped</alert></p>
            
            <p>The function <c>group_by</c> returns a special kind of tibble: a grouped tibble. This class stores information that lets you know which rows are in which groups. The tidyverse functions, in particular the <c>summarize</c> function, are aware of the group information.</p>
            
          </subsection>
          
          <subsection xml:id="subsec-creating-tibbles">
            <title>Creating tibbles</title>
            
            <p>It is sometimes useful for us to create our own data frames. To create a data frame in the tibble format, you can do this by using the <c>tibble</c> function.</p>
            
            <program language="r">
              <input>
grades &lt;- tibble(names = c("John", "Juan", "Jean", "Yao"), 
                     exam_1 = c(95, 80, 90, 85), 
                     exam_2 = c(90, 85, 85, 90))
              </input>
            </program>
            
            <p>Note that base R (without packages loaded) has the <c>data.frame</c> function that can be used to create a regular data frame rather than a tibble.</p>
            
            <program language="r">
              <input>
grades &lt;- data.frame(names = c("John", "Juan", "Jean", "Yao"), 
                     exam_1 = c(95, 80, 90, 85), 
                     exam_2 = c(90, 85, 85, 90))
              </input>
            </program>
            
            <p>To convert a regular data frame to a tibble, you can use the <c>as_tibble</c> function.</p>
            
            <program language="r">
              <input>
as_tibble(grades) |&gt; class()
              </input>
            </program>
            
          </subsection>
          
        </section>
        
        <section xml:id="sec-the-placeholder">
          <title>The placeholder</title>
          
          <p>One of the advantages of using the pipe <c>|&gt;</c> is that we do not have to keep naming new objects as we manipulate the data frame. The object on the left-hand side of the pipe is used as the first argument of the function on the right-hand side of the pipe. But what if we want to pass it as argument to the right-hand side function that is not the first? The answer is the placeholder operator <c>_</c> (for the <c>%&gt;%</c> pipe the placeholder is <c>.</c>). Below is a simple example that passes the <c>base</c> argument to the <c>log</c> function. The following three are equivalent:</p>
          
          <program language="r">
            <input>
log(8, base = 2)
2 |&gt; log(8, base = _)
2 %&gt;% log(8, base = .)
            </input>
          </program>
          
        </section>
        
        <section xml:id="sec-purrr-package">
          <title>The purrr package</title>
          
          <p>In an earlier section we learned about the <c>sapply</c> function, which permitted us to apply the same function to each element of a vector. We constructed a function and used <c>sapply</c> to compute the sum of the first <c>n</c> integers for several values of <c>n</c> like this:</p>
          
          <program language="r">
            <input>
compute_s_n &lt;- function(n) {
  sum(1:n)
}
n &lt;- 1:25
s_n &lt;- sapply(n, compute_s_n)
            </input>
          </program>
          
          <p>This type of operation, applying the same function or procedure to elements of an object, is quite common in data analysis. The <alert>purrr</alert> package includes functions similar to <c>sapply</c> but that better interact with other tidyverse functions. The main advantage is that we can better control the output type of functions. In contrast, <c>sapply</c> can return several different object types; for example, we might expect a numeric result from a line of code, but <c>sapply</c> might convert our result to character under some circumstances. <alert>purrr</alert> functions will never do this: they will return objects of a specified type or return an error if this is not possible.</p>
          
          <p>The first <alert>purrr</alert> function we will learn is <c>map</c>, which works very similar to <c>sapply</c> but always, without exception, returns a list:</p>
          
          <program language="r">
            <input>
library(purrr)
s_n &lt;- map(n, compute_s_n)
class(s_n)
            </input>
          </program>
          
          <p>If we want a numeric vector, we can instead use <c>map_dbl</c> which always returns a vector of numeric values.</p>
          
          <program language="r">
            <input>
s_n &lt;- map_dbl(n, compute_s_n)
class(s_n)
            </input>
          </program>
          
          <p>This produces the same results as the <c>sapply</c> call shown above.</p>
          
          <p>A particularly useful <alert>purrr</alert> function for interacting with the rest of the tidyverse is <c>map_df</c>, which always returns a tibble data frame. However, the function being called needs to return a vector or a list with names. For this reason, the following code would result in an error:</p>
          
          <program language="r">
            <input>
s_n &lt;- map_df(n, compute_s_n)
            </input>
          </program>
          
          <p>The function needs to return a data frame to make this work:</p>
          
          <program language="r">
            <input>
compute_s_n &lt;- function(n) {
  tibble(sum = sum(1:n))
}
s_n &lt;- map_df(n, compute_s_n)
            </input>
          </program>
          
        </section>
        
        <section xml:id="sec-tidyverse-conditionals">
          <title>Tidyverse conditionals</title>
          
          <p>A typical data analysis will often involve one or more conditional operations. In an earlier chapter we described the <c>ifelse</c> function, which we will use extensively in this book. In this section we present two <alert>dplyr</alert> functions that provide further functionality for performing conditional operations.</p>
          
          <subsection xml:id="subsec-case-when">
            <title>case_when</title>
            
            <p>The <c>case_when</c> function is useful for vectorizing conditional statements. It is similar to <c>ifelse</c> but can output any number of values, as opposed to just <c>TRUE</c> or <c>FALSE</c>. Here is an example splitting numbers into negative, positive, and 0:</p>
            
            <program language="r">
              <input>
x &lt;- c(-2, -1, 0, 1, 2)
case_when(x &lt; 0 ~ "Negative", 
          x &gt; 0 ~ "Positive", 
          TRUE  ~ "Zero")
              </input>
            </program>
            
            <p>A common use for this function is to define categorical variables based on existing variables. For example, suppose we want to compare the murder rates in four groups of states: <em>New England</em>, <em>West Coast</em>, <em>South</em>, and <em>other</em>. For each state, we need to ask if it is in New England, if it is not we ask if it is in the West Coast, if not we ask if it is in the South, and if not we assign <em>other</em>. Here is how we use <c>case_when</c> to do this:</p>
            
            <program language="r">
              <input>
murders |&gt; 
  mutate(group = case_when(
    abb %in% c("ME", "NH", "VT", "MA", "RI", "CT") ~ "New England",
    abb %in% c("WA", "OR", "CA") ~ "West Coast",
    region == "South" ~ "South",
    TRUE ~ "Other")) |&gt;
  group_by(group) |&gt;
  summarize(rate = sum(total)/sum(population)*10^5)
              </input>
            </program>
            
          </subsection>
          
          <subsection xml:id="subsec-between">
            <title>between</title>
            
            <p>A common operation in data analysis is to determine if a value falls inside an interval. We can check this using conditionals. For example, to check if the elements of a vector <c>x</c> are between <c>a</c> and <c>b</c> we can type</p>
            
            <program language="r">
              <input>
x &gt;= a &amp; x &lt;= b
              </input>
            </program>
            
            <p>However, this can become cumbersome, especially within the tidyverse approach. The <c>between</c> function performs the same operation.</p>
            
            <program language="r">
              <input>
between(x, a, b)
              </input>
            </program>
            
          </subsection>
          
        </section>
        
        <section xml:id="sec-tidyverse-exercises">
          <title>Exercises</title>
          
          <ol>
            <li>
              <p>Examine the built-in dataset <c>co2</c>. Which of the following is true:</p>
              <ol marker="a">
                <li><c>co2</c> is tidy data: it has one year for each row.</li>
                <li><c>co2</c> is not tidy: we need at least one column with a character vector.</li>
                <li><c>co2</c> is not tidy: it is a matrix instead of a data frame.</li>
                <li><c>co2</c> is not tidy: to be tidy we would have to wrangle it to have three columns (year, month and value), then each co2 observation would have a row.</li>
              </ol>
            </li>
            
            <li>
              <p>Examine the built-in dataset <c>ChickWeight</c>. Which of the following is true:</p>
              <ol marker="a">
                <li><c>ChickWeight</c> is not tidy: each chick has more than one row.</li>
                <li><c>ChickWeight</c> is tidy: each observation (a weight) is represented by one row. The chick from which this measurement came is one of the variables.</li>
                <li><c>ChickWeight</c> is not tidy: we are missing the year column.</li>
                <li><c>ChickWeight</c> is tidy: it is stored in a data frame.</li>
              </ol>
            </li>
            
            <li>
              <p>Examine the built-in dataset <c>BOD</c>. Which of the following is true:</p>
              <ol marker="a">
                <li><c>BOD</c> is not tidy: it only has six rows.</li>
                <li><c>BOD</c> is not tidy: the first column is just an index.</li>
                <li><c>BOD</c> is tidy: each row is an observation with two values (time and demand)</li>
                <li><c>BOD</c> is tidy: all small datasets are tidy by definition.</li>
              </ol>
            </li>
            
            <li>
              <p>Which of the following built-in datasets is tidy (you can pick more than one):</p>
              <ol marker="a">
                <li><c>BJsales</c></li>
                <li><c>EuStockMarkets</c></li>
                <li><c>DNase</c></li>
                <li><c>Formaldehyde</c></li>
                <li><c>Orange</c></li>
                <li><c>UCBAdmissions</c></li>
              </ol>
            </li>
            
            <li>
              <p>Load the <alert>dplyr</alert> package and the murders dataset.</p>
              <program language="r">
                <input>
library(dplyr)
library(dslabs)
                </input>
              </program>
              <p>Use the function <c>mutate</c> to add a murders column named <c>rate</c> with the per 100,000 murder rate. Make sure you redefine <c>murders</c> so we can keep using this variable.</p>
            </li>
            
            <li><p>If <c>rank(x)</c> gives you the ranks of <c>x</c> from lowest to highest, <c>rank(-x)</c> gives you the ranks from highest to lowest. Use the function <c>mutate</c> to add a column <c>rank</c> containing the rank of murder rate from highest to lowest. Make sure you redefine <c>murders</c> so we can keep using this variable.</p></li>
            
            <li>
              <p>With <alert>dplyr</alert>, we can use <c>select</c> to show only certain columns. For example, with this code we would only show the states and population sizes:</p>
              <program language="r">
                <input>
select(murders, state, population)
                </input>
              </program>
              <p>Use <c>select</c> to show the state names and abbreviations in <c>murders</c>. Do not redefine <c>murders</c>, just show the results.</p>
            </li>
            
            <li>
              <p>The <alert>dplyr</alert> function <c>filter</c> is used to choose specific rows of the data frame to keep. Unlike <c>select</c> which is for columns, <c>filter</c> is for rows. For example, you can show just the New York row like this:</p>
              <program language="r">
                <input>
filter(murders, state == "New York")
                </input>
              </program>
              <p>Use <c>filter</c> to show the top 5 states with the highest murder rates. From here on, do not change the murders dataset, just show the result. Remember that you can filter based on the <c>rank</c> column.</p>
            </li>
            
            <li>
              <p>We can remove rows using the <c>!=</c> operator. For example, to remove Florida, we would do this:</p>
              <program language="r">
                <input>
no_florida &lt;- filter(murders, state != "Florida")
                </input>
              </program>
              <p>Create a new data frame called <c>no_south</c> that removes states from the South region. How many states are in this category? You can use the function <c>nrow</c> for this.</p>
            </li>
            
            <li>
              <p>We can also use <c>%in%</c> to filter with <alert>dplyr</alert>. You can therefore see the data from New York and Texas like this:</p>
              <program language="r">
                <input>
filter(murders, state %in% c("New York", "Texas"))
                </input>
              </program>
              <p>Create a new data frame called <c>murders_nw</c> with only the states from the Northeast and the West. How many states are in this category?</p>
            </li>
            
            <li>
              <p>Suppose you want to live in the Northeast or West <alert>and</alert> want the murder rate to be less than 1. We want to see the data for the states satisfying these options. Note that you can use logical operators like <c>&amp;</c> with <c>filter</c>. Here is an example in which we filter to keep only small states in the Northeast region.</p>
              <program language="r">
                <input>
filter(murders, population &lt; 5000000 &amp; region == "Northeast")
                </input>
              </program>
              <p>Make sure <c>murders</c> has been defined with <c>rate</c> and <c>rank</c> and still has all states. Create a table called <c>my_states</c> that contains rows for states satisfying both the conditions: it is in the Northeast or West and the murder rate is less than 1. Use <c>select</c> to show only the state name, the rate, and the rank.</p>
            </li>
            
            <li>
              <p>The pipe <c>|&gt;</c> can be used to perform operations sequentially without having to define intermediate objects. Repeat the previous exercise, but now instead of creating a new object, show the result and only include the state, rate, and rank columns. Use a pipe <c>|&gt;</c> to do this in just one line.</p>
            </li>
            
            <li>
              <p>For exercises 13-19, we will be using the data from the survey collected by the United States National Center for Health Statistics (NCHS). Load the <alert>NHANES</alert> package and data:</p>
              <program language="r">
                <input>
library(NHANES)
                </input>
              </program>
              <p>The <alert>NHANES</alert> data has many missing values. The <c>mean</c> and <c>sd</c> functions in R will return <c>NA</c> if any of the entries of the input vector is an <c>NA</c>. To ignore the <c>NA</c>s we can use the <c>na.rm = TRUE</c> argument. We will provide some basic facts about blood pressure. First let's select a group to set the standard. We will use 20-to-29-year-old females. <c>AgeDecade</c> is a categorical variable with these ages. Note that the category is coded like <c>" 20-29"</c>, with a space in front! What is the average and standard deviation of systolic blood pressure as saved in the <c>BPSysAve</c> variable? Save it to a variable called <c>ref</c>. Hint: Use <c>filter</c> and <c>summarize</c> and use the <c>na.rm = TRUE</c> argument when computing the average and standard deviation. You can also filter the NA values using <c>filter</c>.</p>
            </li>
            
            <li><p>Using a pipe, assign the average to a numeric variable <c>ref_avg</c>. Hint: Use the code from the previous exercise and then <c>pull</c>.</p></li>
            
            <li><p>Now report the min and max values for the same group.</p></li>
            
            <li><p>Compute the average and standard deviation for females, but for each age group separately rather than a selected decade as in exercise 13. Note that the age groups are defined by <c>AgeDecade</c>. Hint: rather than filtering by age and gender, filter by <c>Gender</c> and then use <c>group_by</c>.</p></li>
            
            <li><p>Repeat exercise 16 for males.</p></li>
            
            <li><p>For males between the ages of 40-49, compare systolic blood pressure across race as reported in the <c>Race1</c> variable. Order the resulting table from lowest to highest average systolic blood pressure.</p></li>
            
            <li>
              <p>Load the <c>murders</c> dataset. Which of the following is true?</p>
              <ol marker="a">
                <li><c>murders</c> is in tidy format and is stored in a tibble.</li>
                <li><c>murders</c> is in tidy format and is stored in a data frame.</li>
                <li><c>murders</c> is not in tidy format and is stored in a tibble.</li>
                <li><c>murders</c> is not in tidy format and is stored in a data frame.</li>
              </ol>
            </li>
            
            <li><p>Use <c>as_tibble</c> to convert the <c>murders</c> data table into a tibble and save it in an object called <c>murders_tibble</c>.</p></li>
            
            <li><p>Use the <c>group_by</c> function to convert <c>murders</c> into a tibble that is grouped by region.</p></li>
            
            <li>
              <p>Write tidyverse code that is equivalent to this code:</p>
              <program language="r">
                <input>
exp(mean(log(murders$population)))
                </input>
              </program>
              <p>Write it using the pipe so that each function is called without arguments. Use the dot operator to access the population. Hint: The code should start with <c>murders |&gt;</c>.</p>
            </li>
            
            <li><p>Use the <c>map_df</c> to create a data frame with three columns named <c>n</c>, <c>s_n</c>, and <c>s_n_2</c>. The first column should contain the numbers 1 through 100. The second and third columns should each contain the sum of 1 through <m>n</m> with <m>n</m> the row number.</p></li>
          </ol>
          
        </section>
        
      </chapter>

      <chapter xml:id="ch-data-table">
        <title>data.table</title>
        
        <section xml:id="sec-dt-introduction">
          <title>Introduction</title>
          
          <p>In this book, we use tidyverse packages, primarily because they offer readability that is beneficial for beginners. This readability allows us to emphasize data analysis and statistical concepts. However, while tidyverse is beginner-friendly, there are other methods in R that are more efficient and can handle larger datasets more effectively. One such package is <alert>data.table</alert>, which is widely used in the R community. We'll briefly introduce <alert>data.table</alert> in this chapter. For those interested in diving deeper, there are numerous online resources, including an introduction<fn><url href="https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html"/></fn>.</p>
          
        </section>
        
        <section xml:id="sec-refining-data-tables">
          <title>Refining data tables</title>
          
          <p><c>data.table</c> is a separate package that needs to be installed. Once installed, we then need to load it along with the other packages we will use:</p>
          
          <program language="r">
            <input>
library(dplyr)
library(dslabs)
library(data.table)
            </input>
          </program>
          
          <p>We will provide example code showing the <alert>data.table</alert> approaches to <alert>dplyr</alert>'s <c>mutate</c>, <c>filter</c>, <c>select</c>, <c>group_by</c>, and <c>summarize</c>. As in that chapter, we will use the <c>murders</c> dataset:</p>
          
          <p>The first step when using <alert>data.table</alert> is to convert the data frame into a <c>data.table</c> object using the <c>as.data.table</c> function:</p>
          
          <program language="r">
            <input>
murders_dt &lt;- as.data.table(murders)
            </input>
          </program>
          
          <p>Without this initial step, most of the approaches shown below will not work.</p>
          
          <subsection xml:id="subsec-dt-column-wise-subsetting">
            <title>Column-wise subsetting</title>
            
            <p>Selecting with <alert>data.table</alert> is done in a similar way to subsetting matrices. While with <alert>dplyr</alert> we write</p>
            
            <program language="r">
              <input>
select(murders, state, region)
              </input>
            </program>
            
            <p>in <alert>data.table</alert> we use</p>
            
            <program language="r">
              <input>
murders_dt[, c("state", "region")]
              </input>
            </program>
            
            <p>We can also use the <c>.()</c> <alert>data.table</alert> notation, which is a special syntax that tells data.table that variables inside the parentheses are column names, not objects in the R environment. So the above can also be written like this:</p>
            
            <program language="r">
              <input>
murders_dt[, .(state, region)]
              </input>
            </program>
            
          </subsection>
          
          <subsection xml:id="subsec-dt-adding-transforming-variables">
            <title>Adding or transforming variables</title>
            
            <p>We learned to use the <alert>dplyr</alert> <c>mutate</c> function with this example:</p>
            
            <program language="r">
              <input>
murders &lt;- mutate(murders, rate = total / population * 100000)
              </input>
            </program>
            
            <p><alert>data.table</alert> uses an approach that avoids a new assignment (update by reference). This can help with large datasets that take up most of your computer's memory. The <alert>data.table</alert> <c>:=</c> function permits us to do this:</p>
            
            <program language="r">
              <input>
murders_dt[, rate := total / population * 100000] # rate per 100,000
              </input>
            </program>
            
            <p>This adds a new column, <c>rate</c>, to the table. Notice that, as in <alert>dplyr</alert>, we used <c>total</c> and <c>population</c> without quotes.</p>
            
            <p>To define new multiple columns, we can use the <c>:=</c> function with multiple arguments:</p>
            
            <program language="r">
              <input>
murders_dt[, ":="(rate = total / population * 100000, rank = rank(population))]
              </input>
            </program>
            
          </subsection>
          
          <subsection xml:id="subsec-dt-reference-versus-copy">
            <title>Reference versus copy</title>
            
            <p>The <alert>data.table</alert> package is designed to avoid wasting memory. So if you make a copy of a table, like this:</p>
            
            <program language="r">
              <input>
x &lt;- data.table(a = 1)
y &lt;- x
              </input>
            </program>
            
            <p><c>y</c> is actually referencing <c>x</c>, it is not a new object: <c>y</c> is just another name for <c>x</c>. Until you change <c>y</c>, a new object will not be made. However, the <c>:=</c> function changes <em>by reference</em> so if you change <c>x</c>, a new object is not made and <c>y</c> continues to be just another name for <c>x</c>:</p>
            
            <program language="r">
              <input>
x[, a := 2]
y
              </input>
            </program>
            
            <p>You can also change <c>x</c> like this:</p>
            
            <program language="r">
              <input>
y[, a := 1]
x
              </input>
            </program>
            
            <p>To avoid this, you can use the <c>copy</c> function which forces the creation of an actual copy:</p>
            
            <program language="r">
              <input>
x &lt;- data.table(a = 1)
y &lt;- copy(x)
x[, a := 2]
y
              </input>
            </program>
            
            <p>Note that the function <c>as.data.table</c> creates a copy of the data frame being converted. However, if working with large data frames it is helpful to avoid this by using <c>setDT</c>:</p>
            
            <program language="r">
              <input>
x &lt;- data.frame(a = 1)
setDT(x)
              </input>
            </program>
            
            <p>Note that because no copy is being made the following code does not create a new object:</p>
            
            <program language="r">
              <input>
x &lt;- data.frame(a = 1)
y &lt;- setDT(x)
              </input>
            </program>
            
            <p>The objects <c>x</c> and <c>y</c> are referencing the same data table:</p>
            
            <program language="r">
              <input>
x[, a := 2]
y
              </input>
            </program>
            
          </subsection>
          
          <subsection xml:id="subsec-dt-row-wise-subsetting">
            <title>Row-wise subsetting</title>
            
            <p>With <alert>dplyr</alert>, we filtered like this:</p>
            
            <program language="r">
              <input>
filter(murders, rate &lt;= 0.7)
              </input>
            </program>
            
            <p>With <alert>data.table</alert>, we again use an approach similar to subsetting matrices, except like <alert>dplyr</alert>, <alert>data.table</alert> knows that <c>rate</c> refers to a column name and not an object in the R environment:</p>
            
            <program language="r">
              <input>
murders_dt[rate &lt;= 0.7]
              </input>
            </program>
            
            <p>Notice that we can combine the filter and select into one succinct command. Here are the state names and rates for those with rates below 0.7.</p>
            
            <program language="r">
              <input>
murders_dt[rate &lt;= 0.7, .(state, rate)]
              </input>
            </program>
            
            <p>which is more compact than the <alert>dplyr</alert> approach:</p>
            
            <program language="r">
              <input>
murders |&gt; filter(rate &lt;= 0.7) |&gt; select(state, rate)
              </input>
            </program>
            
            <note>
              <p>You are ready to do exercises 1-7.</p>
            </note>
            
          </subsection>
          
        </section>
        
        <section xml:id="sec-dt-summarizing-data">
          <title>Summarizing data</title>
          
          <p>As an example, we will use the <c>heights</c> dataset:</p>
          
          <program language="r">
            <input>
heights_dt &lt;- as.data.table(heights)
            </input>
          </program>
          
          <p>In <alert>data.table</alert>, we can call functions inside <c>.()</c> and they will be applied to columns. So the equivalent of:</p>
          
          <program language="r">
            <input>
s &lt;- heights |&gt; summarize(avg = mean(height), sd = sd(height))
            </input>
          </program>
          
          <p>in <alert>dplyr</alert> is the following in <alert>data.table</alert>:</p>
          
          <program language="r">
            <input>
s &lt;- heights_dt[, .(avg = mean(height), sd = sd(height))]
            </input>
          </program>
          
          <p>Note that this permits a compact way of subsetting and then summarizing. Instead of:</p>
          
          <program language="r">
            <input>
s &lt;- heights |&gt; 
  filter(sex == "Female") |&gt;
  summarize(avg = mean(height), sd = sd(height))
            </input>
          </program>
          
          <p>we can write:</p>
          
          <program language="r">
            <input>
s &lt;- heights_dt[sex == "Female", .(avg = mean(height), sd = sd(height))]
            </input>
          </program>
          
          <subsection xml:id="subsec-dt-multiple-summaries">
            <title>Multiple summaries</title>
            
            <p>In the tidyverse chapter, we defined the following function to permit multiple column summaries in <alert>dplyr</alert>:</p>
            
            <program language="r">
              <input>
median_min_max &lt;- function(x){
  qs &lt;- quantile(x, c(0.5, 0, 1))
  data.frame(median = qs[1], minimum = qs[2], maximum = qs[3])
}
              </input>
            </program>
            
            <p>In <alert>data.table</alert> we place a function call within <c>.()</c> to obtain the three number summary:</p>
            
            <program language="r">
              <input>
heights_dt[, .(median_min_max(height))]
              </input>
            </program>
            
          </subsection>
          
          <subsection xml:id="subsec-dt-group-then-summarize">
            <title>Group then summarize</title>
            
            <p>The <c>group_by</c> followed by <c>summarize</c> in <alert>dplyr</alert> is performed in one line in <alert>data.table</alert>. We simply add the <c>by</c> argument to split the data into groups based on the values in categorical variable:</p>
            
            <program language="r">
              <input>
heights_dt[, .(avg = mean(height), sd = sd(height)), by = sex]
              </input>
            </program>
            
          </subsection>
          
        </section>
        
        <section xml:id="sec-dt-sorting">
          <title>Sorting</title>
          
          <p>We can order rows using the same approach we use for filter. Here are the states ordered by murder rate:</p>
          
          <program language="r">
            <input>
murders_dt[order(population)]
            </input>
          </program>
          
          <p>To sort the table in descending order, we can order by the negative of <c>population</c> or use the <c>decreasing</c> argument:</p>
          
          <program language="r">
            <input>
murders_dt[order(population, decreasing = TRUE)]
            </input>
          </program>
          
          <p>Similarly, we can perform nested ordering by including more than one variable in order:</p>
          
          <program language="r">
            <input>
murders_dt[order(region, rate)]
            </input>
          </program>
          
          <note>
            <p>You are ready to do exercises 8-12.</p>
          </note>
          
        </section>
        
        <section xml:id="sec-data-table-exercises">
          <title>Exercises</title>
          
          <p>1. Load the <alert>data.table</alert> package and the <c>murders</c> dataset and convert it to <c>data.table</c> object:</p>
          
          <program language="r">
            <input>
library(data.table)
library(dslabs)
murders_dt &lt;- as.data.table(murders)
            </input>
          </program>
          
          <p>Remember you can add columns like this:</p>
          
          <program language="r">
            <input>
murders_dt[, population_in_millions := population / 10^6]
            </input>
          </program>
          
          <p>Add a <c>murders</c> column named <c>rate</c> with the per 100,000 murder rate as in the example code above.</p>
          
          <p>2. Add a column <c>rank</c> containing the rank, from highest to lowest murder rate.</p>
          
          <p>3. If we want to only show the states and population sizes, we can use:</p>
          
          <program language="r">
            <input>
murders_dt[, .(state, population)]
            </input>
          </program>
          
          <p>Show the state names and abbreviations in <c>murders</c>.</p>
          
          <p>4. You can show just the New York row like this:</p>
          
          <program language="r">
            <input>
murders_dt[state == "New York"]
            </input>
          </program>
          
          <p>You can use other logical vectors to filter rows.</p>
          
          <p>Show the top 5 states with the highest murder rates. From here on, do not change the <c>murders</c> dataset, just show the result. Remember that you can filter based on the <c>rank</c> column.</p>
          
          <p>5. We can remove rows using the <c>!=</c> operator. For example, to remove Florida, we would do this:</p>
          
          <program language="r">
            <input>
no_florida &lt;- murders_dt[state != "Florida"]
            </input>
          </program>
          
          <p>Create a new data frame called <c>no_south</c> that removes states from the South region. How many states are in this category? You can use the function <c>nrow</c> for this.</p>
          
          <p>6. We can also use <c>%in%</c> to filter. You can therefore see the data from New York and Texas as follows:</p>
          
          <program language="r">
            <input>
murders_dt[state %in% c("New York", "Texas")]
            </input>
          </program>
          
          <p>Create a new data frame called <c>murders_nw</c> with only the states from the Northeast and the West. How many states are in this category?</p>
          
          <p>7. Suppose you want to live in the Northeast or West <alert>and</alert> want the murder rate to be less than 1. We want to see the data for the states satisfying these options. Note that you can use logical operators with <c>filter</c>. Here is an example in which we filter to keep only small states in the Northeast region.</p>
          
          <program language="r">
            <input>
murders_dt[population &lt; 5000000 &amp; region == "Northeast"]
            </input>
          </program>
          
          <p>Make sure <c>murders</c> has been defined with <c>rate</c> and <c>rank</c> and still has all states. Create a table called <c>my_states</c> that contains rows for states satisfying both the conditions: they are in the Northeast or West and the murder rate is less than 1. Show only the state name, the rate, and the rank.</p>
          
          <p>For exercises 8-12, we will be using the <alert>NHANES</alert> data.</p>
          
          <program language="r">
            <input>
library(NHANES)
            </input>
          </program>
          
          <p>8. We will provide some basic facts about blood pressure. First let's select a group to set the standard. We will use 20-to-29-year-old females. <c>AgeDecade</c> is a categorical variable with these ages. Note that the category is coded like <c>" 20-29"</c>, with a space in front! Use the <alert>data.table</alert> package to compute the average and standard deviation of systolic blood pressure as saved in the <c>BPSysAve</c> variable. Save it to a variable called <c>ref</c>.</p>
          
          <p>9. Report the min and max values for the same group.</p>
          
          <p>10. Compute the average and standard deviation for females, but for each age group separately rather than a selected decade as in exercise 8. Note that the age groups are defined by <c>AgeDecade</c>.</p>
          
          <p>11. Repeat exercise 10 for males.</p>
          
          <p>12. For males between the ages of 40-49, compare systolic blood pressure across race as reported in the <c>Race1</c> variable. Order the resulting table from lowest to highest average systolic blood pressure.</p>
          
        </section>
        
      </chapter>

      <chapter xml:id="ch-importing-data">
        <title>Importing data</title>
        
        <section xml:id="sec-importing-data-introduction">
          <title>Introduction</title>
          
          <p>We have been using datasets already stored as R objects. In data analysis work we rarely have such luck and will have to import data into R from either a file, a database, or another source. Currently, one of the most common ways of storing and sharing data for analysis is through electronic spreadsheets. A spreadsheet stores data in rows and columns. It is basically a file version of a data frame. When saving such a table to a computer file, one needs a way to define when a new row or column ends and the other begins. This in turn defines the cells in which single values are stored. Here is an example of what a comma separated file looks like if we open it with a basic text editor:</p>
          
          <p>In this chapter, we outline how to load data from a file into R. First, it's crucial to identify the file's location; thus, we touch on file paths and working directories. Next, we delve into file types (text or binary) and encodings (like ASCII and Unicode), both essential for data import. We then introduce popular functions for data importing, referred to as <em>parsers</em>. Lastly, we offer tips on how to store data in spreadsheets. Advanced topics like extracting data from websites or PDFs will be discussed in the book's Data Wrangling section.</p>
          
        </section>
        
        <section xml:id="sec-navigating-filesystem">
          <title>Navigating and managing the filesystem</title>
          
          <p>The first step when importing data from a spreadsheet is to locate the file containing the data. Although we do not recommend it, you can use an approach similar to what you do to open files in Microsoft Excel by clicking on the RStudio "File" menu, clicking "Import Dataset", then clicking through folders until you find the file. However, we write code rather than use the point-and-click approach. The key concepts we need to learn to do this are described in detail in the Unix chapter. Here we provide an overview of the very basics.</p>
          
          <subsection xml:id="subsec-the-filesystem">
            <title>The filesystem</title>
            
            <p>You can think of your computer's filesystem as a series of nested folders, each containing other folders and files. We refer to folders as <em>directories</em>. We refer to the folder that contains all other folders as the <em>root directory</em>. We refer to the directory in which we are currently located as the <em>working directory</em>. The working directory therefore changes as you move through folders: think of it as your current location.</p>
            
          </subsection>
          
          <subsection xml:id="subsec-relative-full-paths">
            <title>Relative and full paths</title>
            
            <p>The <em>path</em> of a file is a list of directory names that can be thought of as instructions on what folders to click on, and in what order, to find the file. If these instructions are for finding the file from the root directory, we refer to it as the <em>full path</em>. If the instructions are for finding the file starting in the working directory, we refer to it as a <em>relative path</em>. More details on this topic are provided in a later section on the filesystem.</p>
            
            <p>To see an example of a full path on your system type the following:</p>
            
            <program language="r">
              <input>
system.file(package = "dslabs")
              </input>
            </program>
            
            <p>Note that the output will be different across different computers. The <c>system.file</c> function finds the full path to the files that were added to your system when you installed the <alert>dslabs</alert> package. The strings separated by slashes are the directory names. The first slash represents the root directory and we know this is a full path because it starts with a slash.</p>
            
            <p>We can use the function <c>list.files</c> to show the names of files and directories in any directory. For example, here are the files in the <alert>dslabs</alert> package directory:</p>
            
            <program language="r">
              <input>
dir &lt;- system.file(package = "dslabs")
list.files(dir)
              </input>
            </program>
            
            <p>Note that these do not start with slash which implies they are <em>relative paths</em>. These relative paths give us the location of the files or directories if the path stored in <c>dir</c> is our working directory.</p>
            
            <note>
              <p>You will not make much use of the <c>system.file</c> function in your day-to-day data analysis work. We introduce it in this section because it facilitates the sharing of spreadsheets that can be used to practice. The spreadsheets are in the <c>extdata</c> directory.</p>
            </note>
            
          </subsection>
          
          <subsection xml:id="subsec-working-directory">
            <title>The working directory</title>
            
            <p>We highly recommend only using relative paths in your code. The reason is that full paths are unique to your computer and you want your code to be portable. If you want to know the full path of your working directory using the <c>getwd</c> function. If you need to change your working directory, you can use the function <c>setwd</c> or you can change it through RStudio by clicking on "Session".</p>
            
            <p>When starting a project, choose a directory to store all related files and set it as your working directory for analysis. This practice ensures that when you use relative paths in functions that import files, R will automatically search for the files in the working directory. For more details on organizing projects in RStudio, see the chapter on reproducible projects.</p>
            
          </subsection>
          
          <subsection xml:id="subsec-generating-path-names">
            <title>Generating path names</title>
            
            <p>The <c>file.path</c> function combines characters to form a complete path, ensuring compatibility with the respective operating system. Linux and Mac use forward slashes <c>/</c>, while Windows uses backslashes <c>\</c>, to separate directories. This function is useful because often you want to define paths using a variable. Here is an example that constructs the full path for a spreadsheet containing the murders data. Here the variable <c>dir</c> contains the full path for the <alert>dslabs</alert> package and <c>extdata/murders.csv</c> is the relative path of the spreadsheet if <c>dir</c> is considered the working directory.</p>
            
            <program language="r">
              <input>
dir &lt;- system.file(package = "dslabs")
file_path &lt;- file.path(dir, "extdata/murders.csv")
              </input>
            </program>
            
            <p>You can copy the file with full path <c>file_path</c> to your working directory using the function <c>file.copy</c>:</p>
            
            <program language="r">
              <input>
file.copy(file_path, "murders.csv")
              </input>
            </program>
            
            <p>If the file is copied successfully, this function will return <c>TRUE</c>. Note that we used the same filename for the destination file, but we can give it whatever name we want. If a file with that name already exists in your destination directory, the copy will be unsuccessful. You can change this behavior with the <c>overwrite</c> argument.</p>
            
          </subsection>
          
        </section>
        
        <section xml:id="sec-file-types">
          <title>File types</title>
          
          <p>For most data analysis applications, files can generally be classified into two categories: text files and binary files. In this section we describe the most widely used format for both these types and the best way to identify them. In the last subsection we describe the importance of knowing the file encoding.</p>
          
          <note>
            <p>For this and the following section we assume you have copied the <c>murders.csv</c> file into your working directory. You can use the code at the end of the previous section to do this.</p>
          </note>
          
          <subsection xml:id="subsec-text-files">
            <title>Text files</title>
            
            <p>You have already worked with text files. All your R scripts and Quarto files, for example, are text files and so are the Quarto files used to create this book. The <c>murders.csv</c> file mentioned above is also text files. One big advantage of these files is that we can easily "look" at them without having to purchase any kind of special software or follow complicated instructions. Any text editor can be used to examine a text file, including freely available editors such as RStudio or nano. To see this, try opening a csv file using the "Open file" RStudio tool. You should be able to see the content right on your editor.</p>
            
            <p>When text files are used to store a spreadsheet, line breaks are used to separate rows and a predefined character, referred to as the <em>delimiter</em>, is used to separate columns within a row. The most common delimiters are comma (<c>,</c>), semicolon (<c>;</c>), space (<c> </c>), and tab (the <c>\t</c> character, which represents a single tab character, not multiple spaces). Slightly different approaches are used to read these files into R, so we need to know what delimiter was used. In some cases, the delimiter can be inferred from file suffix. For example, files ending in <c>csv</c> or <c>tsv</c> are expected to be comma and tab delimited, respectively. However, it is harder to infer the delimiter for files ending in <c>txt</c>. As a result we recommend looking at the file rather than inferring from the suffix. You can look at any number of lines from within R using the <c>readLines</c> function:</p>
            
            <program language="r">
              <input>
readLines("murders.csv", n = 3)
              </input>
            </program>
            
            <p>This immediately reveals that the file is indeed comma delimited. It also reveals that the file has a header: the first row contains column names rather than data. This is also important to know. Most parsers assume the file starts with a header, but not all files have one.</p>
            
          </subsection>
          
          <subsection xml:id="subsec-binary-files">
            <title>Binary files</title>
            
            <p>Opening image files such as jpg or png in a text editor or using <c>readLines</c> in R will not show comprehensible content because these are <em>binary</em> files. Unlike text files, which are designed for human readability and have standardized conventions, binary files can adopt numerous formats specific to their data type. While R's <c>readBin</c> function can process any binary file, interpreting the output necessitates a thorough understanding of the file's structure. This intricate topic isn't covered in this book. Instead, we concentrate on the prevalent binary formats for spreadsheets: Microsoft Excel's xls and xlsx.</p>
            
          </subsection>
          
          <subsection xml:id="subsec-encoding">
            <title>Encoding</title>
            
            <p>A frequent issue when importing data, whether text or binary, is incorrectly identifying the file's <em>encoding</em>. At its core, a computer translates everything into sequences of 0s and 1s. ASCII is an <em>encoding</em> system that assigns specific numbers to characters. Using 7 bits, ASCII can represent <m>2^7 = 128</m> unique symbols, sufficient for all English keyboard characters. However, many global languages contain characters outside ASCII's range. For instance, the é in "México" isn't in ASCII's catalog. To address this, broader encodings, such as Unicode, emerged. Unicode offers variations using 8, 16, or 32 bits, known as UTF-8, UTF-16, and UTF-32. RStudio typically uses UTF-8 as its default. Notably, ASCII is a subset of UTF-8, meaning that if a file is ASCII-encoded, presuming it's UTF-8 encoded won't cause issues. However, there are other encodings, such as ISO-8859-1 (also known as Latin-1) developed for the western European languages, Big5 for Traditional Chinese, and ISO-8859-6 for Arabic.</p>
            
            <p>The <alert>dslabs</alert> package includes a file that is not UTF-8 encoded to serve as an example. Notice the strange characters that appear you attempt to read in the first line:</p>
            
            <program language="r">
              <input>
fn &lt;- "calificaciones.csv"
file.copy(file.path(system.file("extdata", package = "dslabs"), fn), fn)
readLines(fn, n = 1)
              </input>
            </program>
            
            <p>In the following section, we'll introduce several helpful import functions, some of which allow you to specify the file encoding.</p>
            
          </subsection>
          
        </section>
        
        <section xml:id="sec-parsers">
          <title>Parsers</title>
          
          <p>Importing functions, or parsers, are available from base R. However, more powerful and often faster functions are available in the <alert>readr</alert>, <alert>readxl</alert>, and <alert>data.table</alert> packages. In this section we review some examples. We also describe how data can be downloaded or read directly from the internet.</p>
          
          <subsection xml:id="subsec-base-r">
            <title>Base R</title>
            
            <p>Base R provides several file parsers for example <c>read.csv</c>, <c>read.table</c> and <c>read.delim</c>. The first argument can take either a full or relative path. If a relative path is provided, the parser assumes you want to search in the working directory. Therefore, to read the <c>murders.csv</c> file previously copied to our working directory, we can simply type:</p>
            
            <program language="r">
              <input>
dat &lt;- read.csv("murders.csv")
              </input>
            </program>
            
            <p>An often useful R-base importing function is <c>scan</c>, as it provides much flexibility. When reading in spreadsheets many things can go wrong. The file might have multiline headers or be missing cells. With experience you will learn how to deal with different challenges. Carefully reading the help files for the functions discussed here will be useful. With scan you can read-in each cell of a file. Here is an example:</p>
            
            <program language="r">
              <input>
x &lt;- scan("murders.csv", sep = ",", what = "c")
x[1:10]
              </input>
            </program>
            
          </subsection>
          
          <subsection xml:id="subsec-readr">
            <title>readr</title>
            
            <p>The <alert>readr</alert> package includes parsers, for reading text file spreadsheets into R. <alert>readr</alert> is part of the <alert>tidyverse</alert>, but you can load it directly using:</p>
            
            <program language="r">
              <input>
library(readr)
              </input>
            </program>
            
            <p>The following functions are available to read-in text file spreadsheets:</p>
            
            <table>
              <title>readr functions for reading text files</title>
              <tabular>
                <row header="yes">
                  <cell>Function</cell>
                  <cell>Format</cell>
                  <cell>Typical suffix</cell>
                </row>
                <row>
                  <cell>read_table</cell>
                  <cell>white space separated values</cell>
                  <cell>txt</cell>
                </row>
                <row>
                  <cell>read_csv</cell>
                  <cell>comma separated values</cell>
                  <cell>csv</cell>
                </row>
                <row>
                  <cell>read_csv2</cell>
                  <cell>semicolon separated values</cell>
                  <cell>csv</cell>
                </row>
                <row>
                  <cell>read_tsv</cell>
                  <cell>tab delimited separated values</cell>
                  <cell>tsv</cell>
                </row>
                <row>
                  <cell>read_delim</cell>
                  <cell>general text file format, must define delimiter</cell>
                  <cell>txt</cell>
                </row>
              </tabular>
            </table>
            
            <p>It also includes <c>read_lines</c> with similar functionality to <c>readLines</c>.</p>
            
            <p>We can read in the <c>murders.csv</c> file using</p>
            
            <program language="r">
              <input>
dat &lt;- read_csv("murders.csv")
              </input>
            </program>
            
            <p>Note that we receive a message letting us know what data types were used for each column. Also note that <c>dat</c> is a <c>tibble</c>, not just a data frame. We can suppress this message using the argument <c>show_col_types = FALSE</c>.</p>
            
            <p>The <alert>readr</alert> parsers permit us to specify an encoding. It also includes a function that tries to guess the encoding:</p>
            
            <program language="r">
              <input>
guess_encoding("murders.csv")
              </input>
            </program>
            
            <p>This function can help us read the file we previously noted was showing strange characters:</p>
            
            <program language="r">
              <input>
guess_encoding("calificaciones.csv")
              </input>
            </program>
            
            <p>Once we know the encoding we can specify it through the <c>locale</c> argument:</p>
            
            <program language="r">
              <input>
dat &lt;- read_csv("calificaciones.csv", show_col_types = FALSE,
                locale = locale(encoding = "ISO-8859-1"))
              </input>
            </program>
            
            <p>We learn about locales in a later chapter.</p>
            
            <p>We can now see that the characters in the header were read in correctly:</p>
            
            <program language="r">
              <input>
names(dat)
              </input>
            </program>
            
          </subsection>
          
          <subsection xml:id="subsec-readxl">
            <title>readxl</title>
            
            <p>The <alert>readxl</alert> package provides functions to read-in Microsoft Excel formats.</p>
            
            <program language="r">
              <input>
library(readxl)
              </input>
            </program>
            
            <p>The main functions are:</p>
            
            <table>
              <title>readxl functions for reading Excel files</title>
              <tabular>
                <row header="yes">
                  <cell>Function</cell>
                  <cell>Format</cell>
                  <cell>Typical suffix</cell>
                </row>
                <row>
                  <cell>read_excel</cell>
                  <cell>auto detect the format</cell>
                  <cell>xls, xlsx</cell>
                </row>
                <row>
                  <cell>read_xls</cell>
                  <cell>original format</cell>
                  <cell>xls</cell>
                </row>
                <row>
                  <cell>read_xlsx</cell>
                  <cell>new format</cell>
                  <cell>xlsx</cell>
                </row>
              </tabular>
            </table>
            
            <p>The Microsoft Excel formats permit you to have more than one spreadsheet in one file. These are referred to as <em>sheets</em>. The functions listed above read the first sheet by default, but we can also read the others. The <c>excel_sheets</c> function gives us the names of all the sheets in an Excel file. These names can then be passed to the <c>sheet</c> argument in the three functions above to read sheets other than the first.</p>
            
          </subsection>
          
          <subsection xml:id="subsec-data-table">
            <title>data.table</title>
            
            <p>The <alert>data.table</alert> package provides the <c>fread</c> function, a powerful and fast utility designed for reading large datasets. <c>fread</c> automatically detects the format of the input, whether it's delimited text or even files compressed in formats like gzip or zip. It offers a significant speed advantage over the other parsers described here, especially for large files.</p>
            
            <program language="r">
              <input>
library(data.table)
dat &lt;- fread("murders.csv")
              </input>
            </program>
            
            <p>Note <c>fread</c> returns a <c>data.table</c> object.</p>
            
          </subsection>
          
          <subsection xml:id="subsec-downloading-files">
            <title>Downloading files</title>
            
            <p>A common place for data to reside is on the internet. When these data are in files, we can download them and then import them or even read them directly from the web. For example, we note that because our <alert>dslabs</alert> package is on GitHub, the file we downloaded with the package has a url:</p>
            
            <program language="r">
              <input>
url &lt;- paste0("https://raw.githubusercontent.com/",
              "rafalab/dslabs/master/inst/extdata/murders.csv")
              </input>
            </program>
            
            <p>Most parsers can read these files directly:</p>
            
            <program language="r">
              <input>
dat &lt;- read.csv(url)
              </input>
            </program>
            
            <p>If you want to have a local copy of the file, you can use the <c>download.file</c> function:</p>
            
            <program language="r">
              <input>
download.file(url, "murders.csv")
              </input>
            </program>
            
            <p>This will download the file and save it on your system with the name <c>murders.csv</c>. You can use any name here, not necessarily <c>murders.csv</c>.</p>
            
            <note>
              <title>Warning</title>
              <p>The function <c>download.file</c> overwrites existing files without warning.</p>
            </note>
            
            <p>Two functions that are sometimes useful when downloading data from the internet are <c>tempdir</c> and <c>tempfile</c>. The first creates a directory with a random name that is very likely to be unique. Similarly, <c>tempfile</c> creates a character string, not a file, that is likely to be a unique filename. So you can run a command like this which erases the temporary file once it imports the data:</p>
            
            <program language="r">
              <input>
tmp_filename &lt;- tempfile()
download.file(url, tmp_filename)
dat &lt;- read_csv(tmp_filename)
file.remove(tmp_filename)
              </input>
            </program>
            
          </subsection>
          
        </section>
        
        <section xml:id="sec-organizing-data">
          <title>Organizing data with spreadsheets</title>
          
          <p>Although this book focuses almost exclusively on data analysis, data management is also an important part of data science operations. As explained in the introduction, we do not cover this topic. However, quite often data analysts need to collect data, or work with others collecting data, in a way that is most conveniently stored in a spreadsheet. Although filling out a spreadsheet by hand is a practice we highly discourage, and we instead recommend the process be automatized as much as possible, sometimes you just have to do it. Therefore, in this section, we provide recommendations on how to organize data in a spreadsheet. Although there are R packages designed to read Microsoft Excel spreadsheets, we generally want to avoid this format. Instead, we recommend Google Sheets as a free software tool. Below we summarize the recommendations made in a paper by Karl Broman and Kara Woo<fn><url href="https://www.tandfonline.com/doi/abs/10.1080/00031305.2017.1375989"/></fn>. Please read the paper for important details.</p>
          
          <ul>
            <li><p><alert>Be Consistent</alert> - Before you commence entering data, have a plan. Once you have a plan, be consistent and stick to it.</p></li>
            <li><p><alert>Choose Good Names for Things</alert> - You want the names you pick for objects, files, and directories to be memorable, easy to spell, and descriptive. This is actually a hard balance to achieve and it does require time and thought. One important rule to follow is <alert>do not use spaces</alert>, use underscores <c>_</c> or dashes instead <c>-</c>. Also, avoid symbols; stick to letters and numbers.</p></li>
            <li><p><alert>Write Dates as YYYY-MM-DD</alert> - To avoid confusion, we strongly recommend using this global ISO 8601 standard.</p></li>
            <li><p><alert>No Empty Cells</alert> - Fill in all cells and use some common code for missing data.</p></li>
            <li><p><alert>Put Just One Thing in a Cell</alert> - It is better to add columns to store the extra information rather than having more than one piece of information in one cell.</p></li>
            <li><p><alert>Make It a Rectangle</alert> - The spreadsheet should be a rectangle.</p></li>
            <li><p><alert>Create a Data Dictionary</alert> - If you need to explain things, such as what the columns are or what the labels used for categorical variables are, do this in a separate file.</p></li>
            <li><p><alert>No Calculations in the Raw Data Files</alert> - Excel permits you to perform calculations. Do not make this part of your spreadsheet. Code for calculations should be in a script.</p></li>
            <li><p><alert>Do Not Use Font Color or Highlighting as Data</alert> - Most import functions are not able to import this information. Encode this information as a variable instead.</p></li>
            <li><p><alert>Make Backups</alert> - Make regular backups of your data.</p></li>
            <li><p><alert>Use Data Validation to Avoid Errors</alert> - Leverage the tools in your spreadsheet software so that the process is as error-free and repetitive-stress-injury-free as possible.</p></li>
            <li><p><alert>Save the Data as Text Files</alert> - Save files for sharing in comma or tab delimited format.</p></li>
          </ul>
          
        </section>
        
        <section xml:id="sec-importing-exercises">
          <title>Exercises</title>
          
          <p>1. Use the <c>read_csv</c> function to read each of the files that the following code saves in the <c>files</c> object:</p>
          
          <program language="r">
            <input>
path &lt;- system.file("extdata", package = "dslabs")
files &lt;- list.files(path)
files
            </input>
          </program>
          
          <p>2. Note that the <c>olive</c> file gives us a warning. This is because the first line of the file is missing the header for the first column.</p>
          
          <p>Read the help file for <c>read_csv</c> to figure out how to read in the file without reading this header. If you skip the header, you should not get this warning. Save the result to an object called <c>dat</c>.</p>
          
          <p>3. A problem with the previous approach is that we don't know what the columns represent. Type:</p>
          
          <program language="r">
            <input>
names(dat)
            </input>
          </program>
          
          <p>to see that the names are not informative.</p>
          
          <p>Use the <c>readLines</c> function to read in just the first line.</p>
          
          <p>4. Pick a measurement you can take on a regular basis. For example, your daily weight or how long it takes you to run 5 miles. Keep a spreadsheet that includes the date, the hour, the measurement, and any other informative variable you think is worth keeping. Do this for 2 weeks. Then make a plot.</p>
          
        </section>
        
      </chapter>

    </part>

    <!-- Part 2: Data Visualization -->
    <part xml:id="part-data-visualization">
      <title>Data Visualization</title>

      <chapter xml:id="ch-visualizing-data-distributions">
        <title>Visualizing data distributions</title>
        
        <introduction>
          <p>Summarizing complex datasets is crucial in data analysis, allowing us to share insights drawn from the data more effectively. One common method is to use the <em>average</em> value to summarize a list of numbers. For instance, a high school's quality might be represented by the average score in a standardized test. Sometimes, an additional value, the <em>standard deviation</em>, is added. So, a report might say the scores were 680 <m>\pm</m> 50, boiling down a full set of scores to just two numbers. But is this enough? Are we overlooking crucial information by relying solely on these summaries instead of the complete data?</p>
          
          <p>Our first data visualization building block is learning to summarize lists of numbers or categories. More often than not, the best way to share or explore these summaries is through data visualization. The most basic statistical summary of a list of objects or numbers is its distribution. Once data has been summarized as a distribution, there are several data visualization techniques to effectively relay this information. For this reason, it is important to have a deep understanding of the concept of a distribution.</p>
          
          <p>In this chapter, we discuss properties of a variety of distributions and how to visualize distributions using a motivating example of student heights.</p>
        </introduction>
        
        <section xml:id="sec-variable-types">
          <title>Variable types</title>
          
          <p>The two main variables types are <em>categorical</em> and <em>numeric</em>. Each can be divided into two other groups: categorical can be ordinal or not, whereas numerical variables can be discrete or continuous. When entries in a dataset represent groups rather than numbers we refer to the data as <em>categorical data</em>. Two simple examples are sex (male or female) and US regions (Northeast, South, North Central, West). Some categorical data can be ordered even if they are not numbers per se, such as spiciness (mild, medium, hot). In statistics, ordered categorical data are referred to as <em>ordinal</em> data. Examples of numerical data are population sizes, murder rates, and heights. We can further divide numerical data into continuous and discrete. Continuous variables are those that can take any value, such as heights, if measured with enough precision. For example, a pair of twins may be 68.12 and 68.11 inches, respectively. Counts, such as population sizes, are discrete because they have to be round numbers.</p>
          
          <p>Keep in mind that discrete numeric data can be considered ordinal. Although this is technically true, we usually reserve the term ordinal data for variables belonging to a small number of different groups, with each group having many members. In contrast, when we have many groups with few cases in each group, we typically refer to them as discrete numerical variables. So, for example, the number of packs of cigarettes a person smokes a day, rounded to the closest pack, would be considered ordinal, while the actual number of cigarettes would be considered a numerical variable. But, indeed, there are examples that can be considered both numerical and ordinal when it comes to visualizing data.</p>
          
          <p>Here we focus on numeric variables because visualizing this data type is substantially more complex. However, we start by describing data visualization and summarization approaches for categorical data.</p>
        </section>
        
        <section xml:id="sec-case-study-heights">
          <title>Case study: describing student heights</title>
          
          <p>We introduce a new motivating problem. It is an artificial one, but it will help us illustrate the concepts needed to understand distributions.</p>
          
          <p>Pretend that we have to describe the heights of our classmates to ET, an extraterrestrial that has never seen humans. As a first step, we need to collect data. To do this, we ask students to report their heights in inches. We ask them to provide sex information because we know there are two different height distributions by sex. We collect the data and save it in the <c>heights</c> data frame:</p>
          
          <program language="r">
            <input>
library(tidyverse)
library(dslabs)
head(heights)
            </input>
          </program>
          
          <p>One way to convey the heights to ET is to simply send him this list of 1,050 heights. But there are much more effective ways to convey this information, and understanding the concept of a distribution will be key. To simplify the explanation, we first focus on male heights. We examine the female height data later in this chapter.</p>
        </section>
        
        <section xml:id="sec-distributions">
          <title>Distributions</title>
          
          <p>The most basic statistical summary of a list of objects or numbers is its <em>distribution</em>. The simplest way to think of a distribution is as a compact description of a list with many entries. This concept should not be new for readers of this book. For example, with categorical data, the distribution simply describes the proportion of each unique category. The sex represented in the heights dataset is:</p>
          
          <program language="r">
            <input>
prop.table(table(heights$sex))
            </input>
          </program>
          
          <p>This two-category <em>frequency table</em> is the simplest form of a distribution. We don't really need to visualize it since one number describes everything we need to know: 23% are females and the rest are males. When there are more categories, then a simple barplot describes the distribution. Here is an example with US state regions:</p>
          
          <program language="r">
            <input>
murders |> group_by(region) |>
  summarize(n = n()) |>
  mutate(Proportion = n/sum(n), 
         region = reorder(region, Proportion)) |>
  ggplot(aes(x=region, y=Proportion, fill=region)) + 
  geom_bar(stat = "identity", show.legend = FALSE) + 
  xlab("")
            </input>
          </program>
          
          <p>This particular plot simply shows us four numbers, one for each category. We usually use barplots to display a few numbers. Although this particular plot does not provide much more insight than a frequency table itself, it is a first example of how we convert a vector into a plot that succinctly summarizes all the information in the vector. When the data is numerical, the task of displaying distributions is more challenging.</p>
          
          <subsection xml:id="subsec-histograms">
            <title>Histograms</title>
            
            <p>Numerical data that are not categorical also have distributions. However, in general, when data is not categorical, reporting the frequency of each entry, as we did for categorical data, is not an effective summary since most entries are unique. For example, in our case study, while several students reported a height of 68 inches, only one student reported a height of 68.503937007874 inches and only one student reported a height 68.8976377952756 inches. We assume that they converted from 174 and 175 centimeters, respectively.</p>
            
            <p>Statistics textbooks teach us that a more useful way to define a distribution for numeric data is to define a function that reports the proportion of the data below <m>a</m> for all possible values of <m>a</m>. This function is called the empirical cumulative distribution function (eCDF), it can be plotted, and it provides a full description of the distribution of our data. Here is the eCDF for male student heights:</p>
            
            <program language="r">
              <input>
ds_theme_set()
heights |> filter(sex=="Male") |> 
  ggplot(aes(height)) + 
  stat_ecdf() +
  ylab("Proportion of heights less than or equal to a") + 
  xlab("a")
              </input>
            </program>
            
            <p>However, summarizing data by plotting the eCDF is actually not very popular in practice. The main reason is that it does not easily convey characteristics of interest such as: at what value is the distribution centered? Is the distribution symmetric? What ranges contain 95% of the values?</p>
            
            <p><em>Histograms</em> are much preferred because they greatly facilitate answering such questions. Histograms sacrifice just a bit of information to produce plots that are much easier to interpret. The simplest way to make a histogram is to divide the span of our data into non-overlapping bins of the same size. Then, for each bin, we count the number of values that fall in that interval. The histogram plots these counts as bars with the base of the bar defined by the intervals. Here is the histogram for the height data splitting the range of values into one inch intervals: <m>(49.5, 50.5]</m>, <m>(50.5, 51.5]</m>, <m>(51.5,52.5]</m>, <m>(52.5,53.5]</m>, <m>...</m>, <m>(82.5,83.5]</m>.</p>
            
            <program language="r">
              <input>
heights |> 
  filter(sex=="Male") |> 
  ggplot(aes(height)) + 
  geom_histogram(binwidth = 1, color = "black")
              </input>
            </program>
            
            <p>As you can see in the figure above, a histogram is similar to a barplot, but it differs in that the x-axis is numerical, not categorical.</p>
            
            <p>If we send this plot to ET, he will immediately learn some important properties about our data. First, the range of the data is from 50 to 84 with the majority (more than 95%) between 63 and 75 inches. Second, the heights are close to symmetric around 69 inches. Also, by adding up counts, ET could obtain a very good approximation of the proportion of the data in any interval. Therefore, the histogram above is not only easy to interpret, but also provides almost all the information contained in the raw list of 812 male heights with about 30 bins.</p>
            
            <p>What information do we lose? Note that all values in each interval are treated the same when computing bin heights. So, for example, the histogram does not distinguish between 64, 64.1, and 64.2 inches. Given that these differences are almost unnoticeable to the eye, the practical implications are negligible and we were able to summarize the data to just 23 numbers.</p>
            
            <p>We discuss how to code histograms later in this chapter.</p>
          </subsection>
          
          <subsection xml:id="subsec-smoothed-density">
            <title>Smoothed density</title>
            
            <p><em>Smooth density</em> plots relay the same information as a histogram but are aesthetically more appealing. Here is what a smooth density plot looks like for our male heights data:</p>
            
            <program language="r">
              <input>
heights |> 
  filter(sex=="Male") |> 
  ggplot(aes(height)) + 
  geom_density(alpha = .2, fill= "#00BFC4", color = 0)  +
  geom_line(stat='density')
              </input>
            </program>
            
            <p>In this plot, we no longer have sharp edges at the interval boundaries and many of the local peaks have been removed. Also, the scale of the y-axis changed from counts to <em>density</em>. To fully understand smooth densities, we have to understand <em>estimates</em>, a topic covered in statistics our advanced data science textbooks. Here we simply describe them as making the histograms prettier by drawing a curve that goes through the top of the histogram bars and then removing the bars. The values shown y-axis are chosen so that the area under the curve adds up to 1. This implies that for any interval, the area under the curve for that interval gives us an approximation of how what proportion of the data is in the interval.</p>
            
            <p>An advantage of smooth densities over histograms for visualization purposes is that densities make it easier to compare two distributions. This is in large part because the jagged edges of the histogram add clutter. Here is an example comparing male and female heights:</p>
            
            <program language="r">
              <input>
heights |> 
  ggplot(aes(height, fill=sex)) + 
  geom_density(alpha = 0.2, color = 0) +
  geom_line(stat='density')
              </input>
            </program>
            
            <p>With the right argument, <c>ggplot</c> automatically shades the intersecting region with a different color. We will show examples of <alert>ggplot2</alert> code for densities later in this book.</p>
          </subsection>
          
          <subsection xml:id="subsec-normal-distribution">
            <title>The normal distribution</title>
            
            <p>Histograms and density plots provide excellent summaries of a distribution. But can we summarize even further? We often see the average and standard deviation used as summary statistics: a two-number summary! To understand what these summaries are and why they are so widely used, we need to understand the normal distribution.</p>
            
            <p>The normal distribution, also known as the bell curve and as the Gaussian distribution. Here is what the normal distribution looks like:</p>
            
            <program language="r">
              <input>
mu &lt;- 0; s &lt;- 1
norm_dist &lt;- data.frame(x=seq(-4,4,len=50)*s+mu) |> mutate(density=dnorm(x,mu,s))
norm_dist |> ggplot(aes(x,density)) + geom_line()
              </input>
            </program>
            
            <p>The normal distribution is one of the most famous mathematical concepts in history. A reason for this is that the distribution of many datasets can be approximated with normal distributions. These include gambling winnings, heights, weights, blood pressure, standardized test scores, and experimental measurement errors. Statistical textbooks offer explanations for why this is the case. But how can the same distribution approximate datasets with completely different ranges for values, for example heights and weights? A second important characteristic of the normal distribution is that it can be adapted to different datasets by just adjusting two numbers, referred to as the <em>average</em> or <em>mean</em> and the <em>standard deviation</em> (SD). The normal distribution is symmetric, centered at what we refer to as the average, and most values (about 95%) are within 2 SDs from the average. The plot above shows a normal distribution with average 0 and SD 1, often referred to as a <em>standard normal</em>. Note that the fact that only two numbers are needed to adapt the normal distribution to a dataset implies that if our data distribution is approximated by a normal distribution, all the information needed to describe the distribution can be encoded by just two numbers. We now define these values for an arbitrary list of numbers.</p>
            
            <p>Once we are convinced that our data, say it is stored in the vector <c>x</c>, has a distribution that is <em>approximately normal</em>, we can find the specific one that matches our data by matching the average and SD of the data to the average and SD of the normal distribution, respectively. For a list of numbers contained in a vector <c>x</c>:</p>
            
            <program language="r">
              <input>
index &lt;- heights$sex == "Male"
x &lt;- heights$height[index]
              </input>
            </program>
            
            <p>the average is defined as</p>
            
            <program language="r">
              <input>
m &lt;- sum(x) / length(x)
              </input>
            </program>
            
            <p>and the SD is defined as</p>
            
            <program language="r">
              <input>
s &lt;- sqrt(sum((x - mu)^2) / length(x))
              </input>
            </program>
            
            <p>which can be interpreted as the average distance between values and their average.</p>
            
            <p>The pre-built functions <c>mean</c> and <c>sd</c> (note that, for reasons explained in statistics textbooks, <c>sd</c> divides by <c>length(x)-1</c> rather than <c>length(x)</c>) can be used here:</p>
            
            <program language="r">
              <input>
m &lt;- mean(x)
s &lt;- sd(x)
c(average = m, sd = s)
              </input>
            </program>
            
            <p>Here is a plot of our student height smooth density in blue and the normal distribution with mean = 69.3 and SD = 3.6 plotted as a black line:</p>
            
            <program language="r">
              <input>
norm_dist &lt;- data.frame(x = seq(-4, 4, len = 50)*s + m) |> 
  mutate(density = dnorm(x, m, s))

heights |> filter(sex == "Male") |> ggplot(aes(height)) +
  geom_density(fill = "#0099FF") +
  geom_line(aes(x, density),  data = norm_dist, lwd = 1.5)
              </input>
            </program>
          </subsection>
        </section>
        
        <section xml:id="sec-boxplots">
          <title>Boxplots</title>
          
          <p>To understand boxplots we need to define some terms that are commonly used in exploratory data analysis.</p>
          
          <p>The <em>percentiles</em> are the values for which <m>p = 0.01, 0.02, ..., 0.99</m> of the data are less then or equal to that value, respectively. We call, for example, the case of <m>p=0.10</m> the 10th percentile, which gives us a number for which 10% of the data is below. The most famous percentile is the 50th, also known as the <em>median</em>. Another special case that receives a name are the <em>quartiles</em>, which are obtained when setting <m>p=0.25,0.50</m>, and <m>0.75</m>, which are used by the boxplot.</p>
          
          <p>To motivate boxplots we will go back to the US murder data. Suppose we want to summarize the murder rate distribution. Using the data visualization technique we have learned, we can quickly see that the normal approximation does not apply here:</p>
          
          <program language="r">
            <input>
murders &lt;- murders |> mutate(rate = total/population*100000)
murders |> ggplot(aes(x = rate)) + geom_histogram(binwidth = 0.5, color = "black") + ggtitle("Histogram")
            </input>
          </program>
          
          <p>In this case, the histogram above or a smooth density plot would serve as a relatively succinct summary.</p>
          
          <p>Now suppose those used to receiving just two numbers as summaries ask us for a more compact numerical summary.</p>
          
          <p>The <em>boxplot</em> provides a five-number summary composed of the range (the minimum and maximum) along with the <em>quartiles</em> (the 25th, 50th, and 75th percentiles). The R implementation of boxplots ignore <em>outliers</em> when computing the range and instead plot these as independent points. The help file provides a specific definition of outliers. The boxplot shows these numbers as a "box" with "whiskers"</p>
          
          <program language="r">
            <input>
murders |> ggplot(aes("",rate)) + geom_boxplot() +
  coord_cartesian(xlim = c(0, 2)) + xlab("")
            </input>
          </program>
          
          <p>with the box defined by the 25% and 75% percentile and the whiskers showing the range. The distance between the 25% and 75% percentile is called the <em>interquartile</em> range. The two points are outliers according to the R implementation. The median is shown with a horizontal line.</p>
          
          <p>From just this simple plot, we know that the median is about 2.5, that the distribution is not symmetric, and that the range is 0 to 5 for the great majority of states with two exceptions.</p>
          
          <p>We discuss how to make boxplots later in this chapter.</p>
        </section>
        
        <section xml:id="sec-dataviz-stratification">
          <title>Stratification</title>
          
          <p>In data analysis we often divide observations into groups based on the values of one or more variables associated with those observations. For example in the next section we divide the height values into groups based on a sex variable: females and males. We call this procedure <em>stratification</em> and refer to the resulting groups as <em>strata</em>.</p>
          
          <p>Stratification is common in data visualization because we are often interested in how the distributions of variables differ across different subgroups. We will see several examples throughout this part of the book, starting with the next section.</p>
        </section>
        
        <section xml:id="sec-student-height-cont">
          <title>Case study continued</title>
          
          <p>If we are convinced that the male height data is well approximated with a normal distribution we can report back to ET a very succinct summary: male heights follow a normal distribution with an average of 69.3 inches and a SD of 3.6 inches. With this information, ET will have a good idea of what to expect when he meets our male students. However, to provide a complete picture we need to also provide a summary of the female heights.</p>
          
          <p>Boxplots are useful when we want to quickly compare two or more distributions. Here are the heights for men and women:</p>
          
          <program language="r">
            <input>
heights |> ggplot(aes(x = sex, y = height, fill = sex)) +
  geom_boxplot()
            </input>
          </program>
          
          <p>The plot immediately reveals that males are, on average, taller than females. The  interquartile ranges appear to be similar. But does the normal approximation also work for the female height data collected by the survey? We expect that they will follow a normal distribution, just like males. However, exploratory plots reveal that the approximation is not as useful:</p>
          
          <program language="r">
            <input>
heights |> filter(sex == "Female") |>
  ggplot(aes(height)) +
  geom_density(fill = "#F8766D")
            </input>
          </program>
          
          <p>We see something we did not see for the males: the density plot has a second "bump". Also, the highest points tend to be taller than expected by the normal than expected heights for a normal distribution. When reporting back to ET, we might need to provide a histogram rather than just the average and standard deviation for the female heights.</p>
          
          <p>However, go back and read Tukey's quote. We have noticed what we didn't expect to see. If we look at other female height distributions, we do find that they are well approximated with a normal distribution. So why are our female students different? Is our class a requirement for the female basketball team? Are small proportions of females claiming to be taller than they are? Another, perhaps more likely, explanation is that in the form students used to enter their heights, <c>FEMALE</c> was the default sex and some males entered their heights, but forgot to change the sex variable. In any case, data visualization has helped discover a potential flaw in our data.</p>
          
          <p>Regarding the five smallest values, note that these values are:</p>
          
          <program language="r">
            <input>
heights |> filter(sex == "Female") |> 
  slice_min(height, n = 5) |>
  pull(height)
            </input>
          </program>
          
          <p>Because these are reported heights, a possibility is that the student meant to enter 5'1", 5'2", 5'3" or 5'5".</p>
        </section>
        
        <section xml:id="sec-distributions-exercises">
          <title>Exercises</title>
          
          <ol>
            <li>
              <p>Define variables containing the heights of males and females like this:</p>
              
              <program language="r">
                <input>
library(dslabs)
male &lt;- heights$height[heights$sex == "Male"]
female &lt;- heights$height[heights$sex == "Female"]
                </input>
              </program>
              
              <p>How many measurements do we have for each?</p>
            </li>
            
            <li><p>Suppose we can't make a plot and want to compare the distributions side by side. We can't just list all the numbers. Instead, we will look at the percentiles. Create a five row table showing <c>female_percentiles</c> and <c>male_percentiles</c> with the 10th, 30th, 50th, 70th, &amp; 90th percentiles for each sex. Then create a data frame with these two as columns.</p></li>
            
            <li>
              <p>Study the following boxplots showing population sizes by country:</p>
              
              <program language="r">
                <input>
library(tidyverse)
library(dslabs)
ds_theme_set()
tab &lt;- gapminder |> filter(year == 2010) |> group_by(continent) |> select(continent, population)  
tab |> ggplot(aes(x = continent, y = population/10^6)) + 
  geom_boxplot() + 
  scale_y_continuous(trans = "log10", breaks = c(1,10,100,1000)) + ylab("Population in millions")
                </input>
              </program>
              
              <p>Which continent has the country with the biggest population size?</p>
            </li>
            
            <li><p>What continent has the largest median population size?</p></li>
            
            <li><p>What is median population size for Africa to the nearest million?</p></li>
            
            <li>
              <p>What proportion of countries in Europe have populations below 14 million?</p>
              
              <p>a.  0.99<br/>
              b.  0.75<br/>
              c.  0.50<br/>
              d.  0.25</p>
            </li>
            
            <li><p>If we use a log transformation, which continent shown above has the largest interquartile range?</p></li>
            
            <li>
              <p>Load the height data set and create a vector <c>x</c> with just the male heights:</p>
              
              <program language="r">
                <input>
library(dslabs)
x &lt;- heights$height[heights$sex=="Male"]
                </input>
              </program>
              
              <p>What proportion of the data is between 69 and 72 inches (taller than 69, but shorter or equal to 72)? Hint: use a logical operator and <c>mean</c>.</p>
            </li>
          </ol>
        </section>
      </chapter>

      <chapter xml:id="ch-ggplot2">
        <title>ggplot2</title>
        
        <introduction>
          <p>Exploratory data visualization is perhaps the greatest strength of R. One can quickly go from idea to data to plot with a unique balance of flexibility and ease. For example, Excel may be easier than R for some plots, but it is nowhere near as flexible. D3.js may be more flexible and powerful than R, but it takes much longer to generate a plot.</p>
          
          <p>Throughout the book, we will be creating plots using the <alert>ggplot2</alert> package.</p>
          
          <program language="r">
            <input>
library(dplyr)
library(ggplot2)
            </input>
          </program>
          
          <p>Many other approaches are available for creating plots in R. In fact, the plotting capabilities that come with a basic installation of R are already quite powerful. There are also other packages for creating graphics such as <alert>grid</alert> and <alert>lattice</alert>. We chose to use <alert>ggplot2</alert> in this book because it breaks plots into components in a way that permits beginners to create relatively complex and aesthetically pleasing plots using syntax that is intuitive and comparatively easy to remember.</p>
          
          <p>One reason <alert>ggplot2</alert> is generally more intuitive for beginners is that it uses a grammar of graphics, the <em>gg</em> in <alert>ggplot2</alert>. This is analogous to the way learning grammar can help a beginner construct hundreds of different sentences by learning just a handful of verbs, nouns, and adjectives without having to memorize each specific sentence. Similarly, by learning a handful of <alert>ggplot2</alert> building blocks and its grammar, you will be able to create hundreds of different plots.</p>
          
          <p>Another reason <alert>ggplot2</alert> is easy for beginners is that its default behavior is carefully chosen to satisfy the great majority of cases and is visually pleasing. As a result, it is possible to create informative and elegant graphs with relatively simple and readable code.</p>
          
          <p>One limitation is that <alert>ggplot2</alert> is designed to work exclusively with data tables in tidy format. However, a substantial percentage of datasets that beginners work with are in, or can be converted into, this format. An advantage of this approach is that, assuming that our data is tidy, <alert>ggplot2</alert> simplifies plotting code and the learning of grammar for a variety of plots.</p>
          
          <p>To use <alert>ggplot2</alert> you will have to learn several functions and arguments. These are hard to memorize, so we highly recommend you have the ggplot2 cheat sheet handy. You can get a copy from Posit's website or simply perform an internet search for "ggplot2 cheat sheet".</p>
        </introduction>
        
        <section xml:id="sec-components-of-graph">
          <title>The components of a graph</title>
          
          <p>We will construct a graph that summarizes the US murders dataset that looks like this:</p>
          
          <program language="r">
            <input>
library(dslabs)
library(ggthemes)
library(ggrepel)

r &lt;- murders |> 
  summarize(pop = sum(population), tot = sum(total)) |> 
  mutate(rate = tot/pop*10^6) |> pull(rate)

murders |> ggplot(aes(x = population/10^6, y = total, label = abb)) +  
  geom_abline(intercept = log10(r), lty = 2, col = "darkgrey") +
  geom_point(aes(color = region), size = 3) +
  geom_text_repel() + 
  scale_x_log10() +
  scale_y_log10() +
  xlab("Populations in millions (log scale)") + 
  ylab("Total number of murders (log scale)") +
  ggtitle("US Gun Murders in 2010") +
  scale_color_discrete(name = "Region") +
  theme_economist()
            </input>
          </program>
          
          <p>We can clearly see how much states vary across population size and the total number of murders. Not surprisingly, we also see a clear relationship between murder totals and population size. A state falling on the dashed grey line has the same murder rate as the US average. The four geographic regions are denoted with color, which depicts how most southern states have murder rates above the average.</p>
          
          <p>This data visualization shows us pretty much all the information in the data frame The code needed to make this plot is relatively simple. We will learn to create the plot part by part.</p>
          
          <p>The first step in learning <alert>ggplot2</alert> is to be able to break a graph apart into components. Let's break down the plot above and introduce some of the <alert>ggplot2</alert> terminology. The main three components to note are:</p>
          
          <ul>
            <li><p><alert>Data</alert>: The US murders data frame is being summarized. We refer to this as the <alert>data</alert> component.</p></li>
            
            <li><p><alert>Geometry</alert>: The plot above is a scatterplot. This is referred to as the <alert>geometry</alert> component. Other possible geometries include barplot, histogram, smooth densities, qqplot, and boxplot. We will learn more about these later in this chapter.</p></li>
            
            <li><p><alert>Aesthetic mapping</alert>: The plot uses several visual cues to represent the information provided by the dataset. The two most important cues in this plot are the point positions on the x-axis and y-axis, which represent population size and the total number of murders, respectively. Each point represents a different observation, and we <em>map</em> data about these observations to visual cues like x- and y-scale. Color is another visual cue that we map to region. We refer to this as the <alert>aesthetic mapping</alert> component. How we define the mapping depends on what <alert>geometry</alert> we are using.</p></li>
          </ul>
          
          <p>We also note that:</p>
          
          <ul>
            <li><p>The points are labeled with the state abbreviations.</p></li>
            <li><p>The range of the x-axis and y-axis appears to be defined by the range of the data. They are both on log-scales.</p></li>
            <li><p>There are labels, a title, a legend, and we use the style of The Economist magazine.</p></li>
          </ul>
          
          <p>The general approach in <alert>ggplot2</alert> is to construct the plot part by part by adding <em>layers</em> to a <c>ggplot</c> object, created by the <c>ggplot</c> function. Layers can define geometries, compute summary statistics, define what scales to use, or change styles. To add layers, we use the symbol <c>+</c>. In general, a line of code will look like this:</p>
          
          <blockquote>
            <p>DATA |&gt; <c>ggplot()</c> + LAYER 1 + LAYER 2 + ... + LAYER N</p>
          </blockquote>
          
          <p>We will now illustrate the basics of ggplot2 by dissecting how we construct the plot above.</p>
        </section>
        
        <section xml:id="sec-initializing-object">
          <title>Initializing an object with data</title>
          
          <p>We start by loading the relevant dataset which is in the <alert>dslabs package</alert>:</p>
          
          <program language="r">
            <input>
library(dslabs)
            </input>
          </program>
          
          <p>The first step in creating a <alert>ggplot2</alert> graph is to define a <c>ggplot</c> object. Typically most or all the layers will be mapping variables from the same dataset, so we associate this object with the relevant data frame</p>
          
          <program language="r">
            <input>
ggplot(data = murders)
            </input>
          </program>
          
          <p>or equivalently</p>
          
          <program language="r">
            <input>
murders |> ggplot()
            </input>
          </program>
          
          <p>Both these lines of code render a plot, in this case a blank slate since no geometry has been defined. The only style choice we see is a grey background, the default. We see a plot because an object was created and not assigned to a variable, it was automatically evaluated and printed. But we can assign our plot to an object in the usual way:</p>
          
          <program language="r">
            <input>
p &lt;- ggplot(data = murders)
            </input>
          </program>
          
          <p>To render the plot associated with this object, we simply print the object <c>p</c>. The following two lines of code each produce the same plot we see above:</p>
          
          <program language="r">
            <input>
print(p)
p
            </input>
          </program>
          
          <p>To summarize, <c>p</c> is a <c>ggplot</c> object with the <c>murders</c> data frame as its data component.</p>
        </section>
        
        <section xml:id="sec-adding-geometry">
          <title>Adding a geometry</title>
          
          <p>A common first step is to let <alert>ggplot2</alert> know what geometry to use. We often add multiple geometries, but we at least need one. In our example, we want to make a scatterplot. Geometries are added using functions. Taking a quick look at the cheat sheet, we see that we should use the function <c>geom_point</c>.</p>
          
          <p>Note that geometry function names follow the pattern: <c>geom_X</c> where X is the name of the geometry. Some examples include <c>geom_histogram</c>, <c>geom_boxplot</c>, and <c>geom_col</c>. We will discuss these further later in this chapter.</p>
          
          <p>For <c>geom_point</c> to run properly we need to provide data and a mapping. We have already assigned the <c>murders</c> data table to the object <c>p</c>. Next we need to add the layer <c>geom_point</c> to define the geometry. To find out what mappings are expected by this function, we read the <alert>Aesthetics</alert> section of the <c>geom_point</c> help file:</p>
          
          <blockquote>
            <p><alert>Aesthetics</alert><br/>
            geom_point() understands the following aesthetics (required aesthetics are in bold):</p>
            
            <ul>
              <li><p><alert>x</alert></p></li>
              <li><p><alert>y</alert></p></li>
              <li><p>alpha</p></li>
              <li><p>colour</p></li>
            </ul>
          </blockquote>
          
          <p>We see that at least two arguments are required: <c>x</c> and <c>y</c>. Next we explain how to map values from the dataset to the plot.</p>
        </section>
        
        <section xml:id="sec-aesthetic-mappings">
          <title>Aesthetic mappings</title>
          
          <p><em>Aesthetic mappings</em> describe how properties of the data connect with features of the graph, such as distance along an axis, size, or color. The <c>aes</c> function connects data with what we see on the graph by defining aesthetic mappings and will be one of the functions you use most often when plotting. This example produces a scatterplot of total murders versus population in millions:</p>
          
          <program language="r">
            <input>
murders |> ggplot() + geom_point(aes(population/10^6, total))
            </input>
          </program>
          
          <p>We didn't use the <c>x</c> and <c>y</c> to define the arguments because the help file showed these are the first and second expected arguments.</p>
          
          <p>The scale and labels are defined by default when adding this layer. Like <alert>dplyr</alert> functions, <c>aes</c> also uses the variable names from the data component: we can use <c>population</c> and <c>total</c> without having to call them as <c>murders$population</c> and <c>murders$total</c>. The behavior of recognizing the variables from the data component is specific to <c>aes</c>. With <alert>ggplot2</alert> functions other than <c>aes</c>, if you try to access the values of <c>population</c> or <c>total</c>, you receive an error.</p>
        </section>
        
        <section xml:id="sec-other-layers">
          <title>Other layers</title>
          
          <p>To shape the plot into its final form, we continue to add layers. A second layer in the plot we wish to make involves adding a label to each point to identify the state. The <c>geom_label</c> and <c>geom_text</c> functions permit us to add text to the plot with and without a rectangle behind the text, respectively.</p>
          
          <p>Because each point (each state in this case) has a label, we need an aesthetic mapping to make the connection between points and labels. By reading the help file, we learn that we supply the mapping between point and label through the <c>label</c> argument of <c>aes</c>. So the code looks like this:</p>
          
          <program language="r">
            <input>
murders |> ggplot() + 
  geom_point(aes(population/10^6, total)) +
  geom_text(aes(population/10^6, total, label = abb))
            </input>
          </program>
          
          <p>As an example of the unique behavior of <c>aes</c> related to variable names, note that if the added layer was <c>geom_text(aes(population/10^6, total), label = abb)</c>, we would result in an error since <c>abb</c> is now outside the call to <c>aes</c> and it is not an object in our workspace, it is a variable name in the data component of the <c>ggplot</c> object.</p>
        </section>
        
        <section xml:id="sec-global-aesthetic-mappings">
          <title>Global aesthetic mappings</title>
          
          <p>In the previous lines of code, we define the mapping <c>aes(population/10^6, total)</c> twice, once in each layer. We can avoid this by using a <em>global</em> aesthetic mapping. We can do this when we define the blank slate <c>ggplot</c> object. Remember that the <c>mapping</c> argument of <c>ggplot</c> function permits us to define aesthetic mappings. If we define a mapping in <c>ggplot</c>, all the geometries that are added as layers will default to this mapping. So we can simply write the following code to produce the previous plot:</p>
          
          <program language="r">
            <input>
murders |> ggplot(aes(population/10^6, total)) +
  geom_point() +
  geom_text(aes(label = abb))
            </input>
          </program>
          
          <p>Note that the mapping for <c>label</c> is only defined in <c>geom_text</c> because <c>geom_point</c> does not use this argument.</p>
          
          <p>If necessary, we can override the global mapping by defining a new mapping within each layer. These <em>local</em> definitions override the <em>global</em>. Here is an example:</p>
          
          <program language="r">
            <input>
murders |> ggplot(aes(population/10^6, total)) +
  geom_point() +
  geom_text(aes(x = 10, y = 800, label = "Hello there!"))
            </input>
          </program>
          
          <p>Clearly, the second call to <c>geom_text</c> does not use <c>population</c> and <c>total</c>.</p>
        </section>
        
        <section xml:id="sec-non-aesthetic-arguments">
          <title>Non-aesthetic arguments</title>
          
          <p>Each geometry function has arguments other than <c>aes</c> and <c>data</c>. They tend to be specific to the function and are not mapped to variables in the data. For example, in the plot we wish to make, the points are larger than the default size. As another example, to avoid putting the text on top of the point, we can use the <c>nudge_x</c> argument in <c>geom_text</c>. The code, with the arguments, looks like this:</p>
          
          <program language="r">
            <input>
murders |> ggplot(aes(population/10^6, total)) +
  geom_point(size = 3) +
  geom_text(aes(label = abb), nudge_x = 1.5)
            </input>
          </program>
          
          <p>Later in this chapter we learn a better way of assuring we can see the points and the labels.</p>
        </section>
        
        <section xml:id="sec-categories-as-colors">
          <title>Categories as colors</title>
          
          <p>For the final plot, we want each region to have a different color. Because this information comes from the data, it is a aesthetic mapping. For our example, we can map color to categories using the <c>color</c> mapping in the <c>geom_point</c> function as follows:</p>
          
          <program language="r">
            <input>
murders |> ggplot(aes(population/10^6, total)) +
  geom_point(aes(color = region), size = 3)
            </input>
          </program>
          
          <p>Note the <c>geom_point</c> automatically assigns a different color to each category and also adds a legend! Legends are usually desired, but to avoid adding a legend we can set the <c>geom_point</c> argument <c>show.legend = FALSE</c>.</p>
          
          <p>Note that <c>color</c> is also a non-aesthetic argument in several <alert>ggplot2</alert> functions, including <c>geom_point</c>. This argument is not used to map colors to categories, but to change the color of all the points. For example, if we wanted all the points to be blue we would change the layer to <c>geom_point(col = "blue", size = 3)</c>.</p>
          
          <program language="r">
            <input>
murders |> ggplot(aes(population/10^6, total)) +
  geom_point(color = "blue", size = 3)
            </input>
          </program>
        </section>
        
        <section xml:id="sec-updating-ggplot-objects">
          <title>Updating ggplot objects</title>
          
          <p>In <alert>ggplot2</alert> we build plots by parts. A useful feature of the package is that we can update existing <c>ggplot</c> objects by adding layers. For example, we can start by initializing an object with a dataset and a global aesthetic</p>
          
          <program language="r">
            <input>
p0 &lt;- murders |> ggplot(aes(population/10^6, total))
            </input>
          </program>
          
          <p>and then start adding layers. For example, we start by adding the scatter plot</p>
          
          <program language="r">
            <input>
p1 &lt;- p0 +  geom_point(aes(color = region), size = 3)
            </input>
          </program>
          
          <p>and labels:</p>
          
          <program language="r">
            <input>
p2 &lt;- p1 + geom_text(aes(label = abb), nudge_x = 0.1)
            </input>
          </program>
          
          <p>In the next few sections, we will be building on objects created in previous sections using this approach. This facilitates improving plots as well as testing options. Note that we changed the <c>nudge_x</c> from 1.5 to 0.1 because in the next section we will apply a log transformation and a smaller value is more appropriate.</p>
        </section>
        
        <section xml:id="sec-scales">
          <title>Scales</title>
          
          <p>One of the strengths of <alert>ggplot2</alert> is that the default behavior often is good enough to achieve our visualization goals. However, it also offers ways in which we can change these defaults. Many of these are changed through the <c>scales</c> functions.</p>
          
          <p>Two examples, are the <c>scale_x_continuous</c> and <c>scale_y_continuous</c> functions which lets us make adjustments to the x-axis and y-axis, respectively. In the final plot we are trying to produce scales in log-scale and this can be achieved by assigning the argument <c>trans = "log10"</c> in these functions. However, because this operation is so common, <alert>ggplot2</alert> includes <c>scale_x_log10</c> and <c>scale_y_log10</c> functions. We can achieve the desired transformation by adding these layers:</p>
          
          <program language="r">
            <input>
p3 &lt;- p2 + scale_x_log10() + scale_y_log10() 
p3
            </input>
          </program>
          
          <p>Be aware that <alert>ggplot2</alert> offers immense flexibility, particularly through the scales functions. We've introduced just one of the many available. In subsequent chapters of this book, we'll provide examples as they become pertinent to our visualizations. However, to familiarize yourself with these functions, we recommend consulting the ggplot2 cheat sheet or conducting internet searches as specific needs arise.</p>
        </section>
        
        <section xml:id="sec-annotations">
          <title>Annotations</title>
          
          <p>We often want to add annotations to figures that are not derived directly from the aesthetic mapping. Examples of annotation functions are <c>labs</c>, <c>annotate</c>, and <c>geom_abline</c>. The <c>labs</c> function permits adding a title, subtitle, caption, and other labels. Note these can also be defined individually using the functions such as <c>xlab</c>, <c>ylab</c> and <c>ggtitle</c>.</p>
          
          <p>The <c>labs</c> function also allows another change needed for our desired plot: changing the legend title. Because the legend for the color mapping, this is achieved with the <c>color = "NEW_TITLE"</c> argument:</p>
          
          <program language="r">
            <input>
p4 &lt;- p3 + labs(title = "US Gun Murders in 2010",
                x = "Populations in millions (log scale)", 
                y = "Total number of murders (log scale)",
                color = "Region")
p4
            </input>
          </program>
          
          <p>Our desired final plot includes a line that represents the average murder rate for the entire country. Once we determine the per million rate to be <m>r</m>, the desired line is defined by the formula: <m>y = r x</m>, with <m>y</m> and <m>x</m> our axes: total murders and population in millions, respectively. In the log-scale this line turns into: <m>\log(y) = \log(r) + \log(x)</m>, a line with slope 1 and intercept <m>\log(r)</m>. We can compute <c>r</c> using:</p>
          
          <program language="r">
            <input>
r &lt;- murders |> 
  summarize(rate = sum(total)/sum(population)*10^6) |> 
  pull(rate)
            </input>
          </program>
          
          <p>To add a line we use the <c>geom_abline</c> function. The <c>ab</c> in the name reminds us we are supplying the intercept (<c>a</c>) and slope (<c>b</c>). The default line has slope 1 and intercept 0 so we only have to define the intercept. Note that the final plot has a dashed line type and is grey and these can be changed through the <c>lty</c> (line type) and <c>color</c> non aesthetic arguments. We add the layer like this:</p>
          
          <program language="r">
            <input>
p5 &lt;- p4 + 
  geom_abline(intercept = log10(r), lty = 2, color = "darkgrey") 
p5
            </input>
          </program>
          
          <p>Note that <c>geom_abline</c> does not use any mappings from the data object, once we have the slope.</p>
          
          <p>We are almost there! All we have to do is add optional changes to the style.</p>
        </section>
        
        <section xml:id="sec-add-on-packages">
          <title>Add-on packages</title>
          
          <p>The power of <alert>ggplot2</alert> is augmented further due to the availability of add-on packages. The remaining changes needed to put the finishing touches on our plot require the <alert>ggthemes</alert> and <alert>ggrepel</alert> packages.</p>
          
          <p>The style of a <alert>ggplot2</alert> graph can be changed using the <c>theme</c> functions. Several themes are included as part of the <alert>ggplot2</alert> package. In fact, for most of the plots in this book, we use a function in the <alert>dslabs</alert> package that automatically sets a default theme:</p>
          
          <program language="r">
            <input>
ds_theme_set()
            </input>
          </program>
          
          <p>Many other themes are added by the package <alert>ggthemes</alert>. Among those is the <c>theme_economist</c> theme that we use here. After installing the package, you can change the style by adding a layer like this:</p>
          
          <program language="r">
            <input>
library(ggthemes)
p6 &lt;- p5 + theme_economist()
            </input>
          </program>
          
          <p>You can see how some of the other themes look by simply changing the function. For instance, you might try the <c>theme_fivethirtyeight()</c> theme instead.</p>
          
          <p>The final change is to better position of the labels to avoid crowding; currently, some of the labels fall on top of each other. The add-on package <alert>ggrepel</alert> includes a geometry that adds labels while ensuring that they don't fall on top of each other. We simply change <c>geom_text</c> to <c>geom_text_repel</c>.</p>
        </section>
        
        <section xml:id="sec-putting-it-all-together">
          <title>Putting it all together</title>
          
          <p>Now that we are done testing, we can write one line of code that produces our desired plot from scratch.</p>
          
          <program language="r">
            <input>
library(ggthemes)
library(ggrepel)

r &lt;- murders |> 
  summarize(rate = sum(total) /  sum(population) * 10^6) |>
  pull(rate)

murders |> 
  ggplot(aes(population/10^6, total)) +   
  geom_abline(intercept = log10(r), lty = 2, color = "darkgrey") +
  geom_point(aes(col = region), size = 3) +
  geom_text_repel(aes(label = abb)) + 
  scale_x_log10() +
  scale_y_log10() +
  labs(title = "US Gun Murders in 2010",
                x = "Populations in millions (log scale)", 
                y = "Total number of murders (log scale)",
                color = "Region") +
  theme_economist()
            </input>
          </program>
        </section>
        
        <section xml:id="sec-other-geometries">
          <title>Geometries</title>
          
          <p>In our illustrative example we introduced the scatterplot geometry <c>geom_point</c>. However, <alert>ggplot2</alert> has many others and here we demonstrate how to generate plots related to distributions, specifically the plots shown in <xref ref="ch-visualizing-data-distributions"/>.</p>
          
          <subsection xml:id="subsec-barplots">
            <title>Barplots</title>
            
            <p>To generate a barplot we can use the <c>geom_bar</c> geometry. The default is to count the number of each category and draw a bar. Here is the plot for the regions of the US.</p>
            
            <program language="r">
              <input>
murders |> ggplot(aes(region)) + geom_bar()
              </input>
            </program>
            
            <p>However, we often already have a table with the numbers we want to present as a barplot. Here is an example of such a table:</p>
            
            <program language="r">
              <input>
tab &lt;- murders |> 
  count(region) |> 
  mutate(proportion = n/sum(n))
              </input>
            </program>
            
            <p>In this case, we use <c>geom_col</c> instead of <c>geom_bar</c>:</p>
            
            <program language="r">
              <input>
tab |> ggplot(aes(region, proportion)) + geom_col()
              </input>
            </program>
          </subsection>
          
          <subsection xml:id="subsec-histograms-geom">
            <title>Histograms</title>
            
            <p>To generate histograms we use <c>geom_histogram</c>. By looking at the help file for this function, we learn that the only required argument is <c>x</c>, the variable for which we will construct a histogram. We dropped the <c>x</c> because we know it is the first argument. The code looks like this:</p>
            
            <program language="r">
              <input>
heights |> filter(sex == "Female") |> 
  ggplot(aes(height)) + 
  geom_histogram(binwidth = 1, fill = "blue", col = "black")
              </input>
            </program>
            
            <p>Note that we use the optional arguments <c>binwidth = 1</c> to change the bin size to 1 inch. The default is to create 30 bins. We also use the optional arguments <c>fill = "blue"</c> and <c>col = "black"</c> to fill the bars with colors and use a different color to outline the bars.</p>
          </subsection>
          
          <subsection xml:id="subsec-density-plots-geom">
            <title>Density plots</title>
            
            <p>To create a smooth density, we use the <c>geom_density</c>. To make a smooth density plot with the data previously shown as a histogram we can use this code:</p>
            
            <program language="r">
              <input>
heights |> 
  filter(sex == "Female") |>
  ggplot(aes(height)) +
  geom_density(fill = "blue")
              </input>
            </program>
            
            <p>Note that we use the optional argument <c>fill</c> to change the color. To change the smoothness of the density, we use the <c>adjust</c> argument to multiply the default value by that <c>adjust</c>. For example, if we want the bandwidth to be twice as big we use:</p>
            
            <program language="r">
              <input>
heights |> 
  filter(sex == "Female") |>
  ggplot(aes(height)) +
  geom_density(fill="blue", adjust = 2)
              </input>
            </program>
          </subsection>
          
          <subsection xml:id="subsec-boxplots-geom">
            <title>Boxplots</title>
            
            <p>The geometry for boxplot is <c>geom_boxplot</c>. As discussed, boxplots are useful for comparing distributions. For example, below are the previously shown heights for women, but compared to men. For this geometry, we need arguments <c>x</c> as the categories, and <c>y</c> as the values.</p>
            
            <program language="r">
              <input>
heights |> ggplot(aes(sex, height)) +
  geom_boxplot()
              </input>
            </program>
          </subsection>
          
          <subsection xml:id="subsec-images">
            <title>Images</title>
            
            <p>Images were not needed for the concepts described in this chapter, but we will use images in future chapters, so we introduce the two geometries used to plot images: <c>geom_tile</c> and <c>geom_raster</c>. They behave similarly; to see how they differ, please consult the help file. To create an image in <alert>ggplot2</alert> we need a data frame with the x and y coordinates as well as the values associated with each of these. Here is a data frame.</p>
            
            <program language="r">
              <input>
x &lt;- expand.grid(x = 1:12, y = 1:10) |> mutate(z = 1:120)
              </input>
            </program>
            
            <p>Note that this is the tidy version of a matrix, <c>matrix(1:120, 12, 10)</c>. To plot the image we use the following code:</p>
            
            <program language="r">
              <input>
x |> ggplot(aes(x, y, fill = z)) + geom_raster()
              </input>
            </program>
            
            <p>With these images you will often want to change the color scale. This can be done through the <c>scale_fill_gradientn</c> layer.</p>
            
            <program language="r">
              <input>
x |> ggplot(aes(x, y, fill = z)) + 
  geom_raster() + 
  scale_fill_gradientn(colors =  terrain.colors(10, 1))
              </input>
            </program>
          </subsection>
        </section>
        
        <section xml:id="sec-grids-of-plots">
          <title>Grids of plots</title>
          
          <p>There are often reasons to graph plots next to each other. The <alert>gridExtra</alert> package permits us to do that. Here are the graphs <c>p5</c> and <c>p6</c> created in the previous sections:</p>
          
          <program language="r">
            <input>
library(gridExtra)
grid.arrange(p5, p6, ncol = 2)
            </input>
          </program>
        </section>
        
        <section xml:id="sec-ggplot2-exercises">
          <title>Exercises</title>
          
          <p>Start by loading the <alert>dplyr</alert> and <alert>ggplot2</alert> library as well as the <c>murders</c> and <c>heights</c> data.</p>
          
          <program language="r">
            <input>
library(dplyr)
library(ggplot2)
library(dslabs)
            </input>
          </program>
          
          <ol>
            <li>
              <p>With <alert>ggplot2</alert>, plots can be saved as objects. For example we can associate a dataset with a plot object like this</p>
              
              <program language="r">
                <input>
p &lt;- ggplot(data = murders)
                </input>
              </program>
              
              <p>Because <c>data</c> is the first argument we don't need to spell it out</p>
              
              <program language="r">
                <input>
p &lt;- ggplot(murders)
                </input>
              </program>
              
              <p>and we can also use the pipe:</p>
              
              <program language="r">
                <input>
p &lt;- murders |> ggplot()
                </input>
              </program>
              
              <p>What is class of the object <c>p</c>?</p>
            </li>
            
            <li>
              <p>Remember that to print an object you can use the command <c>print</c> or simply type the object. Print the object <c>p</c> defined in exercise one and describe what you see.</p>
              
              <p>a.  Nothing happens.<br/>
              b.  A blank slate plot.<br/>
              c.  A scatterplot.<br/>
              d.  A histogram.</p>
            </li>
            
            <li><p>Using the pipe <c>|&gt;</c>, create an object <c>p</c> but this time associated with the <c>heights</c> dataset instead of the <c>murders</c> dataset.</p></li>
            
            <li><p>What is the class of the object <c>p</c> you have just created?</p></li>
            
            <li>
              <p>Now we are going to add a layer and the corresponding aesthetic mappings. For the murders data we plotted total murders versus population sizes. Explore the <c>murders</c> data frame to remind yourself what are the names for these two variables and select the correct answer. <alert>Hint</alert>: Look at <c>?murders</c>.</p>
              
              <p>a.  <c>state</c> and <c>abb</c>.<br/>
              b.  <c>total_murders</c> and <c>population_size</c>.<br/>
              c.  <c>total</c> and <c>population</c>.<br/>
              d.  <c>murders</c> and <c>size</c>.</p>
            </li>
            
            <li>
              <p>To create the scatterplot we add a layer with <c>geom_point</c>. The aesthetic mappings require us to define the x-axis and y-axis variables, respectively. So the code looks like this:</p>
              
              <program language="r">
                <input>
murders |> ggplot(aes(x = , y = )) +
  geom_point()
                </input>
              </program>
              
              <p>except we have to define the two variables <c>x</c> and <c>y</c>. Fill this out with the correct variable names.</p>
            </li>
            
            <li>
              <p>Note that if we don't use argument names, we can obtain the same plot by making sure we enter the variable names in the right order like this:</p>
              
              <program language="r">
                <input>
murders |> ggplot(aes(population, total)) +
  geom_point()
                </input>
              </program>
              
              <p>Remake the plot but now with total in the x-axis and population in the y-axis.</p>
            </li>
            
            <li>
              <p>If instead of points we want to add text, we can use the <c>geom_text()</c> or <c>geom_label()</c> geometries. The following code</p>
              
              <program language="r">
                <input>
murders |> ggplot(aes(population, total)) + geom_label()
                </input>
              </program>
              
              <p>will give us the error message: <c>Error: geom_label requires the following missing aesthetics: label</c></p>
              
              <p>Why is this?</p>
              
              <p>a.  We need to map a character to each point through the label argument in aes.<br/>
              b.  We need to let <c>geom_label</c> know what character to use in the plot.<br/>
              c.  The <c>geom_label</c> geometry does not require x-axis and y-axis values.<br/>
              d.  <c>geom_label</c> is not a ggplot2 command.</p>
            </li>
            
            <li><p>Rewrite the code above to use abbreviation as the label through <c>aes</c></p></li>
            
            <li>
              <p>Change the color of the labels to blue. How will we do this?</p>
              
              <p>a.  Adding a column called <c>blue</c> to <c>murders</c>.<br/>
              b.  Because each label needs a different color, we map the colors through <c>aes</c>.<br/>
              c.  Use the <c>color</c> argument in <c>ggplot</c>.<br/>
              d.  Because we want all labels to be blue, we do not need to map colors, just use the color argument in <c>geom_label</c>.</p>
            </li>
            
            <li><p>Rewrite the code above to make the labels blue.</p></li>
            
            <li>
              <p>Now suppose we want to use color to represent the different regions. In this case which of the following is most appropriate:</p>
              
              <p>a.  Adding a column called <c>color</c> to <c>murders</c> with the color we want to use.<br/>
              b.  Because each label needs a different color, we map the colors through the color argument of <c>aes</c> .<br/>
              c.  Use the <c>color</c> argument in <c>ggplot</c>.<br/>
              d.  Because we want all colors to be blue, we do not need to map colors, just use the color argument in <c>geom_label</c>.</p>
            </li>
            
            <li><p>Rewrite the code above to make the labels' colors be determined by the state's region.</p></li>
            
            <li>
              <p>Now we are going to change the x-axis to a log scale to account for the fact the distribution of population is skewed. Let's start by defining an object <c>p</c> holding the plot we have made up to now</p>
              
              <program language="r">
                <input>
p &lt;- murders |> 
  ggplot(aes(population, total, label = abb, color = region)) +
  geom_label()
                </input>
              </program>
              
              <p>To change the y-axis to a log scale we learned about the <c>scale_x_log10()</c> function. Add this layer to the object <c>p</c> to change the scale and render the plot.</p>
            </li>
            
            <li><p>Repeat the previous exercise but now change both axes to be in the log scale.</p></li>
            
            <li><p>Now edit the code above to add the title "Gun murder data" to the plot. Hint: use the <c>ggtitle</c> function.</p></li>
            
            <li>
              <p>Now we are going to use the <c>geom_histogram</c> function to make a histogram of the heights in the <c>height</c> data frame. When reading the documentation for this function we see that it requires just one mapping, the values to be used for the histogram. Make a histogram of all the plots.</p>
              
              <p>What is the variable containing the heights?</p>
              
              <p>a.  <c>sex</c><br/>
              b.  <c>heights</c><br/>
              c.  <c>height</c><br/>
              d.  <c>heights$height</c></p>
            </li>
            
            <li><p>Now create a ggplot object using the pipe to assign the heights data to a ggplot object. Assign <c>height</c> to the x values through the <c>aes</c> function.</p></li>
            
            <li><p>Now we are ready to add a layer to actually make the histogram. Use the object created in the previous exercise and the <c>geom_histogram</c> function to make the histogram.</p></li>
            
            <li>
              <p>Note that when we run the code in the previous exercise we get the warning: <c>stat_bin()</c> using <c>bins = 30</c>. Pick better value with <c>binwidth</c>.</p>
              
              <p>Use the <c>binwidth</c> argument to change the histogram made in the previous exercise to use bins of size 1 inch.</p>
            </li>
            
            <li><p>Instead of a histogram, we are going to make a smooth density plot. In this case we will not make an object, but instead render the plot with one line of code. Change the geometry in the code previously used to make a smooth density instead of a histogram.</p></li>
            
            <li><p>Now we are going to make a density plot for males and females separately. We can do this using the <c>group</c> argument. We assign groups via the aesthetic mapping as each point needs to a group before making the calculations needed to estimate a density.</p></li>
            
            <li><p>We can also assign groups through the <c>color</c> argument. This has the added benefit that it uses colors to distinguish the groups. Change the code above to use color.</p></li>
            
            <li>
              <p>We can also assign groups through the <c>fill</c> argument. This has the added benefit that it uses colors to distinguish the groups, like this:</p>
              
              <program language="r">
                <input>
heights |> 
  ggplot(aes(height, fill = sex)) + 
  geom_density()
                </input>
              </program>
              
              <p>However, here the second density is drawn over the other. We can make the curves more visible by using alpha blending to add transparency. Set the alpha parameter to 0.2 in the <c>geom_density</c> function to make this change.</p>
            </li>
          </ol>
        </section>
      </chapter>

      <chapter xml:id="ch-data-visualization-principles">
        <title>Data visualization principles</title>
        
          <p>In this chapter we aim to provide some general principles we can use as a guide for effective data visualization. Much of this section is based on a talk by Karl Broman titled "Creating Effective Figures and Tables" and includes some of the figures which were made with code that Karl makes available on his GitHub repository, as well as class notes from Peter Aldhous' Introduction to Data Visualization course. Following Karl's approach, we show some examples of plot styles we should avoid, explain how to improve them, and use these as motivation for a list of principles. We compare and contrast plots that follow these principles to those that don't.</p>

          <p>The principles are mostly based on research related to how humans detect patterns and make visual comparisons. The preferred approaches are those that best fit the way our brains process visual information. When deciding on a visualization approach, it is also important to keep our goal in mind. We may be comparing a viewable number of quantities, describing distributions for categories or numeric values, comparing the data from two groups, or describing the relationship between two variables. As a final note, we want to emphasize that it is important to adapt and optimize graphs to the audience. For example, an exploratory plot made for ourselves will be different than a chart intended to communicate a finding to a general audience.</p>

          <p>In this chapter we focus on the principles and do not show code (code can be viewed on GitHub). In <xref ref="sec-dataviz-in-practice"/>, we apply these principles in case study and do show code.</p>

          <program language="r">
            <input>
library(tidyverse)
library(dslabs)
library(gridExtra)
            </input>
          </program>

        <section xml:id="sec-encoding-data-using-visual-cues">
          <title>Encoding data using visual cues</title>

          <p>We start by describing some principles for encoding data. There are several visual cues at our disposal including position, aligned lengths, angles, area, brightness, and color hue.</p>

          <program language="r">
            <input>
browsers &lt;- data.frame(Browser = rep(c("Opera","Safari","Firefox","IE","Chrome"),2),
                       Year = rep(c(2000, 2015), each = 5),
                       Percentage = c(3,21,23,28,26, 2,22,21,27,29)) |&gt;
  mutate(Browser = reorder(Browser, Percentage))
            </input>
          </program>

          <p>To illustrate how some of these visual cues compare, let's suppose we want to report the results from two hypothetical polls regarding browser preference taken in 2000 and then 2015. For each year, we are simply comparing five quantities – the five percentages. A widely used graphical representation of percentages, popularized by Microsoft Excel, is the pie chart:</p>

          <program language="r">
            <input>
library(ggthemes)
p1 &lt;- browsers |&gt; ggplot(aes(x = "", y = Percentage, fill = Browser)) +
  geom_col(width = 1, col = "black")  + coord_polar(theta = "y") +
  xlab("") + ylab("") +
  theme(axis.text=element_blank(), 
        axis.ticks = element_blank(), 
        panel.grid  = element_blank()) +
  facet_grid(.~Year)
p1
            </input>
          </program>

          <p>Here we are representing quantities with both areas and angles, since both the angle and area of each pie slice are proportional to the quantity the slice represents. This turns out to be a sub-optimal choice since, as demonstrated by perception studies, humans are not good at precisely quantifying angles and are even worse when area is the only available visual cue. The donut chart is an example of a plot that uses only area:</p>

          <program language="r">
            <input>
browsers |&gt; ggplot(aes(x = 2, y = Percentage, fill = Browser)) +
  geom_col(width = 1, col = "black")  + 
  scale_x_continuous(limits=c(0.5,2.5)) + coord_polar(theta = "y") +
  xlab("") + ylab("") +
  theme(axis.text=element_blank(), 
        axis.ticks = element_blank(), 
        panel.grid  = element_blank()) +
  facet_grid(.~Year)
            </input>
          </program>

          <p>To see how hard it is to quantify angles and area, note that the rankings and all the percentages in the plots above changed from 2000 to 2015. Can you determine the actual percentages and rank the browsers' popularity? Can you see how the percentages changed from 2000 to 2015? It is not easy to tell from the plot.</p>

          <p>In this case, simply showing the numbers is not only clearer, but would also save on printing costs if printing a paper copy:</p>

          <program language="r">
            <input>
if(knitr::is_html_output()){
  browsers |&gt; spread(Year, Percentage) |&gt; knitr::kable("html") |&gt;
    kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
   browsers |&gt; spread(Year, Percentage) |&gt; 
    knitr::kable("latex", booktabs = TRUE) |&gt;
    kableExtra::kable_styling(font_size = 8)
}
            </input>
          </program>

          <p>The preferred way to plot these quantities is to use length and position as visual cues, since humans are much better at judging linear measures. The barplot uses this approach by using bars of length proportional to the quantities of interest. By adding horizontal lines at strategically chosen values, in this case at every multiple of 10, we ease the visual burden of quantifying through the position of the top of the bars. Compare and contrast the information we can extract from the two figures.</p>

          <program language="r">
            <input>
p2 &lt;-browsers |&gt;
  ggplot(aes(Browser, Percentage)) + 
  geom_col(width=0.5) +
  ylab("Percent using the Browser") +
  facet_grid(.~Year)
grid.arrange(p1, p2, nrow = 2)
            </input>
          </program>

          <p>Notice how much easier it is to see the differences in the barplot. In fact, we can now determine the actual percentages by following a horizontal line to the x-axis.</p>

          <p>If for some reason you need to make a pie chart, label each pie slice with its respective percentage so viewers do not have to infer them from the angles or area:</p>

          <program language="r">
            <input>
library(scales)
browsers &lt;- filter(browsers, Year == 2015)
at &lt;- with(browsers, 100 - cumsum(c(0,Percentage[-length(Percentage)])) - 0.5*Percentage)  
label &lt;- percent(browsers$Percentage/100)
browsers |&gt; ggplot(aes(x = "", y = Percentage, fill = Browser)) +
  geom_col(width = 1, col = "black")  + coord_polar(theta = "y") +
  xlab("") + ylab("") + ggtitle("2015") +
  theme(axis.text=element_blank(), 
        axis.ticks = element_blank(), 
        panel.grid  = element_blank()) +
  annotate(geom = "text", 
              x = 1.62, 
              y =  at, 
              label = label, size=4)
            </input>
          </program>

          <p>In general, when displaying quantities, position and length are preferred over angles and/or area. Brightness and color are even harder to quantify than angles. But, as we will see later, they are sometimes useful when more than two dimensions must be displayed at once.</p>

        </section>

        <section xml:id="sec-know-when-to-include-0">
          <title>Know when to include 0</title>

          <p>When using length as a visual cue, it is misinformative not to start the bars at 0. This is because, by using length as a visual cue, say with a barplot, we are implying the length is proportional to the quantities being displayed. By avoiding 0, relatively small differences can be made to look much bigger than they actually are. This approach is often used by politicians or media organizations trying to exaggerate a difference. Below is an illustrative example:</p>

          <figure>
            <image source="dataviz/img/class2_8.jpg"/>
          </figure>

          <p>(Source: Fox News, via Media Matters.)</p>

          <p>From the plot above, it appears that apprehensions have almost tripled when, in fact, they have only increased by about 16%. Starting the graph at 0 illustrates this clearly:</p>

          <program language="r">
            <input>
data.frame(Year = as.character(c(2011, 2012, 2013)),Southwest_Border_Apprehensions = c(165244,170223,192298)) |&gt;
  ggplot(aes(Year, Southwest_Border_Apprehensions )) +
  geom_col(fill = "yellow", col = "black", width = 0.65) 
            </input>
          </program>

          <p>Here is another example:</p>

          <p><!--http://i2.wp.com/flowingdata.com/wp-content/uploads/2012/08/Bush-cuts.png--></p>

          <figure>
            <image source="dataviz/img/Bush-cuts.png"/>
          </figure>

          <p>(Source: Fox News, via Flowing Data.)</p>

          <p>This plot makes a 13% increase look like a five fold change. Here is the appropriate plot:</p>

          <program language="r">
            <input>
data.frame(date = c("Now", "Jan 1, 2013"), tax_rate = c(35, 39.6)) |&gt;
  mutate(date = reorder(date, tax_rate)) |&gt;
  ggplot(aes(date, tax_rate)) + 
  ylab("") + xlab("") +
  geom_col(fill = "yellow", col = "black", width = 0.5) + 
  ggtitle("Top Tax Rate If Bush Tax Cut Expires")
            </input>
          </program>

          <p>Finally, here is an extreme example that makes a very small difference of under 2% look like a 10-100 fold change:</p>

          <p><!-- http://i2.wp.com/flowingdata.com/wp-content/uploads/2012/08/Bush-cuts.png--></p>

          <figure>
            <image source="dataviz/img/venezuela-election.png"/>
          </figure>

          <p>(Source: Venezolana de Televisión via El Mundo.)</p>

          <p>Here is the appropriate plot:</p>

          <program language="r">
            <input>
data.frame(Candidate = factor(c("Maduro", "Capriles"), levels = c("Maduro", "Capriles")),
           Percent = c(50.66, 49.07)) |&gt;
  ggplot(aes(Candidate, Percent, fill = Candidate)) +
  geom_col(width = 0.65, show.legend = FALSE) 
            </input>
          </program>

          <p>When using position rather than length, it is then not necessary to include 0. This is particularly the case when we want to compare differences between groups relative to the within-group variability. Here is an illustrative example showing country average life expectancy stratified across continents in 2012:</p>

          <program language="r">
            <input>
p1 &lt;- gapminder |&gt; filter(year == 2012) |&gt;
  ggplot(aes(continent, life_expectancy)) +
  geom_jitter(width = 0.1)
p2 &lt;- p1 +
  scale_y_continuous(limits = c(0, 84))
grid.arrange(p2, p1, ncol = 2)
            </input>
          </program>

          <p>Note that in the plot on the left, which includes 0, the space between 0 and 43 adds no information and makes it harder to compare the between and within group variability.</p>

        </section>

        <section xml:id="sec-do-not-distort-quantities">
          <title>Do not distort quantities</title>

          <p>During President Barack Obama’s 2011 State of the Union Address, the following chart was used to compare the US GDP to the GDP of four competing nations:</p>

          <p><!--idea from http://paldhous.github.io/ucb/2016/img/class2_30.jpg--> <!--screen shot my own from state of the union--></p>

          <figure>
            <image source="dataviz/img/state-of-the-union.png"/>
          </figure>

          <p>(Source: The 2011 State of the Union Address)</p>

          <p>Judging by the area of the circles, the US appears to have an economy over five times larger than China's and over 30 times larger than France's. However, if we look at the actual numbers, we see that this is not the case. The actual ratios are 2.6 and 5.8 times bigger than China and France, respectively. The reason for this distortion is that the radius, rather than the area, was made to be proportional to the quantity, which implies that the proportion between the areas is squared: 2.6 turns into 6.5 and 5.8 turns into 34.1. Here is a comparison of the circles we get if we make the value proportional to the radius and to the area:</p>

          <program language="r">
            <input>
gdp &lt;- c(14.6, 5.7, 5.3, 3.3, 2.5)
gdp_data &lt;- data.frame(Country = rep(c("United States", "China", "Japan", "Germany", "France"),2),
           y = factor(rep(c("Radius","Area"),each=5), levels = c("Radius", "Area")),
           GDP= c(gdp^2/min(gdp^2), gdp/min(gdp))) |&gt; 
   mutate(Country = reorder(Country, GDP))
gdp_data |&gt; 
  ggplot(aes(Country, y, size = GDP)) + 
  geom_point(show.legend = FALSE, color = "blue") + 
  scale_size(range = c(2,20)) +
  coord_flip() + ylab("") + xlab("")
            </input>
          </program>

          <p>Not surprisingly, __ggplot2__ defaults to using area rather than radius. Of course, in this case, we really should not be using area at all since we can use position and length:</p>

          <program language="r">
            <input>
data.frame(Country = c("United States", "China", "Japan", "Germany", "France"), GDP = gdp) |&gt;
  mutate(Country = reorder(Country, GDP)) |&gt;
  ggplot(aes(Country, GDP)) + 
  geom_col(width = 0.5) + 
  ylab("GDP in trillions of US dollars")
            </input>
          </program>

        </section>

        <section xml:id="sec-order-categories-by-a-meaningful-value">
          <title>Order categories by a meaningful value</title>

          <p>When one of the axes is used to show categories, as is done in barplots and boxplots, the default __ggplot2__ behavior is to order the categories alphabetically when they are defined by character strings. If they are defined by factors, they are ordered by the factor levels. We rarely want to use alphabetical order. Instead, we should order by a meaningful quantity. In all the cases above, the barplots were ordered by the values being displayed. The exception was the graph showing barplots comparing browsers. In this case, we kept the order the same across the barplots to ease the comparison. Specifically, instead of ordering the browsers separately in the two years, we ordered both years by the average value of 2000 and 2015.</p>

          <p>To appreciate how the right order can help convey a message, suppose we want to create a plot to compare the murder rate across states. We are particularly interested in the most dangerous and safest states. Note the difference when we order alphabetically (the default) versus when we order by the actual rate:</p>

          <program language="r">
            <input>
p1 &lt;- murders |&gt; mutate(murder_rate = total / population * 100000) |&gt;
  ggplot(aes(state, murder_rate)) +
  geom_col() +
  coord_flip() +
  theme(axis.text.y = element_text(size = 8))  +
  xlab("")

p2 &lt;- murders |&gt; mutate(murder_rate = total / population * 100000) |&gt;
  mutate(state = reorder(state, murder_rate)) |&gt;
  ggplot(aes(state, murder_rate)) +
  geom_col() +
  coord_flip() +
  theme(axis.text.y = element_text(size = 8))  +
  xlab("")

grid.arrange(p1, p2, ncol = 2)
            </input>
          </program>

          <p>Here is an example showing boxplots of income distributions across regions. Here are the two versions plotted against each other:</p>

          <program language="r">
            <input>
past_year &lt;- 1970
p1 &lt;- gapminder |&gt; 
  mutate(dollars_per_day = gdp/population/365) |&gt;
  filter(year == past_year &amp; !is.na(gdp)) |&gt;
  ggplot(aes(region, dollars_per_day)) +
  geom_boxplot() +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  xlab("")

p2 &lt;- gapminder |&gt; 
  mutate(dollars_per_day = gdp/population/365) |&gt;
  filter(year == past_year &amp; !is.na(gdp)) |&gt;
  mutate(region = reorder(region, dollars_per_day, FUN = median)) |&gt;
  ggplot(aes(region, dollars_per_day)) +
  geom_boxplot() +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  xlab("")

grid.arrange(p1, p2, nrow=1)
            </input>
          </program>

          <p>The first orders the regions alphabetically, while the second orders them by the group's median.</p>

        </section>

        <section xml:id="sec-show-the-data">
          <title>Show the data</title>

          <p>We have focused on displaying single quantities across categories. We now shift our attention to displaying data, with a focus on comparing groups.</p>

          <p>To motivate the principle, "show the data", we go back to our artificial example of describing heights to ET, an extraterrestrial. This time let's assume ET is interested in the difference in heights between males and females. A commonly seen plot used for comparisons between groups, popularized by software such as Microsoft Excel, is the dynamite plot, which shows the average and standard errors (standard errors are defined in a later chapter, but do not confuse them with the standard deviation of the data). The plot looks like this:</p>

          <program language="r">
            <input>
p1 &lt;- heights |&gt; 
  group_by(sex) |&gt; 
  summarize(average = mean(height), se=sd(height)/sqrt(n())) |&gt;
  ggplot(aes(sex, average)) + 
  theme_excel() + 
  geom_errorbar(aes(ymin = average - 2*se, ymax = average+2*se), width = 0.25) +
  geom_col(width=0.5, fill = "blue", color = "black") +
  ylab("Height in inches")
p1
            </input>
          </program>

          <p>The average of each group is represented by the top of each bar and the antennae extend out from the average to the average plus two standard errors.  If all ET receives is this plot, he will have little information on what to expect if he meets a group of human males and females. The bars go to 0: does this mean there are tiny humans measuring less than one foot? Are all males taller than the tallest females? Is there a range of heights? ET can't answer these questions since we have provided almost no information on the height distribution.</p>

          <p>This brings us the "show the data" principle. This simple __ggplot2__ code already generates a more informative plot than the barplot by simply showing all the data points:</p>

          <program language="r">
            <input>
#| echo: false
heights |&gt; 
  ggplot(aes(sex, height)) + 
  geom_point() 
            </input>
          </program>

          <p>For example, this plot gives us an idea of the range of the data. However, this plot has limitations as well, since we can't really see all the points plotted for females and males, respectively, and many points are plotted on top of each other. As we have previously described, visualizing the distribution is much more informative. But before doing this, we point out two ways we can improve a plot showing all the points.</p>

          <p>The first is to add <em>jitter</em>, which adds a small random shift to each point. In this case, adding horizontal jitter does not alter the interpretation, since the point heights do not change, but we minimize the number of points that fall on top of each other and, therefore, get a better visual sense of how the data is distributed. A second improvement comes from using <em>alpha blending</em>: making the points somewhat transparent. The more points fall on top of each other, the darker the plot, which also helps us get a sense of how the points are distributed. Here is the same plot with jitter and alpha blending:</p>

          <program language="r">
            <input>
heights |&gt; 
  ggplot(aes(sex, height)) +
  geom_jitter(width = 0.05, alpha = 0.2) 
            </input>
          </program>

          <p>Now we start getting a sense that, on average, males are taller than females. We also note dark horizontal bands of points, demonstrating that many report values that are rounded to the nearest integer.</p>

        </section>

        <section xml:id="sec-ease-comparisons">
          <title>Ease comparisons</title>

          <subsection xml:id="subsec-use-common-axes">
            <title>Use common axes</title>

            <p>Since there are so many points, it is more effective to show distributions rather than individual points. We therefore show histograms for each group:</p>

            <program language="r">
              <input>
heights |&gt; 
  ggplot(aes(x = height, y = after_stat(density))) +
  geom_histogram(binwidth = 1, color = "black") +
  facet_grid(.~sex, scales = "free_x")
              </input>
            </program>

            <p>However, from this plot it is not immediately obvious that males are, on average, taller than females. We have to look carefully to notice that the x-axis has a higher range of values in the male histogram. An important principle here is to <alert>keep the axes the same</alert> when comparing data across two plots. Below we see how the comparison becomes a little easier:</p>

            <program language="r">
              <input>
heights |&gt; 
  ggplot(aes(height, y = after_stat(density))) +
  geom_histogram(binwidth = 1, color = "black") +
  facet_grid(.~sex)
              </input>
            </program>

          </subsection>

          <subsection xml:id="subsec-aligning-plots-for-comparisons">
            <title>Aligning plots for comparisons</title>

            <p>In these histograms, the visual cue related to decreases or increases in height are shifts to the left or right, respectively: horizontal changes. Aligning the plots vertically helps us see this change when the axes are fixed:</p>

            <program language="r">
              <input>
p2 &lt;- heights |&gt; 
  ggplot(aes(height, after_stat(density))) +
  geom_histogram(binwidth = 1, color = "black") +
  facet_grid(sex~.)
p2
              </input>
            </program>

            <p>This plot makes it much easier to notice that men are, on average, taller.</p>

            <p>If we want the more compact summary provided by boxplots, we then align them horizontally since, by default, boxplots move up and down with changes in height. Following our <em>show the data</em> principle, we then overlay all the data points:</p>

            <program language="r">
              <input>
p3 &lt;- heights |&gt; 
  ggplot(aes(sex, height)) + 
  geom_boxplot(coef = 3) + 
  geom_jitter(width = 0.1, alpha = 0.2) +
  ylab("Height in inches")
p3
              </input>
            </program>

            <p>Now contrast and compare these three plots, based on exactly the same data:</p>

            <program language="r">
              <input>
grid.arrange(p1, p2, p3, ncol = 3)
              </input>
            </program>

            <p>Notice how much more we learn from the two plots on the right. Barplots are useful for showing one number, but not very useful when we want to describe distributions.</p>

          </subsection>

        </section>

        <section xml:id="sec-log-transform">
          <title>Log transformations</title>

          <p>The combination of an incorrectly chosen barplot and a failure to use a transformation when one is merited can be particularly distorting. As an example, consider this barplot showing the average population sizes for each continent in 2015:</p>

          <program language="r">
            <input>
p1 &lt;- gapminder |&gt; 
  filter(year == 2015) |&gt;
  group_by(continent) |&gt; 
  summarize(population = mean(population)) |&gt;
  mutate(continent = reorder(continent, population)) |&gt;
  ggplot(aes(continent, population/10^6)) + 
  geom_col(width=0.5, fill = "blue") +
  theme_excel() + 
  ylab("Population in Millions") +
  xlab("Continent")
p1
            </input>
          </program>

          <p>From this plot, one would conclude that countries in Asia are much more populous than in other continents. Following the <em>show the data</em> principle, we quickly notice that this is due to two very large countries, which we assume are India and China:</p>

          <program language="r">
            <input>
p2 &lt;- gapminder |&gt; filter(year == 2015) |&gt; 
  mutate(continent = reorder(continent, population, median)) |&gt;
  ggplot(aes(continent, population/10^6)) + 
  ylab("Population in Millions") +
  xlab("Continent")
p2 +  geom_jitter(width = .1, alpha = .5) 
            </input>
          </program>

          <p>Here, we focus on examples in which the log transformation improves data visualization of skewed data. Other common transformations to be aware of include the logistic transformation (<c>logit</c>), which is useful for interpreting fold changes in odds, and the square root transformation (<c>sqrt</c>), which is often applied to stabilize variance in count data.</p>

          <subsection xml:id="subsec-right-skewed-distributions">
            <title>Right-skewed distributions</title>

            <p>Country population sizes provide a clear example of a <em>right-skewed</em> distribution: most countries have relatively small populations, while a few have extremely large ones. As shown in the box plot above, this imbalance causes most of the data points to be compressed into a small area of the plot, while a large portion of the plotting space is left empty. This makes it difficult to see meaningful differences among the majority of countries.</p>

            <p>In <xref ref="sec-scales"/>, we saw how applying a log transformation improved the readability of a scatter plot by addressing this kind of skew. Similarly, applying a log transformation to population sizes here produces a much more informative visualization. Below, we compare the original barplot to a boxplot with a log-transformed y-axis to illustrate the improvement.</p>

            <program language="r">
              <input>
p2 &lt;- p2 + geom_boxplot(coef = 3) + 
  geom_jitter(width = .1, alpha = .5) + 
  scale_y_log10(breaks = c(1,10,100,1000)) +
  theme(axis.text.x = element_text(size = 7)) 
grid.arrange(p1, p2, ncol = 2)
              </input>
            </program>

            <p>With the new plot, we realize that countries in Africa actually have a larger median population size than those in Asia.</p>

          </subsection>

          <subsection xml:id="subsec-ratios">
            <title>Ratios</title>

            <p>Ratios are commonly used in data analysis to compare two values. For example, we often report the relative risk of developing a disease, such as stating that the risk of disease is <em>three times higher</em> in smokers than in non-smokers.</p>

            <p>Conceptually, ratios are centered around 1, where a ratio of 1 indicates no difference between the two values. However, mathematically, ratios are not symmetric around 1. For instance, if the ratio of <m>A</m> to <m>B</m> is <m>3</m>, meaning <m>A</m> is three times larger than <m>B</m>, the reverse ratio of <m>B</m> to <m>A</m> is <m>1/3</m>. Notice that <m>3</m> and <m>1/3</m> are not equally distant from 1, which can make it difficult to visualize ratios in a way that fairly represents increases and decreases.</p>

            <p>For this reason, it is common to use a log transformation when displaying ratios. This is because the logarithm of a ratio has a symmetric property:</p>

            <me>
\log(A/B) = -\log(B/A)
            </me>

            <p>This means that if <m>A</m> is three times larger than <m>B</m>, the log ratio is equally distant from zero as when <m>B</m> is three times larger than <m>A</m>, but in the opposite direction. This symmetry around zero makes differences easier to interpret visually.</p>

            <p>Below is a plot demonstrating the advantage of using a log scale for displaying ratios.</p>

            <program language="r">
              <input>
#| echo: false
p &lt;- data.frame(Value = c(1 / c(10, 5, 2), c(1, 2, 5, 10))) |&gt;
  mutate(
    id = seq_along(Value),
    label = c(paste0("frac(1,", c(10, 5, 2), ")"),
      as.character(c(1, 2, 5, 10)))) |&gt;
  ggplot(aes(id, Value)) +
  geom_text(aes(label = label), parse = TRUE) +
  geom_hline(yintercept = 1, linetype = 2, color = "grey") +
  xlab("Arbitrary index") + 
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())  
grid.arrange(p +  scale_y_continuous(expand = expansion(mult = c(0.10, 0.05))) + ggtitle("Linear scale y-axis"),  
             p + scale_y_log10(expand = expansion(mult = c(0.10, 0.05))) + ggtitle("Log transformed y-axis"), nrow = 1)
              </input>
            </program>

            <note>
              <p>A common challenge when plotting log ratios is handling zeros in either the numerator or denominator, since <m>\log(0)</m> is undefined. Additionally, very small values can produce log ratios that approach positive or negative infinity, making the results unstable and difficult to interpret.</p>
              <p>A practical solution to address both issues is to apply a <em>continuity correction</em>, which involves adding a small constant to both the numerator and denominator. This prevents zeros and stabilizes extreme values. A commonly used constant is 0.5, leading to the following adjusted log ratio:</p>
              <me>
\log\left( \frac{A + 0.5}{B + 0.5} \right)
              </me>
              <p>This simple adjustment helps ensure that log ratios remain finite and more interpretable, particularly when dealing with values close to 0. Additionally, when <m>A</m> and <m>B</m> are large, it closely approximates the actual log ratio <m>\log(A/B)</m>.</p>
            </note>

          </subsection>

        </section>

        <section xml:id="sec-visual-cues-to-be-compared-should-be-adjacent">
          <title>Visual cues to be compared should be adjacent</title>

          <p>For each continent, let's compare income in 1970 versus 2010. When comparing income data across regions between 1970 and 2010, we made a figure similar to the one below, but this time we investigate continents rather than regions.</p>

          <program language="r">
            <input>
gapminder |&gt; 
  filter(year %in% c(1970, 2010) &amp; !is.na(gdp)) |&gt;
  mutate(dollars_per_day = gdp/population/365) |&gt;
  mutate(labels = paste(year, continent)) |&gt;
  ggplot(aes(labels, dollars_per_day)) +
  geom_boxplot() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  scale_y_continuous(trans = "log2") + 
  ylab("Income in dollars per day")
            </input>
          </program>

          <p>The default in __ggplot2__ is to order labels alphabetically so the labels with 1970 come before the labels with 2010, making the comparisons challenging because a continent's distribution in 1970 is visually far from its distribution in 2010. It is much easier to make the comparison between 1970 and 2010 for each continent when the boxplots for that continent are next to each other:</p>

          <program language="r">
            <input>
gapminder |&gt; 
  filter(year %in% c(1970, 2010) &amp; !is.na(gdp)) |&gt;
  mutate(dollars_per_day = gdp/population/365) |&gt;
  mutate(labels = paste(continent, year)) |&gt;
  ggplot(aes(labels, dollars_per_day)) +
  geom_boxplot() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  scale_y_continuous(trans = "log2") + 
  ylab("Income in dollars per day")
            </input>
          </program>

          <p>The comparison becomes even easier to make if we use color to denote the two things we want to compare:</p>

          <program language="r">
            <input>
 gapminder |&gt; 
  filter(year %in% c(1970, 2010) &amp; !is.na(gdp)) |&gt;
  mutate(dollars_per_day = gdp/population/365, year = factor(year)) |&gt;
  ggplot(aes(continent, dollars_per_day, fill = year)) +
  geom_boxplot() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  scale_y_continuous(trans = "log2") + 
  ylab("Income in dollars per day")
            </input>
          </program>

        </section>

        <section xml:id="sec-think-of-the-color-blind">
          <title>Think of the color blind</title>

          <p>About 10% of the population is color blind. Unfortunately, the default colors used in __ggplot2__ are not optimal for this group. However, __ggplot2__ does make it easy to change the color palette used in the plots. An example of how we can use a color blind friendly palette is described in the R cookbook:</p>

          <program language="r">
            <input>
color_blind_friendly_cols &lt;- 
  c("#999999", "#E69F00", "#56B4E9", "#009E73", 
    "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
            </input>
          </program>

          <p>Here are the colors</p>

          <program language="r">
            <input>
color_blind_friendly_cols &lt;- 
  c("#999999", "#E69F00", "#56B4E9", "#009E73", 
    "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

p1 &lt;- data.frame(x=1:8, y=rep(1,8), col = as.character(1:8)) |&gt; 
  ggplot(aes(x, y, color = col)) + 
  geom_point(size=8, show.legend = FALSE) +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank())

p1 + scale_color_manual(values=color_blind_friendly_cols)
            </input>
          </program>

          <p>There are several resources that can help you select colors, for example tutorials on R-bloggers.</p>

        </section>

        <section xml:id="sec-plots-for-two-variables">
          <title>Plots for two variables</title>

          <p>In general, you should use scatterplots to visualize the relationship between two variables. In every single instance in which we have examined the relationship between two variables, including total murders versus population size and life expectancy versus fertility rates, we have used scatterplots. This is the plot we generally recommend. However, there are some exceptions and we describe two alternative plots here: the <em>slope chart</em> and the <em>Bland-Altman plot</em>.</p>

          <subsection xml:id="subsec-slope-charts">
            <title>Slope charts</title>

            <p>One exception where another type of plot may be more informative is when you are comparing variables of the same type, but at different time points and for a relatively small number of comparisons. For example, comparing life expectancy between 2010 and 2015. In this case, we might recommend a <em>slope chart</em>.</p>

            <p>There is no geometry for slope charts in __ggplot2__, but we can construct one using <c>geom_line</c>. We need to do some tinkering to add labels. Below is an example comparing 2010 to 2015 for large western countries:</p>

            <program language="r">
              <input>
#| echo: false
west &lt;- c("Western Europe","Northern Europe","Southern Europe",
          "Northern America","Australia and New Zealand")

dat &lt;- gapminder |&gt; 
  filter(year%in% c(2010, 2015) &amp; region %in% west &amp; 
           !is.na(life_expectancy) &amp; population &gt; 10^7) 

dat |&gt;
  mutate(location = ifelse(year == 2010, 1, 2), 
         location = ifelse(year == 2015 &amp; 
                             country %in% c("United Kingdom", "Portugal"),
                           location+0.22, location),
         hjust = ifelse(year == 2010, 1, 0)) |&gt;
  mutate(year = as.factor(year)) |&gt;
  ggplot(aes(year, life_expectancy, group = country)) +
  geom_line(aes(color = country), show.legend = FALSE) +
  geom_text(aes(x = location, label = country, hjust = hjust), 
            show.legend = FALSE) +
  xlab("") + ylab("Life Expectancy")
              </input>
            </program>

            <p>An advantage of the slope chart is that it permits us to quickly get an idea of changes based on the slope of the lines. Although we are using angle as the visual cue, we also have position to determine the exact values. Comparing the improvements is a bit harder with a scatterplot:</p>

            <program language="r">
              <input>
#| echo: false
library(ggrepel)
west &lt;- c("Western Europe","Northern Europe","Southern Europe",
          "Northern America","Australia and New Zealand")

dat &lt;- gapminder |&gt; 
  filter(year%in% c(2010, 2015) &amp; region %in% west &amp; 
           !is.na(life_expectancy) &amp; population &gt; 10^7) 

dat |&gt; 
  mutate(year = paste0("life_expectancy_", year)) |&gt;
  select(country, year, life_expectancy) |&gt;
  spread(year, life_expectancy) |&gt; 
  ggplot(aes(x=life_expectancy_2010,y=life_expectancy_2015, label = country)) + 
  geom_point() + geom_text_repel() +
  scale_x_continuous(limits=c(78.5, 83)) +
  scale_y_continuous(limits=c(78.5, 83)) +
  geom_abline(lty = 2) +
  xlab("2010") + 
  ylab("2015")
              </input>
            </program>

            <p>In the scatterplot, we have followed the principle <em>use common axes</em> since we are comparing these before and after. However, if we have many points, slope charts stop being useful as it becomes hard to see all the lines.</p>

          </subsection>

          <subsection xml:id="subsec-bland-altman-plot">
            <title>Bland-Altman plot</title>

            <p>Since we are primarily interested in the difference, it makes sense to dedicate one of our axes to it. The Bland-Altman plot, also known as the Tukey mean-difference plot and the MA-plot, shows the difference versus the average:</p>

            <program language="r">
              <input>
#| echo: false
library(ggrepel)
dat |&gt; 
  mutate(year = paste0("life_expectancy_", year)) |&gt;
  select(country, year, life_expectancy) |&gt; 
  pivot_wider(names_from = "year", values_from="life_expectancy") |&gt; 
  mutate(average = (life_expectancy_2015 + life_expectancy_2010)/2,
         difference = life_expectancy_2015 - life_expectancy_2010) |&gt;
  ggplot(aes(average, difference, label = country)) + 
  geom_point() +
  geom_text_repel() +
  geom_abline(lty = 2) +
  xlab("Average of 2010 and 2015") + 
  ylab("Difference between 2015 and 2010")
              </input>
            </program>

            <p>Here, by simply looking at the y-axis, we quickly see which countries have shown the most improvement. We also get an idea of the overall value from the x-axis.</p>

          </subsection>

        </section>

        <section xml:id="sec-encoding-a-third-variable">
          <title>Encoding a third variable</title>

          <p>An earlier scatterplot showed the relationship between infant survival and average income. Below is a version of this plot that encodes three additional variables: OPEC membership, region, and population.</p>

          <program language="r">
            <input>
present_year &lt;- 2010

dat &lt;- gapminder |&gt;
  mutate(region = case_when(
    region %in% west ~ "The West",
    region %in% "Northern Africa" ~ "Northern Africa",
    region %in% c("Eastern Asia", "South-Eastern Asia") ~ "East Asia",
    region == "Southern Asia"~ "Southern Asia",
    region %in% c("Central America", "South America", "Caribbean") ~ "Latin America",
    continent == "Africa" &amp; region != "Northern Africa" ~ "Sub-Saharan Africa",
    region %in% c("Melanesia", "Micronesia", "Polynesia") ~ "Pacific Islands"),
    dollars_per_day = gdp / population / 365) |&gt;
  filter(year %in% present_year &amp; !is.na(gdp) &amp; !is.na(infant_mortality) &amp; !is.na(region) ) |&gt;
  mutate(OPEC = ifelse(country%in%opec, "Yes", "No")) 

dat |&gt; 
  ggplot(aes(dollars_per_day, 1 - infant_mortality/1000, 
             col = region, size = population/10^6,
             pch =  OPEC)) +
  scale_x_continuous(trans = "log2", limits=c(0.25, 150)) +
  scale_y_continuous(trans = "logit",limit=c(0.875, .9981),
                     breaks=c(.85,.90,.95,.99,.995,.998)) + 
  geom_point(alpha = 0.5) +
  ylab("Infant survival proportion")
            </input>
          </program>

          <p>We encode categorical variables with color and shape. These shapes can be controlled with <c>shape</c>  argument. Below are the shapes available for use in R. For the last five, the color goes inside.</p>

          <program language="r">
            <input>
dat=data.frame(x=c(0:25))
ggplot() +
  theme_minimal() +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) +
scale_shape_identity() + scale_y_reverse() +
geom_point(dat, mapping=aes(x%%9, x%/%9, shape=x), size=4, fill="blue") +
geom_text(dat, mapping=aes(x%%9, x%/%9+0.25, label=x), size=4) 
            </input>
          </program>

          <p>For continuous variables, we can use color, intensity, or size. We now show an example of how we do this with a case study.</p>

          <p>When selecting colors to quantify a numeric variable, we choose between two options: sequential and diverging. Sequential colors are suited for data that goes from high to low.  High values are clearly distinguished from low values. Here are some examples offered by the package <c>RColorBrewer</c>:</p>

          <program language="r">
            <input>
library(RColorBrewer)
rafalib::mypar()
display.brewer.all(type = "seq")
            </input>
          </program>

          <p>Diverging colors are used to represent values that diverge from a center. We put equal emphasis on both ends of the data range: higher than the center and lower than the center. An example of when we would use a divergent pattern would be if we were to show height in standard deviations away from the average. Here are some examples of divergent patterns:</p>

          <program language="r">
            <input>
library(RColorBrewer)
rafalib::mypar()
display.brewer.all(type = "div")
            </input>
          </program>

        </section>

        <section xml:id="sec-avoid-pseudo-three-dimensional-plots">
          <title>Avoid pseudo-three-dimensional plots</title>

          <p>The figure below, taken from the scientific literature, shows three variables: dose, drug type and survival. Although your screen/book page is flat and two-dimensional, the plot tries to imitate three dimensions and assigned a dimension to each variable.</p>

          <p><!-- https://raw.githubusercontent.com/kbroman/Talk_Graphs/master/Figs/fig8b.png--></p>

          <figure>
            <image source="dataviz/img/fig8b.png"/>
          </figure>

          <p>(Image courtesy of Karl Broman)</p>

          <p>Humans are not good at seeing in three dimensions (which explains why it is hard to parallel park) and our limitation is even worse with regard to pseudo-three-dimensions. To see this, try to determine the values of the survival variable in the plot above. Can you tell when the purple ribbon intersects the red one? This is an example in which we can easily use color to represent the categorical variable instead of using a pseudo-3D:</p>

          <program language="r">
            <input>
##First read data
url &lt;- "https://github.com/kbroman/Talk_Graphs/raw/master/R/fig8dat.csv"
dat &lt;- read.csv(url)

##Now make alternative plot
dat |&gt; gather(drug, survival, -log.dose) |&gt;
  mutate(drug = gsub("Drug.","",drug)) |&gt;
  ggplot(aes(log.dose, survival, color = drug)) +
  geom_line()    
            </input>
          </program>

          <p>Notice how much easier it is to determine the survival values.</p>

          <p>Pseudo-3D is sometimes used completely gratuitously: plots are made to look 3D even when the 3rd dimension does not represent a quantity. This only adds confusion and makes it harder to relay your message.  Here are two examples:</p>

          <figure>
            <image source="dataviz/img/fig1e.png"/>
          </figure>

          <figure>
            <image source="dataviz/img/fig2d.png"/>
          </figure>

          <p>(Images courtesy of Karl Broman)</p>

        </section>

        <section xml:id="sec-avoid-too-many-significant-digits">
          <title>Avoid too many significant digits</title>

          <p>By default, statistical software like R returns many significant digits. The default behavior in R is to show 7 significant digits. That many digits often adds no information and the added visual clutter can make it hard for the viewer to understand the message. As an example, here are the per 10,000 disease rates, computed from totals and population in R, for California across the five decades:</p>

          <program language="r">
            <input>
tmp &lt;- options()$digits
options(digits=7)
dat &lt;- us_contagious_diseases |&gt;
  filter(year %in% seq(1940, 1980, 10) &amp;  state == "California" &amp;
          disease %in% c("Measles", "Pertussis", "Polio")) |&gt;
  mutate(rate = count / population * 10000) |&gt; 
  mutate(state = reorder(state, rate)) |&gt; 
  select(state, year, disease, rate) |&gt;
  spread(disease, rate)
if(knitr::is_html_output()){
  knitr::kable(dat, "html") |&gt;
    kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
  knitr::kable(dat, "latex", booktabs = TRUE) |&gt;
    kableExtra::kable_styling(font_size = 8)
}
options(digits = tmp)
            </input>
          </program>

          <p>We are reporting precision up to 0.00001 cases per 10,000, a very small value in the context of the changes that are occurring across the dates. In this case, one significant figures is enough and clearly makes the point that rates are decreasing:</p>

          <program language="r">
            <input>
dat &lt;- dat |&gt; 
  mutate_at(c("Measles", "Pertussis", "Polio"), ~round(., digits=1))
if(knitr::is_html_output()){
  knitr::kable(dat, "html") |&gt;
    kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
  knitr::kable(dat, "latex", booktabs = TRUE) |&gt;
    kableExtra::kable_styling(font_size=8)
}
            </input>
          </program>

          <p>Useful ways to change the number of significant digits or to round numbers are <c>signif</c> and <c>round</c>. You can define the number of significant digits globally by setting options like this: <c>options(digits = 3)</c>.</p>

          <p>Another principle related to displaying tables is to place values being compared on columns rather than rows. Note that our table above is easier to read than this one:</p>

          <program language="r">
            <input>
dat &lt;- us_contagious_diseases |&gt;
  filter(year %in% seq(1940, 1980, 10) &amp;  state == "California" &amp;
          disease %in% c("Measles", "Pertussis", "Polio")) |&gt;
  mutate(rate = count / population * 10000) |&gt; 
  mutate(state = reorder(state, rate)) |&gt; 
  select(state, year, disease, rate) |&gt;
  spread(year, rate) |&gt; 
  rename(State = state, Disease = disease) |&gt;
  mutate_if(is.numeric, round, digits = 1) 
if(knitr::is_html_output()){
  knitr::kable(dat, "html") |&gt;
    kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
  knitr::kable(dat, "latex", booktabs = TRUE) |&gt;
    kableExtra::kable_styling(font_size = 8)
}
            </input>
          </program>

        </section>

        <section xml:id="sec-know-your-audience">
          <title>Know your audience</title>

          <p>Graphs can be used 1) for our own exploratory data analysis, 2) to convey a message to experts, or 3) to help convey a message to a general audience. Make sure that the intended audience understands each element of the plot.</p>

          <p>As a simple example, consider that for your own exploration it may be more useful to log-transform data and then plot it. However, for a general audience that is unfamiliar with converting logged values back to the original measurements, using a log-scale for the axis instead of log-transformed values will be much easier to digest.</p>

        </section>

        <section xml:id="sec-dataviz-principles-exercises">
          <title>Exercises</title>

          <p>For these exercises, we will be using the vaccines data in the __dslabs__ package:</p>

          <program language="r">
            <input>
library(dslabs)
            </input>
          </program>

          <ol>
            <li><p>Pie charts are appropriate:</p></li>
          </ol>

          <p>a. When we want to display percentages. b. When __ggplot2__ is not available. c. When I am in a bakery. d. Never. Barplots and tables are always better.</p>

          <ol>
            <li><p>What is the problem with the plot below:</p></li>
          <program language="r">
            <input>
library(tidyverse)
ds_theme_set()
data.frame(candidate=c("Clinton","Trump"), electoral_votes = c(232, 306)) |&gt;
  ggplot(aes(candidate, electoral_votes)) +
  geom_col(width=0.5, color =1, fill = c("Blue","Red")) +
  coord_cartesian(ylim=c(200,310)) +
  ylab("Electoral Votes") +
  xlab("") +
  ggtitle("Results of Presidential Election 2016")
            </input>
          </program>

          </ol>

          <p>a. The values are wrong. The final vote was 306 to 232. b. The axis does not start at 0. Judging by the length, it appears Trump received 3 times as many votes when, in fact, it was about 30% more. c. The colors should be the same. d. Percentages should be shown as a pie chart.</p>

          <ol>
            <li><p>Take a look at the following two plots. They show the same information: 1928 rates of measles across the 50 states.</p></li>
          <program language="r">
            <input>
p1 &lt;- us_contagious_diseases |&gt; 
  filter(year == 1928 &amp; disease=="Measles" &amp; count&gt;0 &amp; !is.na(population)) |&gt; 
  mutate(rate = count / population * 10000 * 52 / weeks_reporting) |&gt;
  ggplot(aes(state, rate)) +
  geom_col() +
  coord_flip() +
  xlab("")

p2 &lt;- us_contagious_diseases |&gt; 
  filter(year == 1928 &amp; disease=="Measles" &amp; count&gt;0 &amp; !is.na(population)) |&gt; 
  mutate(rate = count / population * 10000*52 / weeks_reporting) |&gt;
  mutate(state = reorder(state, rate)) |&gt;
  ggplot(aes(state, rate)) +
  geom_col() +
  coord_flip() +
  xlab("")
grid.arrange(p1, p2, ncol = 2)
            </input>
          </program>

          </ol>

          <p>Which plot is easier to read if you are interested in determining which are the best and worst states in terms of rates, and why?</p>

          <p>a. They provide the same information, so they are both equally as good. b. The plot on the right is better because it orders the states alphabetically. c. The plot on the right is better because alphabetical order has nothing to do with the disease and by ordering according to actual rate, we quickly see the states with most and least rates. d. Both plots should be a pie chart.</p>

          <ol>
            <li><p>To make the plot on the left, we have to reorder the levels of the states' variables.</p></li>
          <program language="r">
            <input>
dat &lt;- us_contagious_diseases |&gt;  
  filter(year == 1967 &amp; disease=="Measles" &amp; !is.na(population)) |&gt;
  mutate(rate = count / population * 10000 * 52 / weeks_reporting)
            </input>
          </program>

          </ol>

          <p>Note what happens when we make a barplot:</p>

          <program language="r">
            <input>
dat |&gt; ggplot(aes(state, rate)) +
  geom_col() +
  coord_flip() 
            </input>
          </program>

          <p>Define these objects:</p>

          <program language="r">
            <input>
state &lt;- dat$state
rate &lt;- dat$count/dat$population*10000*52/dat$weeks_reporting
            </input>
          </program>

          <p>Redefine the <c>state</c> object so that the levels are re-ordered. Print the new object <c>state</c> and its levels so you can see that the vector is not re-ordered by the levels.</p>

          <ol>
            <li><p>Now with one line of code, define the <c>dat</c> table as done above, but change the use mutate to create a rate variable and re-order the state variable so that the levels are re-ordered by this variable. Then make a barplot using the code above, but for this new <c>dat</c>.</p></li>
            <li><p>Say we are interested in comparing gun homicide rates across regions of the US. We see this plot:</p></li>
          <program language="r">
            <input>
library(dslabs)
murders |&gt; mutate(rate = total/population*100000) |&gt;
group_by(region) |&gt;
summarize(avg = mean(rate)) |&gt;
mutate(region = factor(region)) |&gt;
ggplot(aes(region, avg)) +
geom_col() + 
ylab("Murder Rate Average")
            </input>
          </program>

          </ol>

          <p>and decide to move to a state in the western region. What is the main problem with this interpretation?</p>

          <p>a. The categories are ordered alphabetically. b. The graph does not show standard errors. c. It does not show all the data. We do not see the variability within a region and it's possible that the safest states are not in the West. d. The Northeast has the lowest average.</p>

          <ol>
            <li><p>Make a boxplot of the murder rates defined as</p></li>
          <program language="r">
            <input>
murders |&gt; mutate(rate = total/population*100000)
            </input>
          </program>

          </ol>

          <p>by region, showing all the points and ordering the regions by their median rate.</p>

          <ol>
            <li><p>The plots below show three continuous variables. </p></li>
          <program language="r">
            <input>
library(scatterplot3d)
library(RColorBrewer)
set.seed(1)
n &lt;- 25
group &lt;- rep(1,n)
group[1:(round(n/2))] &lt;- 2
x &lt;- rnorm(n, group, .33)
y &lt;- rnorm(n, group, .33)
z &lt;- rnorm(n)
rafalib::mypar()
scatterplot3d(x,y,z, color = group, pch=16, ylab="")
text(8.25, -1.5, label = "y")
abline(v=4, col=3)
            </input>
          </program>

          </ol>

          <p>The line <m>x=2</m> appears to separate the points. But it is actually not the case, which we can see by plotting the data in a couple of two-dimensional points.</p>

          <program language="r">
            <input>
rafalib::mypar(1,2)
plot(x,y, col=group, pch =16)
abline(v=2, col=3)
plot(x,z,col=group, pch=16)
abline(v=2, col=3)
            </input>
          </program>

          <p>Why is this happening?</p>

          <p>a. Humans are not good at reading pseudo-3D plots. b. There must be an error in the code. c. The colors confuse us. d. Scatterplots should not be used to compare two variables when we have access to 3.</p>

        </section>
      </chapter>

      <chapter xml:id="ch-data-visualization-in-practice">
        <title>Data visualization in practice</title>
        
          <p>In this chapter, we will demonstrate how relatively simple <alert>ggplot2</alert> code can create insightful and aesthetically pleasing plots. As motivation we will create plots that help us better understand trends in world health and economics. We will implement what we learned in <xref ref="sec-ggplot2"/> and <xref ref="sec-dataviz-principles"/> and learn how to augment the code to perfect the plots. As we go through our case study, we will describe relevant general data visualization principles and learn concepts such as <em>faceting</em>, <em>time series plots</em>, <em>transformations</em>, and <em>ridge plots</em>.</p>

        <section xml:id="sec-case-study-1-new-insights-on-poverty">
          <title>Case study 1: new insights on poverty</title>

          <p>Hans Rosling was the co-founder of the Gapminder Foundation, an organization dedicated to educating the public by using data to dispel common myths about the so-called developing world. The organization uses data to show how actual trends in health and economics contradict the narratives that emanate from sensationalist media coverage of catastrophes, tragedies, and other unfortunate events. As stated in the Gapminder Foundation's website:</p>

          <blockquote>
            <p>Journalists and lobbyists tell dramatic stories. That's their job. They tell stories about extraordinary events and unusual people. The piles of dramatic stories pile up in peoples' minds into an over-dramatic worldview and strong negative stress feelings: "The world is getting worse!", "It's we vs. them!", "Other people are strange!", "The population just keeps growing!" and "Nobody cares!"</p>
          </blockquote>

          <p>Hans Rosling conveyed actual data-based trends in a dramatic way of his own, using effective data visualization. This section is based on two talks that exemplify this approach to education: New Insights on Poverty and The Best Stats You've Ever Seen. Specifically, in this section, we use data to attempt to answer the following two questions:</p>

          <ol>
            <li><p>Is it a fair characterization of today's world to say it is divided into western rich nations and the developing world in Africa, Asia, and Latin America?</p></li>
            <li><p>Has income inequality across countries worsened during the last 40 years?</p></li>
          </ol>

          <p>To answer these questions, we will be using the <c>gapminder</c> dataset provided in <alert>dslabs</alert>. This dataset was created using a number of spreadsheets available from the Gapminder Foundation. You can access the table like this:</p>

          <program language="r">
            <input>
library(tidyverse)
library(dslabs)
gapminder |&gt; as_tibble()
            </input>
          </program>

          <p>As done in the <em>New Insights on Poverty</em> video, we start by testing our knowledge regarding differences in child mortality across different countries. For each of the six pairs of countries below, which country do you think had the highest child mortality rates in 2015? Which pairs do you think are most similar?</p>

          <ol>
            <li><p>Sri Lanka or Turkey</p></li>
            <li><p>Poland or South Korea</p></li>
            <li><p>Malaysia or Russia</p></li>
            <li><p>Pakistan or Vietnam</p></li>
            <li><p>Thailand or South Africa</p></li>
          </ol>

          <p>When answering these questions without data, the non-European countries are typically picked as having higher child mortality rates: Sri Lanka over Turkey, South Korea over Poland, and Malaysia over Russia. It is also common to assume that countries considered to be part of the developing world: Pakistan, Vietnam, Thailand, and South Africa, have similarly high mortality rates.</p>

          <p>To answer these questions <alert>with data</alert>, we can use <alert>dplyr</alert>. For example, for the first comparison we see that:</p>

          <program language="r">
            <input>
gapminder |&gt; 
  filter(year == 2015 &amp; country %in% c("Sri Lanka","Turkey")) |&gt; 
  select(country, infant_mortality)
            </input>
          </program>

          <p>Turkey has the higher infant mortality rate.</p>

          <p>We can use this code on all comparisons and find the following:</p>

          <program language="r">
            <input>
comp_table &lt;- tibble(comparison = rep(1:5, each = 2),
           country = c("Sri Lanka", "Turkey", "Poland", "South Korea", "Malaysia", "Russia", "Pakistan","Vietnam","Thailand","South Africa"))

tmp &lt;- gapminder |&gt; 
  filter(year == 2015) |&gt; 
  select(country, infant_mortality) |&gt; 
  mutate(country = as.character(country)) ##to match characters to characters
  
tab &lt;- inner_join(comp_table, tmp, by = "country") |&gt; select(-comparison)
  
tmp &lt;- cbind(slice(tab,seq(1,9,2)), slice(tab,seq(2,10,2)))
if (knitr::is_html_output()) {
  knitr::kable(tmp, "html") |&gt;
    kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
  knitr::kable(tmp, "latex", booktabs = TRUE) |&gt;
    kableExtra::kable_styling(font_size = 8)
}
            </input>
          </program>

          <p>We see that the European countries on this list have higher child mortality rates: Poland has a higher rate than South Korea, and Russia has a higher rate than Malaysia. We also see that Pakistan has a much higher rate than Vietnam, and South Africa has a much higher rate than Thailand. It turns out that when Hans Rosling gave this quiz to educated groups of people, the average score was less than 2.5 out of 5, worse than what they would have obtained had they guessed randomly. This implies that more than ignorant, we are misinformed. In this chapter we see how data visualization helps inform us.</p>

        </section>

        <section xml:id="sec-scatterplots">
          <title>Scatterplots</title>

          <p>The reason for the misconception described in the previous section stems from the preconceived notion that the world is divided into two groups: the western world (Western Europe and North America), characterized by long life spans and small families, versus the developing world (Africa, Asia, and Latin America) characterized by short life spans and large families. But do the data support this dichotomous view?</p>

          <p>The necessary data to answer this question is also available in our <c>gapminder</c> table. Using our newly learned data visualization skills, we will be able to tackle this challenge.</p>

          <p>In order to analyze this world view, our first plot is a scatterplot of life expectancy versus fertility rates (average number of children per woman). We start by looking at data from about 50 years ago, when perhaps this view was first cemented in our minds.</p>

          <program language="r">
            <input>
filter(gapminder, year == 1962) |&gt;
  ggplot(aes(fertility, life_expectancy)) +
  geom_point()
            </input>
          </program>

          <p>Most points fall into two distinct categories:</p>

          <ol>
            <li><p>Life expectancy around 70 years and 3 or fewer children per family.</p></li>
            <li><p>Life expectancy lower than 65 years and more than 5 children per family.</p></li>
          </ol>

          <p>To confirm that indeed these countries are from the regions we expect, we can use color to represent continent.</p>

          <program language="r">
            <input>
filter(gapminder, year == 1962) |&gt;
  ggplot( aes(fertility, life_expectancy, color = continent)) +
  geom_point() 
            </input>
          </program>

          <p>In 1962, "the West versus developing world" view was grounded in some reality. Is this still the case 50 years later?</p>

        </section>

        <section xml:id="sec-faceting">
          <title>Faceting</title>

          <p>We could easily plot the 2012 data in the same way we did for 1962. To make comparisons, however, side by side plots are preferable. In <alert>ggplot2</alert>, we can achieve this by <em>faceting</em> variables: we stratify the data by some variable and make the same plot for each strata.</p>

          <p>To achieve faceting, we add a layer with the function <c>facet_grid</c>, which automatically separates the plots. This function lets you facet by up to two variables using columns to represent one variable and rows to represent the other. The function expects the row and column variables to be separated by a <c>~</c>. Here is an example of a scatterplot with <c>facet_grid</c> added as the last layer:</p>

          <program language="r">
            <input>
filter(gapminder, year %in% c(1962, 2012)) |&gt;
  ggplot(aes(fertility, life_expectancy, col = continent)) +
  geom_point() +
  facet_grid(year~continent)
            </input>
          </program>

          <p>We see a plot for each continent/year pair. However, this is just an example and more than what we want, which is simply to compare 1962 and 2012. In this case, there is just one variable and we use <c>.</c> to let facet know that we are not using a second variable:</p>

          <program language="r">
            <input>
filter(gapminder, year %in% c(1962, 2012)) |&gt;
  ggplot(aes(fertility, life_expectancy, col = continent)) +
  geom_point() +
  facet_grid(. ~ year)
            </input>
          </program>

          <p>This plot clearly shows that the majority of countries have moved from the <em>developing world</em> cluster to the <em>western world</em> one. In 2012, the western versus developing world view no longer makes sense. This is particularly clear when comparing Europe to Asia, the latter of which includes several countries that have made great improvements.</p>

          <subsection xml:id="subsec-facet-wrap">
            <title>`facet_wrap`</title>

            <p>To explore how this transformation happened through the years, we can make the plot for several years. For example, we can add 1970, 1980, 1990, and 2000. If we do this, we will not want all the plots on the same row, the default behavior of <c>facet_grid</c>, since they will become too thin to show the data. Instead, we will want to use multiple rows and columns. The function <c>facet_wrap</c> permits us to do this by automatically wrapping the series of plots so that each display has viewable dimensions:</p>

            <program language="r">
              <input>
years &lt;- c(1962, 1980, 1990, 2000, 2012)
continents &lt;- c("Europe", "Asia")
gapminder |&gt; 
  filter(year %in% years &amp; continent %in% continents) |&gt;
  ggplot( aes(fertility, life_expectancy, col = continent)) +
  geom_point() +
  facet_wrap(~year) 
              </input>
            </program>

            <p>This plot clearly shows how most Asian countries have improved at a much faster rate than European ones.</p>

          </subsection>

          <subsection xml:id="subsec-fixed-scales-for-better-comparisons">
            <title>Fixed scales for better comparisons</title>

            <p>The default choice of the range of the axes is important. When not using <c>facet</c>, this range is determined by the data shown in the plot. When using <c>facet</c>, this range is determined by the data shown in all plots and therefore kept fixed across plots. This makes comparisons across plots much easier. For example, in the above plot, we can see that life expectancy has increased and the fertility has decreased across most countries. We see this because the cloud of points moves. This is not the case if we adjust the scales:</p>

            <program language="r">
              <input>
filter(gapminder, year %in% c(1962, 2012)) |&gt;
  ggplot(aes(fertility, life_expectancy, col = continent)) +
  geom_point() +
  facet_wrap(. ~ year, scales = "free")
              </input>
            </program>

            <p>In the plot above, we have to pay special attention to the range to notice that the plot on the right has a larger life expectancy.</p>

          </subsection>

        </section>

        <section xml:id="sec-time-series-plots">
          <title>Time series plots</title>

          <p>The visualizations above effectively illustrate that data no longer supports the western versus developing world view. Once we see these plots, new questions emerge. For example, which countries are improving more and which ones less? Was the improvement constant during the last 50 years or was it more accelerated during certain periods? For a closer look that may help answer these questions, we introduce <em>time series plots</em>.</p>

          <p>Time series plots have time in the x-axis and an outcome or measurement of interest on the y-axis. For example, here is a trend plot of United States fertility rates:</p>

          <program language="r">
            <input>
gapminder |&gt; 
  filter(country == "United States") |&gt; 
  ggplot(aes(year, fertility)) +
  geom_point()
            </input>
          </program>

          <p>We see that the trend is not linear at all. Instead there is sharp drop during the 1960s and 1970s to below 2. Then the trend comes back to 2 and stabilizes during the 1990s.</p>

          <p>When the points are regularly and densely spaced, as they are here, we create curves by joining the points with lines, to convey that these data are from a single series, here a country. To do this, we use the <c>geom_line</c> function instead of <c>geom_point</c>.</p>

          <program language="r">
            <input>
gapminder |&gt; 
  filter(country == "United States") |&gt; 
  ggplot(aes(year, fertility)) +
  geom_line()
            </input>
          </program>

          <p>This is particularly helpful when we look at two countries. We can subset the data to include two countries, one from Europe and one from Asia, then adapt the code above:</p>

          <program language="r">
            <input>
countries &lt;- c("South Korea", "Germany")

gapminder |&gt; filter(country %in% countries) |&gt; 
  ggplot(aes(year,fertility)) +
  geom_line()
            </input>
          </program>

          <p>Unfortunately, this is <alert>not</alert> the plot that we want. Rather than a line for each country, the points for both countries are joined. This is actually expected since we have not told <c>ggplot</c> anything about wanting two separate lines. To let <c>ggplot</c> know that there are two curves that need to be made separately, we assign each point to a <c>group</c>, one for each country:</p>

          <program language="r">
            <input>
countries &lt;- c("South Korea","Germany")

gapminder |&gt; filter(country %in% countries &amp; !is.na(fertility)) |&gt; 
  ggplot(aes(year, fertility, group = country)) +
  geom_line()
            </input>
          </program>

          <p>But which line goes with which country? We can assign colors to make this distinction. A useful side-effect of using the <c>color</c> argument to assign different colors to the different countries is that the data is automatically grouped:</p>

          <program language="r">
            <input>
countries &lt;- c("South Korea","Germany")
gapminder |&gt; filter(country %in% countries &amp; !is.na(fertility)) |&gt; 
  ggplot(aes(year,fertility, col = country)) +
  geom_line()
            </input>
          </program>

          <p>The plot clearly shows how South Korea's fertility rate dropped drastically during the 1960s and 1970s, and by 1990 had a similar rate to that of Germany.</p>

          <p>For trend plots we recommend labeling the lines rather than using legends since the viewer can quickly see which line is which country. This suggestion actually applies to most plots: labeling is usually preferred over legends.</p>

          <p>We demonstrate how we can do this using the <c>geomtextpath</c> package. We define a data table with the label locations and then use a second mapping just for these labels:</p>

          <program language="r">
            <input>
library(geomtextpath)
gapminder |&gt; 
  filter(country %in% countries) |&gt; 
  ggplot(aes(year, life_expectancy, col = country, label = country)) +
  geom_textpath() +
  theme(legend.position = "none")
            </input>
          </program>

          <p>The plot clearly shows how an improvement in life expectancy followed the drops in fertility rates. In 1960, Germans lived 15 years longer than South Koreans, although by 2010 the gap is completely closed. It exemplifies the improvement that many non-western countries have achieved in the last 40 years.</p>

        </section>

        <section xml:id="sec-data-transformations">
          <title>Data transformations</title>

          <p>We now shift our attention to the second question related to the commonly held notion that wealth distribution across the world has become worse during the last decades. When general audiences are asked if poor countries have become poorer and rich countries become richer, the majority answers yes. By using stratification, histograms, smooth densities, and boxplots, we will be able to understand if this is in fact the case. First we learn how transformations can sometimes help provide more informative summaries and plots.</p>

          <p>The <c>gapminder</c> data table includes a column with the countries' gross domestic product (GDP). GDP measures the market value of goods and services produced by a country in a year. The GDP per person is often used as a rough summary of a country's wealth. Here we divide this quantity by 365 to obtain the more interpretable measure <em>dollars per day</em>. Using current US dollars as a unit, a person surviving on an income of less than $2 a day is defined to be living in <em>absolute poverty</em>. We add this variable to the data table:</p>

          <program language="r">
            <input>
gapminder &lt;- gapminder |&gt;  
  mutate(dollars_per_day = gdp/population/365)
            </input>
          </program>

          <p>The GDP values are adjusted for inflation and represent current US dollars, so these values are meant to be comparable across the years. Of course, these are country averages and within each country there is much variability. All the graphs and insights described below relate to country averages and not to individuals.</p>

          <subsection xml:id="subsec-log-transformation">
            <title>Log transformation</title>

            <p>Here is a histogram of per day incomes from 1970:</p>

            <program language="r">
              <input>
past_year &lt;- 1970
gapminder |&gt; 
  filter(year == past_year &amp; !is.na(gdp)) |&gt;
  ggplot(aes(dollars_per_day)) + 
  geom_histogram(binwidth = 1, color = "black")
              </input>
            </program>

            <p>We use the <c>color = "black"</c> argument to draw a boundary and clearly distinguish the bins.</p>

            <p>In this plot, we see that for the majority of countries, averages are below 10 dollars a day. However, the majority of the x-axis is dedicated to countries with averages above 10 dollars. So the plot is not very informative about countries with values below 10 dollars a day.</p>

            <p>It might be more informative to quickly be able to see how many countries have average daily incomes of about 1 dollar (extremely poor), 2 dollars (very poor), 4 dollars (poor), 8 dollars (middle), 16 dollars (well off), 32 dollars (rich), 64 dollars (very rich) per day. These changes are multiplicative, and log transformations convert multiplicative changes into additive ones: when using base 2, a doubling of a value turns into an increase by 1.</p>

            <p>Here is the distribution if we apply a log base 2 transform:</p>

            <program language="r">
              <input>
gapminder |&gt; 
  filter(year == past_year &amp; !is.na(gdp)) |&gt;
  ggplot(aes(log2(dollars_per_day))) + 
  geom_histogram(binwidth = 1, color = "black")
              </input>
            </program>

            <p>In a way, this provides a <em>close-up</em> of the mid to lower income countries.</p>

          </subsection>

          <subsection xml:id="subsec-which-base">
            <title>Which base?</title>

            <p>In the case above, we used base 2 in the log transformations. Other common choices are base <m>\mathrm{e}</m> (the natural log) and base 10.</p>

            <p>In general, we do not recommend using the natural log for data exploration and visualization. This is because while <m>2^2, 2^3, 2^4, \dots</m> or <m>10^2, 10^3, \dots</m> are easy to mentally compute, but the same is not true for <m>\mathrm{e}^2, \mathrm{e}^3, \dots</m>. The natural log scale is not intuitive or easy to interpret.</p>

            <p>In the dollars per day example, we used base 2 instead of base 10 because the resulting range is easier to interpret. The range of the untransformed values is <c>with(filter(gapminder, year==past_year), range(dollars_per_day, na.rm=TRUE))</c>.</p>

            <p>In base 10, this turns into a range that includes very few integers: just 0 and 1. With base 2, our range includes -2, -1, 0, 1, 2, 3, 4, and 5. It is easier to compute <m>2^x</m> and <m>10^x</m> when <m>x</m> is an integer and between -10 and 10, so we prefer to have smaller integers in the scale. Another consequence of a limited range is that choosing the binwidth is more challenging. With log base 2, we know that a binwidth of 1 will translate to a bin with range <m>x</m> to <m>2x</m>.</p>

            <p>For an example in which base 10 makes more sense, consider population sizes. A log base 10 is preferable since the range for these is:</p>

            <program language="r">
              <input>
filter(gapminder, year == past_year) |&gt;
  summarize(min = min(population), max = max(population))
              </input>
            </program>

            <p>Here is the histogram of the transformed values:</p>

            <program language="r">
              <input>
gapminder |&gt; 
  filter(year == past_year) |&gt;
  ggplot(aes(log10(population))) +
  geom_histogram(binwidth = 0.5, color = "black")
              </input>
            </program>

            <p>In the above, we quickly see that country populations range between ten thousand and ten billion.</p>

          </subsection>

          <subsection xml:id="subsec-transform-the-values-or-the-scale">
            <title>Transform the values or the scale?</title>

            <p>There are two ways we can use log transformations in plots. We can log the values before plotting them or use log scales in the axes. The plot will look the same,  except for the numbers in the axes. Both approaches are useful and have different strengths. If we log the data, we can more easily interpret intermediate values in the scale. For example, if we see:</p>

            <p><c>----1----x----2--------3----</c></p>

            <p>for log transformed data, we know that the value of <m>x</m> is about 1.5. If the scales are logged:</p>

            <p><c>----10---x---100------1000---</c></p>

            <p>then, to determine <c>x</c>, we need to compute <m>10^{1.5}</m>, which is not easy to do in our heads. However, the advantage of showing logged scales is that the original values are displayed in the plot, which are easier to interpret. For example, we would see "32 dollars a day" instead of "5 log base 2 dollars a day".</p>

            <p>As we learned earlier, if we want to scale the axis with logs, we can use the <c>scale_x_continuous</c> function. Instead of logging the values first, we apply this layer:</p>

            <program language="r">
              <input>
gapminder |&gt; 
  filter(year == past_year &amp; !is.na(gdp)) |&gt;
  ggplot(aes(dollars_per_day)) + 
  geom_histogram(binwidth = 1, color = "black") +
  scale_x_continuous(trans = "log2")
              </input>
            </program>

            <p>Note that the log base 10 transformation has its own function: <c>scale_x_log10()</c>, but currently base 2 does not, although we could easily define our own.</p>

            <p>There are other transformations available through the <c>trans</c> argument. As we learn later on, the square root (<c>sqrt</c>) transformation is useful when considering counts. The logistic transformation (<c>logit</c>) is useful when plotting proportions between 0 and 1. The <c>reverse</c> transformation is useful when we want smaller values to be on the right or on top.</p>

          </subsection>

        </section>

        <section xml:id="sec-multimodal-distributions">
          <title>Multimodal distributions</title>

          <p>In the histogram above we see two <em>bumps</em>: one at about 4 and another at about 32. In statistics these bumps are sometimes referred to as <em>modes</em>. The mode of a distribution is the value with the highest frequency. The mode of the normal distribution is the average. When a distribution, like the one above, doesn't monotonically decrease from the mode, we call the locations where it goes up and down again <em>local modes</em> and say that the distribution has <em>multiple modes</em>.</p>

          <p>The histogram above suggests that the 1970 country income distribution has two modes: one at about 2 dollars per day (1 in the log 2 scale) and another at about 32 dollars per day (5 in the log 2 scale). This <em>bimodality</em> is consistent with a dichotomous world made up of countries with average incomes less than 8 dollars per day (3 in the log 2 scale) and countries above that.</p>

        </section>

        <section xml:id="sec-comparing-distributions">
          <title>Comparing distributions</title>

          <p>A histogram showed us that the 1970 income distribution values show a dichotomy. However, the histogram does not show us if the two groups of countries are <em>west</em> versus the <em>developing</em> world.</p>

          <p>Let's start by quickly examining the data by region. We reorder the regions by the median value and use a log scale.</p>

          <program language="r">
            <input>
gapminder |&gt; 
  filter(year == past_year &amp; !is.na(gdp)) |&gt;
  mutate(region = reorder(region, dollars_per_day, FUN = median)) |&gt;
  ggplot(aes(dollars_per_day, region)) +
  geom_point() +
  scale_x_continuous(trans = "log2")  
            </input>
          </program>

          <p>We can already see that there is indeed a "west versus the rest" dichotomy: we see two clear groups, with the rich group composed of North America, Northern and Western Europe, and New Zealand and Australia. We define groups based on this observation:</p>

          <program language="r">
            <input>
gapminder &lt;- gapminder |&gt; 
  mutate(group = case_when(
    region %in% c("Western Europe", "Northern Europe","Southern Europe", 
                    "Northern America", 
                  "Australia and New Zealand") ~ "West",
    region %in% c("Eastern Asia", "South-Eastern Asia") ~ "East Asia",
    region %in% c("Caribbean", "Central America", 
                  "South America") ~ "Latin America",
    continent == "Africa" &amp; 
      region != "Northern Africa" ~ "Sub-Saharan",
    TRUE ~ "Others"))
            </input>
          </program>

          <p>We turn this <c>group</c> variable into a factor to control the order of the levels:</p>

          <program language="r">
            <input>
gapminder &lt;- gapminder |&gt; 
  mutate(group = factor(group, levels = c("Others", "Latin America", 
                                          "East Asia", "Sub-Saharan",
                                          "West")))
            </input>
          </program>

          <p>In the next section we demonstrate how to visualize and compare distributions across groups.</p>

          <subsection xml:id="subsec-boxplots">
            <title>Boxplots</title>

            <p>The exploratory data analysis above has revealed two characteristics about average income distribution in 1970. Using a histogram, we found a bimodal distribution with the modes relating to poor and rich countries. We now want to compare the distribution across these five groups to confirm the "west versus the rest" dichotomy. The number of points in each category is large enough that a summary plot may be useful. We could generate five histograms or five density plots, but it may be more practical to have all the visual summaries in one plot. We therefore start by stacking boxplots next to each other. Note that we add the layer <c>theme(axis.text.x = element_text(angle = 90, hjust = 1))</c> to turn the group labels vertical, since they do not fit if we show them horizontally, and we remove the axis label to make space.</p>

            <program language="r">
              <input>
p &lt;- gapminder |&gt; 
  filter(year == past_year &amp; !is.na(gdp)) |&gt;
  ggplot(aes(group, dollars_per_day)) +
  geom_boxplot() +
  scale_y_continuous(trans = "log2") +
  xlab("") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) 
p
              </input>
            </program>

            <p>Boxplots have the limitation that by summarizing the data into five numbers, we might miss important characteristics of the data. One way to avoid this is by showing the data.</p>

            <program language="r">
              <input>
p + geom_point(alpha = 0.5)
              </input>
            </program>

          </subsection>

          <subsection xml:id="subsec-ridge-plots">
            <title>Ridge plots</title>

            <p>Showing each individual point does not always reveal important characteristics of the distribution. Although not the case here, when the number of data points is so large that there is over-plotting, showing the data can be counterproductive. Boxplots help with this by providing a five-number summary, but this has limitations too. For example, boxplots will not permit us to discover bimodal distributions. To see this, note that the two plots below are summarizing the same dataset:</p>

            <program language="r">
              <input>
set.seed(1987)
z &lt;- sample(c(0,1), 1000, replace = TRUE, prob = c(0.25, 0.75))
x &lt;- rnorm(100)*z + rnorm(100, 5)*(1 - z)
p1 &lt;- data.frame(x=x) |&gt; 
  ggplot(aes(x)) + 
  geom_density(fill = 1, show.legend=FALSE, alpha = 0.2) +
  scale_x_continuous(limits=c(-4,8.5))
p2 &lt;- data.frame(g= "", x=x) |&gt; ggplot(aes(g, x)) + geom_boxplot() + xlab("") +
  theme(axis.ticks = element_blank())
  
gridExtra::grid.arrange(p1, p2, nrow = 1)
              </input>
            </program>

            <p>In cases in which we are concerned that the boxplot summary is too simplistic, we can show stacked smooth densities or histograms. We refer to these as <em>ridge plots</em>. Because we are used to visualizing densities with values in the x-axis, we stack them vertically. Also, because more space is needed in this approach, it is convenient to overlay them. The package <alert>ggridges</alert> provides a convenient function for doing this. Here is the income data shown above with boxplots but with a <em>ridge plot</em>.</p>

            <program language="r">
              <input>
library(ggridges)
p &lt;- gapminder |&gt; 
  filter(year == past_year &amp; !is.na(dollars_per_day)) |&gt;
  ggplot(aes(dollars_per_day, group)) + 
  scale_x_continuous(trans = "log2") 
p  + geom_density_ridges() 
              </input>
            </program>

            <p>Note that we have to invert the <c>x</c> and <c>y</c> used for the boxplot. A useful <c>geom_density_ridges</c> parameter is <c>scale</c>, which lets you determine the amount of overlap, with <c>scale = 1</c> meaning no overlap and larger values resulting in more overlap.</p>

            <p>If the number of data points is small enough, we can add them to the ridge plot using the following code:</p>

            <program language="r">
              <input>
p + geom_density_ridges(jittered_points = TRUE)
              </input>
            </program>

            <p>By default, the height of the points is jittered and should not be interpreted in any way. To show data points, but without using jitter we can use the following code to add what is referred to as a <em>rug representation</em> of the data.</p>

            <program language="r">
              <input>
p + geom_density_ridges(jittered_points = TRUE, 
                        position = position_points_jitter(height = 0),
                        point_shape = '|', point_size = 3, 
                        point_alpha = 1, alpha = 0.7)
              </input>
            </program>

          </subsection>

          <subsection xml:id="subsec-example-1970-versus-2010-income-distributions">
            <title>Example: 1970 versus 2010 income distributions</title>

            <p>Data exploration clearly shows that in 1970 there was a "west versus the rest" dichotomy. But does this dichotomy persist? Let's use <c>facet_grid</c> and see how the distributions have changed. To start, we will focus on two groups: the west and the rest. We make four histograms. We make this plot only for countries with data in both 1970 and 2010. Note that several countries were founded after 1970; for example, the Soviet Union divided into several countries during the 1990s. We also note that that data was available for more countries in 2010.</p>

            <p>We therefore make the plot only for countries with data in both years:</p>

            <program language="r">
              <input>
past_year &lt;- 1970
present_year &lt;- 2010
years &lt;- c(past_year, present_year)
country_list &lt;- gapminder |&gt; 
  filter(year %in% c(present_year, past_year)) |&gt;
  group_by(country) |&gt;
  summarize(n = sum(!is.na(dollars_per_day)), .groups = "drop") |&gt;
  filter(n == 2) |&gt;
  pull(country)
              </input>
            </program>

            <p>These <c>length(country_list)</c> countries account for <c>round(gapminder |> filter(year==present_year) |> summarize(perc=sum(population[country%in%country_list], na.rm=TRUE)/sum(population, na.rm=TRUE)) |> pull(perc)*100 )</c>% of the world population, so this subset should be representative. We can compare the distributions using this code:</p>

            <program language="r">
              <input>
gapminder |&gt; 
  filter(year %in% years &amp; country %in% country_list) |&gt;
  mutate(west = ifelse(group == "West", "West", "Developing")) |&gt;
  ggplot(aes(dollars_per_day)) +
  geom_histogram(binwidth = 1, color = "black") +
  scale_x_continuous(trans = "log2") + 
  facet_grid(year ~ west)
              </input>
            </program>

            <p>We now see that the rich countries have become a bit richer, but percentage-wise, the poor countries appear to have improved more. In particular, we see that the proportion of <em>developing</em> countries earning more than $16 a day increased substantially.</p>

            <p>To see which specific regions improved the most, we can remake the boxplots we made above, but now adding the year 2010 and then using facet to compare the two years.</p>

            <program language="r">
              <input>
gapminder |&gt; 
  filter(year %in% years &amp; country %in% country_list) |&gt;
  ggplot(aes(group, dollars_per_day)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  scale_y_continuous(trans = "log2") +
  xlab("") +
  facet_grid(. ~ year)
              </input>
            </program>

            <p>Here, we pause to introduce another powerful <alert>ggplot2</alert> feature. Because we want to compare each region before and after, it would be convenient to have the <c>past_year</c> boxplot next to the <c>present_year</c> boxplot for each region. In general, comparisons are easier when data are plotted next to each other.</p>

            <p>So instead of faceting, we keep the data from each year together and ask to color (or fill) them depending on the year. Note that groups are automatically separated by year and each pair of boxplots drawn next to each other. Because the year column is a number, we have to convert it into a factor since <alert>ggplot2</alert> automatically assigns a color to each category of a factor.</p>

            <program language="r">
              <input>
gapminder |&gt; 
  filter(year %in% years &amp; country %in% country_list) |&gt;
  mutate(year = factor(year)) |&gt;
  ggplot(aes(group, dollars_per_day, fill = year)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  scale_y_continuous(trans = "log2") +
  xlab("") 
              </input>
            </program>

            <p>The previous data exploration suggested that the income gap between rich and poor countries has narrowed considerably during the last 40 years. We used a series of histograms and boxplots to see this. We suggest a succinct way to convey this message with just one plot.</p>

            <p>Let's start by noting that density plots for income distribution in <c>past_year</c> and <c>present_year</c> deliver the message that the gap is closing:</p>

            <program language="r">
              <input>
gapminder |&gt; 
  filter(year %in% years &amp; country %in% country_list) |&gt;
  ggplot(aes(dollars_per_day)) +
  geom_density(fill = "grey") + 
  scale_x_continuous(trans = "log2") + 
  facet_grid(. ~ year)
              </input>
            </program>

            <p>In the <c>past_year</c> plot, we see two clear modes: poor and rich countries. In <c>present_year</c>, it appears that some of the poor countries have shifted towards the right, closing the gap.</p>

            <p>The next message we need to convey is that the reason for this change in distribution is that several poor countries became richer, rather than some rich countries becoming poorer. To do this, we can assign a color to the groups we identified during data exploration.</p>

            <p>However, because when we overlay two densities, the default is to have the area under the distribution curve add up to 1 for each group, regardless of the size of each group, we first need to learn how to make these smooth densities in a way that preserves information on the number of countries in each group. To do this, we will need to learn to access computed variables with the <c>geom_density</c> function.</p>

          </subsection>

          <subsection xml:id="subsec-accessing-computed-variables">
            <title>Accessing computed variables</title>

            <p>To have the areas of these densities be proportional to the size of the groups, we can simply multiply the y-axis values by the size of the group. From the <c>geom_density</c> help file, we see that the functions compute a variable called <c>count</c> that does exactly this. We want this variable to be on the y-axis rather than the density.</p>

            <p>In <alert>ggplot2</alert>, we access these variables using the function <c>after_stat</c>. We will therefore use the following mapping:</p>

            <program language="r">
              <input>
aes(x = dollars_per_day, y = after_stat(count))
              </input>
            </program>

            <p>We can now create the desired plot by simply changing the mapping in the previous code chunk. We will also expand the limits of the x-axis.</p>

            <program language="r">
              <input>
p &lt;- gapminder |&gt; 
  filter(year %in% years &amp; country %in% country_list) |&gt;
  mutate(group = ifelse(group == "West", "West", "Developing")) |&gt;
  ggplot(aes(dollars_per_day, y = after_stat(count), fill = group)) +
  scale_x_continuous(trans = "log2", limits = c(0.125, 300))
p + geom_density(alpha = 0.2) + facet_grid(year ~ .)
              </input>
            </program>

            <p>If we want the densities to be smoother, we use the <c>bw</c> argument so that the same bandwidth is used in each density. We selected 0.75 after trying out several values.</p>

            <program language="r">
              <input>
p + geom_density(alpha = 0.2, bw = 0.75) + facet_grid(year ~ .)
              </input>
            </program>

            <p>This plot now shows what is happening very clearly. The developing world distribution is changing. A third mode appears consisting of the countries that most narrowed the gap.</p>

            <p>To visualize if any of the groups defined above are driving this we can quickly make a ridge plot:</p>

            <program language="r">
              <input>
gapminder |&gt; 
  filter(year %in% years &amp; !is.na(dollars_per_day)) |&gt;
  ggplot(aes(dollars_per_day, group)) + 
  scale_x_continuous(trans = "log2") + 
  geom_density_ridges(bandwidth = 1.5) +
  facet_grid(. ~ year)
              </input>
            </program>

            <p>Another way to achieve this is by stacking the densities on top of each other:</p>

            <program language="r">
              <input>
gapminder |&gt; 
    filter(year %in% years &amp; country %in% country_list) |&gt;
  group_by(year) |&gt;
  mutate(weight = population/sum(population)*2) |&gt;
  ungroup() |&gt;
  ggplot(aes(dollars_per_day, fill = group)) +
  scale_x_continuous(trans = "log2", limits = c(0.125, 300)) + 
  geom_density(alpha = 0.2, bw = 0.75, position = "stack") + 
  facet_grid(year ~ .) 
              </input>
            </program>

            <p>Here we can clearly see how the distributions for East Asia, Latin America, and others shift markedly to the right while Sub-Saharan Africa remains stagnant.</p>

            <p>Notice that we order the levels of the group so that the West's density is plotted first, then Sub-Saharan Africa. Having the two extremes plotted first allows us to see the remaining bimodality better.</p>

          </subsection>

          <subsection xml:id="subsec-weighted-densities">
            <title>Weighted densities</title>

            <p>As a final point, we note that these distributions weigh every country the same. So if most of the population is improving, but living in a very large country, such as China, we might not appreciate this. We can actually weight the smooth densities using the <c>weight</c> mapping argument. The plot then looks like this:</p>

            <program language="r">
              <input>
gapminder |&gt; 
  filter(year %in% years &amp; country %in% country_list) |&gt;
  group_by(year) |&gt;
  mutate(weight = population/sum(population)*2) |&gt;
  ungroup() |&gt;
  ggplot(aes(dollars_per_day, fill = group, weight = weight)) +
  scale_x_continuous(trans = "log2", limits = c(0.125, 300)) + 
  geom_density(alpha = 0.2, bw = 0.75, position = "stack") + facet_grid(year ~ .) 
              </input>
            </program>

            <p>This particular figure shows very clearly how the income distribution gap is closing with most of the poor remaining in Sub-Saharan Africa.</p>

          </subsection>

        </section>

        <section xml:id="sec-case-study-2-the-ecological-fallacy">
          <title>Case study 2: the ecological fallacy</title>

          <p>Throughout this section, we have been comparing regions of the world. We have seen that, on average, some regions do better than others. In this section, we focus on describing the importance of variability within the groups when examining the relationship between a country's infant mortality rates and average income.</p>

          <p>We define a few more regions and compare the averages across regions:</p>

          <program language="r">
            <input>
library(ggrepel)
gapminder &lt;- gapminder |&gt; 
  mutate(group = case_when(
    region %in% c("Western Europe", "Northern Europe",
                  "Southern Europe", "Northern America", 
                  "Australia and New Zealand") ~ "West",
    region %in% "Northern Africa" ~ "Northern Africa",
    region %in% c("Eastern Asia", "South-Eastern Asia") ~ "East Asia",
    region == "Southern Asia"~ "Southern Asia",
    region %in% c("Central America", "South America", 
                  "Caribbean") ~ "Latin America",
    continent == "Africa" &amp; 
      region != "Northern Africa" ~ "Sub-Saharan",
    region %in% c("Melanesia", "Micronesia", 
                  "Polynesia") ~ "Pacific Islands"))
surv_income &lt;- gapminder |&gt; 
  filter(year %in% present_year &amp; !is.na(gdp) &amp; 
           !is.na(infant_mortality) &amp; !is.na(group)) |&gt;
  group_by(group) |&gt;
  summarize(income = sum(gdp)/sum(population)/365,
            infant_survival_rate = 
              1 - sum(infant_mortality/1000*population)/sum(population)) 

#surv_income |&gt; arrange(income) |&gt; print(n=nrow(surv_income))

surv_income |&gt; ggplot(aes(income, infant_survival_rate, label = group, color = group)) +
  scale_x_continuous(trans = "log2", limits = c(0.25, 150)) +
  scale_y_continuous(trans = "logit", limits = c(0.875, .9981), 
                     breaks = c(.85,.90,.95,.99,.995,.998)) +
  geom_label_repel(size = 3, show.legend = FALSE)
            </input>
          </program>

          <p>The relationship between these two variables is almost perfectly linear with the chosen axis transformations, and the graph shows a dramatic difference. While in the West less than 0.5% of infants die, in Sub-Saharan Africa the rate is higher than 6%!</p>

          <p>Note that the plot uses a new transformation, the logistic transformation.</p>

          <subsection xml:id="sec-logit">
            <title>Logistic transformation</title>

            <p>The logistic or logit transformation for a proportion or rate <m>p</m> is defined as:</p>

            <me>
f(p) = \log \left( \frac{p}{1-p} \right)
            </me>

            <p>When <m>p</m> is a proportion or probability, the quantity that is being logged, <m>p/(1-p)</m>, is called the <em>odds</em>. In this case <m>p</m> is the proportion of infants that survived. The odds tell us how many more infants are expected to survive than to die. The log transformation makes this symmetric. If the rates are the same, then the log odds is 0. Fold increases or decreases turn into positive and negative increments, respectively.</p>

            <p>This scale is useful when we want to highlight differences near 0 or 1. For survival rates this is important because a survival rate of 90% is unacceptable, while a survival of 99% is relatively good. We would much prefer a survival rate closer to 99.9%. We want our scale to highlight these difference and the logit does this. Note that 99.9/0.1 is about 10 times bigger than 99/1 which is about 10 times larger than 90/10. By using the log, these fold changes turn into constant increases.</p>

          </subsection>

          <subsection xml:id="subsec-show-the-data">
            <title>Show the data</title>

            <p>Now, back to our plot. Based on the plot above, do we conclude that a country with a low income is destined to have low survival rate? Do we conclude that survival rates in Sub-Saharan Africa are all lower than in Southern Asia, which in turn are lower than in the Pacific Islands, and so on?</p>

            <p>Jumping to this conclusion based on a plot showing averages is referred to as the <em>ecological fallacy</em>. The almost perfect relationship between survival rates and income is only observed for the averages at the region level. Once we show all the data, we see a somewhat more complicated story:</p>

            <program language="r">
              <input>
library(ggrepel)
highlight &lt;- c("Sierra Leone", "Mauritius",  "Sudan", "Botswana", "Tunisia",
               "Cambodia","Singapore","Chile", "Haiti", "Bolivia",
               "United States","Sweden", "Angola", "Serbia")

gapminder |&gt; filter(year %in% present_year &amp; !is.na(gdp) &amp; !is.na(infant_mortality) &amp; !is.na(group) ) |&gt;
  mutate(country_name = ifelse(country %in% highlight, as.character(country), "")) |&gt;
  ggplot(aes(dollars_per_day, 1 - infant_mortality/1000, col = group, label = country_name)) +
  scale_x_continuous(trans = "log2", limits = c(0.25, 150)) +
  scale_y_continuous(trans = "logit",limits = c(0.875, .9981),
                     breaks = c(.85,.90,.95,.99,.995,.998)) + 
  geom_point(alpha = 0.5, size = 3) +
  geom_text_repel(size = 4, show.legend = FALSE)
              </input>
            </program>

            <p>Specifically, we see that there is a large amount of variability. We see that countries from the same regions can be quite different and that countries with the same income can have different survival rates. For example, while on average Sub-Saharan Africa had the worse health and economic outcomes, there is wide variability within that group. Mauritius and Botswana are doing better than Angola and Sierra Leone, with Mauritius comparable to Western countries.</p>

          </subsection>

        </section>

        <section xml:id="sec-vaccines">
          <title>Case study 3: vaccines and infectious diseases</title>

          <p>Vaccines have helped save millions of lives. In the 19th century, before herd immunization was achieved through vaccination programs, deaths from infectious diseases, such as smallpox and polio, were common. Today however, vaccination programs have become somewhat controversial despite all the scientific evidence for their importance.</p>

          <p>The controversy started with a paper published in 1988 and led by Andrew Wakefield claiming there was a link between the administration of the measles, mumps, and rubella (MMR) vaccine and the appearance of autism and bowel disease. Despite much scientific evidence contradicting this finding, sensationalist media reports and fear-mongering from conspiracy theorists led parts of the public into believing that vaccines were harmful. As a result, many parents ceased to vaccinate their children. This dangerous practice can be potentially disastrous given that the Centers for Disease Control (CDC) estimates that vaccinations will prevent more than 21 million hospitalizations and 732,000 deaths among children born in the last 20 years (see Benefits from Immunization during the Vaccines for Children Program Era — United States, 1994-2013, MMWR). The 1988 paper has since been retracted and Andrew Wakefield was eventually "struck off the UK medical register, with a statement identifying deliberate falsification in the research published in The Lancet, and was thereby barred from practicing medicine in the UK." (source: Wikipedia). Yet misconceptions persist, in part due to self-proclaimed activists who continue to disseminate misinformation about vaccines.</p>

          <p>Effective communication of data is a strong antidote to misinformation and fear-mongering. In the introduction to this part of the book we showed an example, provided by a Wall Street Journal article, showing data related to the impact of vaccines on battling infectious diseases.  Here we reconstruct that example.</p>

          <subsection xml:id="subsec-vaccine-data">
            <title>Vaccine data</title>

            <p>The data used for these plots were collected, organized, and distributed by the Tycho Project. They include weekly reported counts for seven diseases from 1928 to 2011, from all fifty states. We include the yearly totals in the __dslabs__ package:</p>

            <program language="r">
              <input>
library(tidyverse)
library(RColorBrewer)
library(dslabs)
names(us_contagious_diseases)
              </input>
            </program>

            <p>We create a temporary object <c>dat</c> that stores only the measles data, includes a per 100,000 rate, orders states by average value of disease and removes Alaska and Hawaii since they only became states in the late 1950s. Note that there is a <c>weeks_reporting</c> column that tells us for how many weeks of the year data was reported. We have to adjust for that value when computing the rate.</p>

            <program language="r">
              <input>
the_disease &lt;- "Measles"
dat &lt;- us_contagious_diseases |&gt;
  filter(!state %in% c("Hawaii","Alaska") &amp; disease == the_disease) |&gt;
  mutate(rate = count / population * 10000 * 52 / weeks_reporting) |&gt; 
  mutate(state = reorder(state, ifelse(year &lt;= 1963, rate, NA), 
                         median, na.rm = TRUE)) 
              </input>
            </program>

          </subsection>

          <subsection xml:id="subsec-trend-plots">
            <title>Trend plots</title>

            <p>We can now easily plot disease rates per year. Here are the measles data from California:</p>

            <program language="r">
              <input>
dat |&gt; filter(state == "California" &amp; !is.na(rate)) |&gt;
  ggplot(aes(year, rate)) +
  geom_line() + 
  ylab("Cases per 10,000")  + 
  geom_vline(xintercept = 1963, col = "blue")
              </input>
            </program>

            <p>We add a vertical line at 1963 since this is when the vaccine was introduced .</p>

          </subsection>

        </section>

        <section xml:id="sec-heatmaps">
          <title>Heatmaps</title>

          <p>Now can we show data for all states in one plot? We have three variables to show: year, state, and rate. In the WSJ figure, they use the x-axis for year, the y-axis for state, and color hue to represent rates. However, the color scale they use, which goes from yellow to blue to green to orange to red, can be improved.</p>

          <p>In our example, we want to use a sequential palette since there is no meaningful center, just low and high rates.</p>

          <p>We use the geometry <c>geom_tile</c> to tile the region with colors representing disease rates. We use a square root transformation to avoid having the really high counts dominate the plot. Notice that missing values are shown in grey. Note that once a disease was pretty much eradicated, some states stopped reporting cases all together. This is why we see so much grey after 1980.</p>

          <program language="r">
            <input>
dat |&gt; ggplot(aes(year, state, fill = rate)) +
  geom_tile(color = "grey50") +
  scale_x_continuous(expand = c(0,0)) +
  scale_fill_gradientn(colors = brewer.pal(9, "Reds"), trans = "sqrt") +
  geom_vline(xintercept = 1963, col = "blue") +
  theme_minimal() +  
  theme(panel.grid = element_blank(), 
        legend.position = "bottom", 
        text = element_text(size = 8)) +
  labs(title = the_disease, x = "", y = "")
            </input>
          </program>

          <p>This plot makes a very striking argument for the contribution of vaccines. However, one limitation of this plot is that it uses color to represent quantity, which we earlier explained makes it harder to know exactly how high values are going. Position and lengths are better cues. If we are willing to lose state information, we can make a version of the plot that shows the values with position. We can also show the average for the US, which we compute like this:</p>

          <program language="r">
            <input>
avg &lt;- us_contagious_diseases |&gt;
  filter(disease == the_disease) |&gt; group_by(year) |&gt;
  summarize(us_rate = sum(count, na.rm = TRUE) / 
              sum(population, na.rm = TRUE) * 10000)
            </input>
          </program>

          <p>Now to make the plot we simply use the <c>geom_line</c> geometry:</p>

          <program language="r">
            <input>
dat |&gt; 
  filter(!is.na(rate)) |&gt;
    ggplot() +
  geom_line(aes(year, rate, group = state),  color = "grey50", 
            show.legend = FALSE, alpha = 0.2, linewidth = 1) +
  geom_line(mapping = aes(year, us_rate),  data = avg, linewidth = 1) +
  scale_y_continuous(trans = "sqrt", breaks = c(5, 25, 125, 300)) + 
  ggtitle("Cases per 10,000 by state") + 
  xlab("") + ylab("") +
  geom_text(data = data.frame(x = 1955, y = 50), 
            mapping = aes(x, y, label = "US average"), 
            color = "black") + 
  geom_vline(xintercept = 1963, col = "blue")
            </input>
          </program>

          <p>In theory, we could use color to represent the categorical value state, but it is hard to pick 50 distinct colors.</p>

        </section>

        <section xml:id="sec-dataviz-in-practice-exercises">
          <title>Exercises</title>

          <ol>
            <li><p>Reproduce the image plot we previously made but for smallpox. For this plot, do not include years in which cases were not reported in 10 or more weeks.</p></li>
            <li><p>Now reproduce the time series plot we previously made, but this time following the instructions of the previous question for smallpox.</p></li>
            <li><p>For the state of California, make a time series plot showing rates for all diseases. Include only years with 10 or more weeks reporting. Use a different color for each disease.</p></li>
            <li><p>Now do the same for the rates for the US. Hint: compute the US rate as the total divided by total population using <c>summarize</c>.</p></li>
          </ol>

        </section>
      </chapter>

    </part>

    <!-- Part 3: Data Wrangling -->
    <part xml:id="part-data-wrangling">
      <title>Data Wrangling</title>

      <chapter xml:id="ch-reshaping-data">
        <title>Reshaping data</title>
        
          <p>As we have seen through the book, having data in <em>tidy</em> format is what makes the tidyverse flow. After the first step in the data analysis process, importing data, a common next step is to reshape the data into a form that facilitates the rest of the analysis. The <alert>tidyr</alert> package, part of <alert>tidyverse</alert>, includes several functions that are useful for tidying data.</p>

          <p>We will use the fertility wide format dataset described in <xref ref="sec-tidy-data"/> as an example in this section.</p>

          <program language="r">
            <input>
library(tidyverse) 
library(dslabs)
path &lt;- system.file("extdata", package = "dslabs")
filename &lt;- file.path(path, "fertility-two-countries-example.csv")
wide_data &lt;- read_csv(filename)
            </input>
          </program>

        <section xml:id="sec-pivot-longer">
          <title>`pivot_longer`</title>

          <p>One of the most used functions in the <alert>tidyr</alert> package is <c>pivot_longer</c>, which is useful for converting wide data into tidy data.</p>

          <p>As with most tidyverse functions, the <c>pivot_longer</c> function's first argument is the data frame that will be converted. Here we want to reshape the <c>wide_data</c> dataset so that each row represents a fertility observation, which implies we need three columns to store the year, country, and the observed value. In its current form, data from different years are in different columns with the year values stored in the column names. Through the <c>names_to</c> and <c>values_to</c> argument we will tell <c>pivot_longer</c> the column names we want to assign to the columns containing the current column names and observations, respectively. The default names are <c>name</c> and <c>value</c>, which are often usable choices. In this case a better choice for these two arguments would be <c>year</c> and <c>fertility</c>. Note that nowhere in the data file does it tell us this is fertility data. Instead, we deciphered this from the file name. Through <c>cols</c>, the second argument, we specify the columns containing observed values; these are the columns that will be <em>pivoted</em>. The default is to pivot all columns so, in most cases, we have to specify the columns. In our example we want columns <c>1960</c>, <c>1961</c> up to <c>2015</c>.</p>

          <p>The code to pivot the fertility data therefore looks like this:</p>

          <program language="r">
            <input>
new_tidy_data &lt;- wide_data |&gt;
  pivot_longer(`1960`:`2015`, names_to = "year", values_to = "fertility")
            </input>
          </program>

          <p>We can see that the data have been converted to tidy format with columns <c>year</c> and <c>fertility</c></p>

          <program language="r">
            <input>
head(new_tidy_data)
            </input>
          </program>

          <p>and that each year resulted in two rows since we have two countries and this column was not pivoted. A somewhat quicker way to write this code is to specify which column will <alert>not</alert> include in the pivot, rather than all the columns that will be pivoted:</p>

          <program language="r">
            <input>
new_tidy_data &lt;- wide_data |&gt;
  pivot_longer(-country, names_to = "year", values_to = "fertility")
            </input>
          </program>

          <p>The <c>new_tidy_data</c> object looks like the original <c>tidy_data</c> we defined this way</p>

          <program language="r">
            <input>
tidy_data &lt;- gapminder |&gt; 
  filter(country %in% c("South Korea", "Germany") &amp; !is.na(fertility)) |&gt;
  select(country, year, fertility)
            </input>
          </program>

          <p>with just one minor difference. Can you spot it? Look at the data type of the year column. The <c>pivot_longer</c> function assumes that column names are characters. So we need a bit more wrangling before we are ready to make a plot. We need to convert the year column to be numbers:</p>

          <program language="r">
            <input>
new_tidy_data &lt;- wide_data |&gt;
  pivot_longer(-country, names_to = "year", values_to = "fertility") |&gt;
  mutate(year = as.integer(year))
            </input>
          </program>

          <p>Now that the data is tidy, we can use this relatively simple ggplot code:</p>

          <program language="r">
            <input>
new_tidy_data |&gt; 
  ggplot(aes(year, fertility, color = country)) + 
  geom_point()
            </input>
          </program>

        </section>

        <section xml:id="sec-pivot-wider">
          <title>`pivot_wider`</title>

          <p>As we will see in later examples, it is sometimes useful for data wrangling purposes to convert tidy data into wide data. We often use this as an intermediate step in tidying up data. The <c>pivot_wider</c> function is basically the inverse of <c>pivot_longer</c>. The first argument is for the data, but since we are using the pipe, we don't show it. The <c>names_from</c> argument tells <c>pivot_wider</c> which variable will be used as the column names. The <c>values_from</c> argument specifies which variable to use to fill out the cells.</p>

          <program language="r">
            <input>
new_wide_data &lt;- new_tidy_data |&gt; 
  pivot_wider(names_from = year, values_from = fertility)
select(new_wide_data, country, `1960`:`1967`)
            </input>
          </program>

          <p>Similar to <c>pivot_wider</c>, <c>names_from</c> and <c>values_from</c> default to <c>name</c> and <c>value</c>.</p>

        </section>

        <section xml:id="sec-separate">
          <title>Separating variables</title>

          <p>The data wrangling shown above was simple compared to what is usually required. In our example spreadsheet files, we include an illustration that is slightly more complicated. It contains two variables: life expectancy and fertility. However, the way it is stored is not tidy and, as we will explain, not optimal.</p>

          <program language="r">
            <input>
path &lt;- system.file("extdata", package = "dslabs")

filename &lt;- "life-expectancy-and-fertility-two-countries-example.csv"
filename &lt;-  file.path(path, filename)

raw_dat &lt;- read_csv(filename)
select(raw_dat, 1:5)
            </input>
          </program>

          <p>First, note that the data is in wide format. Second, notice that this table includes values for two variables, fertility and life expectancy, with the column name encoding which column represents which variable. Encoding information in the column names is not recommended but, unfortunately, it is quite common. We will put our wrangling skills to work to extract this information and store it in a tidy fashion.</p>

          <p>We can start the data wrangling with the <c>pivot_longer</c> function, but we should no longer use the column name <c>year</c> for the new column since it also contains the variable type. We will call it <c>name</c>, the default, for now:</p>

          <program language="r">
            <input>
dat &lt;- raw_dat |&gt; pivot_longer(-country)
head(dat)
            </input>
          </program>

          <p>The result is not exactly what we refer to as tidy since each observation is associated with two, not one, rows. We want to have the values from the two variables, fertility and life expectancy, in two separate columns. The first challenge to achieve this is to separate the <c>name</c> column into the year and the variable type. Notice that the entries in this column separate the year from the variable name with an underscore:</p>

          <program language="r">
            <input>
dat$name[1:5]
            </input>
          </program>

          <p>Encoding multiple variables in a column name is such a common problem that the <alert>tidyr</alert> package includes function to separate these columns into two or more. The <c>separate_wider_delim</c> function takes three arguments: the name of the column to be separated, the names to be used for the new columns, and the character that separates the variables. So, a first attempt at separating the variable name from the year might be:</p>

          <program language="r">
            <input>
dat |&gt; separate_wider_delim(name, delim = "_", 
                            names = c("year", "name"))
            </input>
          </program>

          <p>However, this line of code will give an error. This is because the life expectancy names have three strings separated by <c>_</c> and the fertility names have two. This is a common problem so the <c>separate_wider_delim</c> function has arguments <c>too_few</c> and <c>too_many</c> to handle these situations. We see in the help file that the option <c>too_many = merge</c> <em>will merge together any additional pieces</em>. The following line does what we want:</p>

          <program language="r">
            <input>
dat |&gt; separate_wider_delim(name, delim = "_", 
                            names = c("year", "name"), 
                            too_many = "merge")
            </input>
          </program>

          <p>But we are not done yet. We need to create a column for each variable and change <c>year</c> to a number. As we learned, the <c>pivot_wider</c> function can do this:</p>

          <program language="r">
            <input>
dat &lt;- dat |&gt; 
  separate_wider_delim(name, delim = "_", 
                       names = c("year", "name"), 
                       too_many = "merge") |&gt;
  pivot_wider() |&gt;
  mutate(year = as.integer(year))

dat
            </input>
          </program>

          <p>The data is now in tidy format with one row for each observation with three variables: year, fertility, and life expectancy.</p>

          <p>Three related function are <c>separate_wider_position</c>, <c>separate_wider_regex</c>, and <c>unite</c>. <c>separate_wider_position</c> takes a width instead of delimiter. <c>separate_wider_regex</c>, described in <xref ref="sec-separate"/>_regex, provides much more control over how we separate and what we keep. The <c>unite</c> function can be thought of as the inverse of the <c>separate</c> function: it combines two columns into one.</p>

        </section>

        <section xml:id="sec-reshaping-with-data-table">
          <title>Reshaping with data.table</title>

          <p>In general, everything you can do with <alert>tidyverse</alert> can be done with <alert>data.table</alert> and base R which, although perhaps harder to read, it is often more flexible, faster, and more efficient. Here we show how the <alert>data.table</alert> approach to <c>pivot_longer</c>, <c>pivot_wider</c>, and <c>separate</c>. We will illustrate with the previously used this example:</p>

          <program language="r">
            <input>
path &lt;- system.file("extdata", package = "dslabs")
filename &lt;- file.path(path, "fertility-two-countries-example.csv")
            </input>
          </program>

          <subsection xml:id="subsec-pivot-longer-is-melt">
            <title>`pivot_longer` is `melt`</title>

            <p>If in <alert>tidyverse</alert> we  write</p>

            <program language="r">
              <input>
wide_data &lt;- read_csv(filename)
new_tidy_data &lt;- wide_data |&gt;
  pivot_longer(-1, names_to = "year", values_to = "fertility")
              </input>
            </program>

            <p>in <alert>data.table</alert> we use the <c>melt</c> function.</p>

            <program language="r">
              <input>
#| message: false
#| warning: false
library(data.table)
dt_wide_data &lt;- fread(filename) 
dt_new_tidy_data  &lt;- melt(dt_wide_data, 
                      measure.vars = 2:ncol(dt_wide_data), 
                      variable.name = "year", 
                      value.name = "fertility")
              </input>
            </program>

          </subsection>

          <subsection xml:id="subsec-pivot-wider-is-dcast">
            <title>`pivot_wider` is `dcast`</title>

            <p>If in <alert>tidyverse</alert> we  write</p>

            <program language="r">
              <input>
new_wide_data &lt;- new_tidy_data |&gt; 
  pivot_wider(names_from = year, values_from = fertility)
              </input>
            </program>

            <p>in <alert>data.table</alert> we use the <c>dcast</c> function.</p>

            <program language="r">
              <input>
dt_new_wide_data &lt;- dcast(dt_new_tidy_data, formula = ... ~ year,
                          value.var = "fertility")
              </input>
            </program>

          </subsection>

          <subsection xml:id="subsec-separating-variables">
            <title>Separating variables</title>

            <p>We now illustrate with this previously used example:</p>

            <program language="r">
              <input>
path &lt;- system.file("extdata", package = "dslabs")
filename &lt;- "life-expectancy-and-fertility-two-countries-example.csv"
filename &lt;-  file.path(path, filename)
              </input>
            </program>

            <p>In <alert>tidyverse</alert> we wrangled using</p>

            <program language="r">
              <input>
raw_dat &lt;- read_csv(filename)
dat &lt;- raw_dat |&gt; pivot_longer(-country) |&gt;
  separate_wider_delim(name, delim = "_", names = c("year", "name"), 
                       too_many = "merge") |&gt;
  pivot_wider() |&gt;
  mutate(year = as.integer(year))
              </input>
            </program>

            <p>In <alert>data.table</alert> we can use the <c>tstrsplit</c> function:</p>

            <program language="r">
              <input>
dt_raw_dat &lt;- fread(filename)
dat_long &lt;- melt(dt_raw_dat, 
                 measure.vars = which(names(dt_raw_dat) != "country"), 
                 variable.name = "name", value.name = "value")
dat_long[, c("year", "name", "name2") := 
           tstrsplit(name, "_", fixed = TRUE, type.convert = TRUE)]
dat_long[is.na(name2), name2 := ""]
dat_long[, name := paste(name, name2, sep = "_")][, name2 := NULL]
dat_wide &lt;- dcast(dat_long, country + year ~ name, value.var = "value")
              </input>
            </program>

          </subsection>

        </section>

        <section xml:id="sec-the-janitor-package">
          <title>The janitor package</title>

          <p>The <alert>janitor</alert> package includes function for some of the most common steps needed to wrangle data. These are particularly useful as these tasks that are often repetitive and time-consuming. Key features include functions for examining and cleaning column names, removing empty or duplicate rows, and converting data types. It also offers capabilities to generate frequency tables and perform cross tabulations with ease. The package is designed to work seamlessly with the  <alert>tidyverse</alert>. Here we show four examples.</p>

          <p>Spreadsheets often use names that are not compatible with programming. The most common problem is column names with spaces. The <c>clean_names()</c> function attempts to fix this and other common problems. By default it forces variable names to be lower case and with underscore instead of space. In this example we change the variable names of the object <c>dat</c> created in the previous section and then demonstrate how this function works:</p>

          <program language="r">
            <input>
library(janitor)
names(dat) &lt;- c("Country", "Year", "Fertility",  "Life Expectancy")
clean_names(dat) |&gt; names()
            </input>
          </program>

          <p>Another very common challenging reality is that numeric matrices are saved in spreadsheets and include a column with characters defining the row names. To fix this we have to remove the first column, but only after assigning them as vector that we will use to define rownames after converting the data frame to a matrix. The function <c>column_to_rows</c> does these operations for us and all we have to do is specify which column contains the rownames:</p>

          <program language="r">
            <input>
data.frame(ids = letters[1:3], x = 1:3, y = 4:6) |&gt; 
  column_to_rownames("ids") |&gt;
  as.matrix() 
            </input>
          </program>

          <p>Another common challenge is that spreadsheets include the column names as a first row. To quickly fix this we can <c>row_to_names</c>:</p>

          <program language="r">
            <input>
x &lt;- read.csv(file.path(path, "murders.csv"), header = FALSE) |&gt; 
  row_to_names(1)
names(x)
            </input>
          </program>

          <p>Our final example relates to finding duplicates. A very common error in the creation of spreadsheets is that rows are duplicated. The <c>get_dups</c> function finds and reports duplicate records. By default it considers all variables, but you can also specify which ones to use.</p>

          <program language="r">
            <input>
x &lt;- bind_rows(x, x[1,])
get_dupes(x)
            </input>
          </program>

        </section>

        <section xml:id="sec-reshaping-data-exercises">
          <title>Exercises</title>

          <ol>
            <li><p>Run the following command to define the <c>co2_wide</c> object:</p></li>
          <program language="r">
            <input>
co2_wide &lt;- data.frame(matrix(co2, ncol = 12, byrow = TRUE)) |&gt; 
  setNames(1:12) |&gt;
  mutate(year = as.character(1959:1997))
            </input>
          </program>

          </ol>

          <p>Use the <c>pivot_longer</c> function to wrangle this into a tidy dataset. Call the column with the CO2 measurements <c>co2</c> and call the month column <c>month</c>. Call the resulting object <c>co2_tidy</c>.</p>

          <ol>
            <li><p>Plot CO2 versus month with a different curve for each year using this code:</p></li>
          <program language="r">
            <input>
co2_tidy |&gt; ggplot(aes(month, co2, color = year)) + geom_line()
            </input>
          </program>

          </ol>

          <p>If the expected plot is not made, it is probably because <c>co2_tidy$month</c> is not numeric:</p>

          <program language="r">
            <input>
class(co2_tidy$month)
            </input>
          </program>

          <p>Rewrite your code to make sure the month column is numeric. Then make the plot.</p>

          <ol>
            <li><p>What do we learn from this plot?</p></li>
          </ol>

          <p>a.  CO2 measures increase monotonically from 1959 to 1997. b.  CO2 measures are higher in the summer and the yearly average increased from 1959 to 1997. c.  CO2 measures appear constant and random variability explains the differences. d.  CO2 measures do not have a seasonal trend.</p>

          <ol>
            <li><p>Now load the <c>admissions</c> data set, which contains admission information for men and women across six majors and keep only the admitted percentage column:</p></li>
          <program language="r">
            <input>
load(admissions)
dat &lt;- admissions |&gt; select(-applicants)
            </input>
          </program>

          </ol>

          <p>If we think of an observation as a major, and that each observation has two variables (men admitted percentage and women admitted percentage) then this is not tidy. Use the <c>pivot_wider</c> function to wrangle into tidy shape: one row for each major.</p>

          <ol>
            <li><p>Now we will try a more advanced wrangling challenge. We want to wrangle the admissions data so that for each major we have 4 observations: <c>admitted_men</c>, <c>admitted_women</c>, <c>applicants_men</c> and <c>applicants_women</c>. The <em>trick</em> we perform here is actually quite common: first use <c>pivot_longer</c> to generate an intermediate data frame and then <c>pivot_wider</c> to obtain the tidy data we want. We will go step by step in this and the next two exercises.</p></li>
          </ol>

          <p>Use the <c>pivot_longer</c> function to create a <c>tmp</c> data frame with a column containing the type of observation: <c>admitted</c> or <c>applicants</c>. Call the new columns <c>name</c> and <c>value</c>.</p>

          <ol>
            <li><p>Now you have an object <c>tmp</c> with columns <c>major</c>, <c>gender</c>, <c>name</c> and <c>value</c>. Note that if you combine the <c>name</c> and <c>gender</c>, we get the column names we want: <c>admitted_men</c>, <c>admitted_women</c>, <c>applicants_men</c> and <c>applicants_women</c>. Use the function <c>unite</c> to create a new column called <c>column_name</c>.</p></li>
            <li><p>Now use the <c>pivot_wider</c> function to generate the tidy data with four variables for each major.</p></li>
            <li><p>Now use the pipe to write a line of code that turns <c>admissions</c> to the table produced in the previous exercise.</p></li>
          </ol>

        </section>
        
      </chapter>

      <chapter xml:id="ch-joining-tables">
        <title>Joining tables</title>
        
          <p>The information we need for a given analysis may not be just in one table. Here we use a simple examples to illustrate the general challenge of combining tables.</p>

          <p>Suppose we want to explore the relationship between population size for US states and electoral votes. We have the population size in this table:</p>

          <program language="r">
            <input>
library(tidyverse)
library(dslabs)
head(murders)
            </input>
          </program>

          <p>and electoral votes in this one:</p>

          <program language="r">
            <input>
head(results_us_election_2016)
            </input>
          </program>

          <p>Just concatenating these two tables together will not work since the order of the states is not the same.</p>

          <program language="r">
            <input>
identical(results_us_election_2016$state, murders$state)
            </input>
          </program>

          <p>The <em>join</em> functions, described below, are designed to handle this challenge.</p>

        <section xml:id="sec-joins">
          <title>Joins</title>

          <p>The <em>join</em> functions in the __dplyr__ package make sure that the tables are combined so that matching rows are together. If you know SQL, you will see that the approach and syntax is very similar. The general idea is that one needs to identify one or more columns that will serve to match the two tables. Then a new table with the combined information is returned. Notice what happens if we join the two tables above by state using <c>left_join</c> (we will remove the <c>others</c> column and rename <c>electoral_votes</c> so that the tables fit on the page):</p>

          <program language="r">
            <input>
tab &lt;- left_join(murders, results_us_election_2016, by = "state") |&gt;
  select(-others) |&gt; rename(ev = electoral_votes)
head(tab)
            </input>
          </program>

          <p>The data has been successfully joined and we can now, for example, make a plot to explore the relationship:</p>

          <program language="r">
            <input>
library(ggrepel)
tab |&gt; ggplot(aes(population/10^6, ev, label = abb)) +
  geom_point() +
  scale_x_log10() + scale_y_log10() +
  geom_text_repel() + 
  geom_smooth(method = "lm", se = FALSE)
            </input>
          </program>

          <p>We see the relationship is close to linear with about 2 electoral votes for every million persons, but with very small states getting higher ratios.</p>

          <p>In practice, it is not always the case that each row in one table has a matching row in the other. For this reason, we have several versions of join. To illustrate this challenge, we will take subsets of the tables above. We create the tables <c>tab1</c> and <c>tab2</c> so that they have some states in common but not all:</p>

          <program language="r">
            <input>
tab_1 &lt;- slice(murders, 1:6) |&gt; select(state, population)
tab_2 &lt;- results_us_election_2016 |&gt; 
  filter(state %in% c("Alabama", "Alaska", "Arizona", 
                    "California", "Connecticut", "Delaware")) |&gt; 
  select(state, electoral_votes) |&gt; rename(ev = electoral_votes)
            </input>
          </program>

          <p>We will use these two tables as examples in the next sections.</p>

          <subsection xml:id="subsec-left-join">
            <title>Left join</title>

            <p>Suppose we want a table like <c>tab_1</c>, but adding electoral votes to whatever states we have available. For this, we use <c>left_join</c> with <c>tab_1</c> as the first argument. We specify which column to use to match with the <c>by</c> argument.</p>

            <program language="r">
              <input>
left_join(tab_1, tab_2, by = "state")
              </input>
            </program>

            <p>Note that <c>NA</c>s are added to the two states not appearing in <c>tab_2</c>. Also, notice that this function, as well as all the other joins, can receive the first arguments through the pipe:</p>

            <program language="r">
              <input>
tab_1 |&gt; left_join(tab_2, by = "state")
              </input>
            </program>

          </subsection>

          <subsection xml:id="subsec-right-join">
            <title>Right join</title>

            <p>If instead of a table with the same rows as first table, we want one with the same rows as second table, we can use <c>right_join</c>:</p>

            <program language="r">
              <input>
tab_1 |&gt; right_join(tab_2, by = "state")
              </input>
            </program>

            <p>Now the NAs are in the column coming from <c>tab_1</c>.</p>

          </subsection>

          <subsection xml:id="subsec-inner-join">
            <title>Inner join</title>

            <p>If we want to keep only the rows that have information in both tables, we use <c>inner_join</c>. You can think of this as an intersection:</p>

            <program language="r">
              <input>
inner_join(tab_1, tab_2, by = "state")
              </input>
            </program>

          </subsection>

          <subsection xml:id="subsec-full-join">
            <title>Full join</title>

            <p>If we want to keep all the rows and fill the missing parts with NAs, we can use <c>full_join</c>. You can think of this as a union:</p>

            <program language="r">
              <input>
full_join(tab_1, tab_2, by = "state")
              </input>
            </program>

          </subsection>

          <subsection xml:id="subsec-semi-join">
            <title>Semi join</title>

            <p>The <c>semi_join</c> function lets us keep the part of first table for which we have information in the second. It does not add the columns of the second:</p>

            <program language="r">
              <input>
semi_join(tab_1, tab_2, by = "state")
              </input>
            </program>

          </subsection>

          <subsection xml:id="subsec-anti-join">
            <title>Anti join</title>

            <p>The function <c>anti_join</c> is the opposite of <c>semi_join</c>. It keeps the elements of the first table for which there is no information in the second:</p>

            <program language="r">
              <input>
anti_join(tab_1, tab_2, by = "state")
              </input>
            </program>

            <p>The following diagram summarizes the above joins:</p>

            <figure>
              <image source="dataviz/img/joins.png"/>
            </figure>

            <p>(Image courtesy of RStudio. CC-BY-4.0 license. Cropped from original.)</p>

          </subsection>

        </section>

        <section xml:id="sec-binding">
          <title>Binding</title>

          <p>Although we have yet to use it in this book, another common way in which datasets are combined is by <em>binding</em> them. Unlike the join function, the binding functions do not try to match by a variable, but instead simply combine datasets. If the datasets don't match by the appropriate dimensions, one obtains an error.</p>

          <subsection xml:id="subsec-binding-columns">
            <title>Binding columns</title>

            <p>The __dplyr__ function _bind_cols_ binds two objects by making them columns in a tibble. For example, we quickly want to make a data frame consisting of numbers we can use</p>

            <program language="r">
              <input>
bind_cols(a = 1:3, b = 4:6)
              </input>
            </program>

            <p>This function requires that we assign names to the columns. Here we chose <c>a</c> and <c>b</c>.</p>

            <p>Note that there is an R-base function <c>cbind</c> with the exact same functionality. An important difference is that <c>cbind</c> can create different types of objects, while <c>bind_cols</c> always produces a data frame.</p>

            <p><c>bind_cols</c> can also bind two different data frames. For example, here we break up the <c>tab</c> data frame and then bind them back together:</p>

            <program language="r">
              <input>
tab_1 &lt;- tab[, 1:3]
tab_2 &lt;- tab[, 4:6]
tab_3 &lt;- tab[, 7:8]
new_tab &lt;- bind_cols(tab_1, tab_2, tab_3)
head(new_tab)
              </input>
            </program>

          </subsection>

          <subsection xml:id="subsec-binding-by-rows">
            <title>Binding by rows</title>

            <p>The <c>bind_rows</c> function is similar to <c>bind_cols</c>, but binds rows instead of columns:</p>

            <program language="r">
              <input>
tab_1 &lt;- tab[1:2,]
tab_2 &lt;- tab[3:4,]
bind_rows(tab_1, tab_2)
              </input>
            </program>

            <p>This is based on an R-base function <c>rbind</c>.</p>

          </subsection>

        </section>

        <section xml:id="sec-set-operators">
          <title>Set operators</title>

          <p>Another set of commands useful for combining datasets are the set operators. When applied to vectors, these behave as their names suggest. Examples are <c>intersect</c>, <c>union</c>, <c>setdiff</c>, and <c>setequal</c>. However, if the __tidyverse__, or  more specifically __dplyr__, is loaded, these functions can be used on data frames as opposed to just on vectors.</p>

          <subsection xml:id="subsec-intersect">
            <title>Intersect</title>

            <p>You can take intersections of vectors of any type, such as numeric:</p>

            <program language="r">
              <input>
intersect(1:10, 6:15)
              </input>
            </program>

            <p>or characters:</p>

            <program language="r">
              <input>
intersect(c("a","b","c"), c("b","c","d"))
              </input>
            </program>

            <p>The __dplyr__ package includes an <c>intersect</c> function that can be applied to tables with the same column names. This function returns the rows in common between two tables. To make sure we use the __dplyr__ version of <c>intersect</c> rather than the base R version, we can use <c>dplyr::intersect</c> like this:</p>

            <program language="r">
              <input>
tab_1 &lt;- tab[1:5,]
tab_2 &lt;- tab[3:7,]
dplyr::intersect(tab_1, tab_2)
              </input>
            </program>

          </subsection>

          <subsection xml:id="subsec-union">
            <title>Union</title>

            <p>Similarly <em>union</em> takes the union of vectors. For example:</p>

            <program language="r">
              <input>
union(1:10, 6:15)
union(c("a","b","c"), c("b","c","d"))
              </input>
            </program>

            <p>The __dplyr__ package includes a version of <c>union</c> that combines all the rows of two tables with the same column names.</p>

            <program language="r">
              <input>
tab_1 &lt;- tab[1:5,]
tab_2 &lt;- tab[3:7,]
dplyr::union(tab_1, tab_2) 
              </input>
            </program>

          </subsection>

          <subsection xml:id="subsec-setdiff">
            <title>`setdiff`</title>

            <p>The set difference between a first and second argument can be obtained with <c>setdiff</c>. Unlike <c>intersect</c> and <c>union</c>, this function is not symmetric:</p>

            <program language="r">
              <input>
setdiff(1:10, 6:15)
setdiff(6:15, 1:10)
              </input>
            </program>

            <p>As with the functions shown above, __dplyr__ has a version for data frames:</p>

            <program language="r">
              <input>
tab_1 &lt;- tab[1:5,]
tab_2 &lt;- tab[3:7,]
dplyr::setdiff(tab_1, tab_2)
              </input>
            </program>

          </subsection>

          <subsection xml:id="subsec-setequal">
            <title>`setequal`</title>

            <p>Finally, the function <c>setequal</c> tells us if two sets are the same, regardless of order. So notice that:</p>

            <program language="r">
              <input>
setequal(1:5, 1:6)
              </input>
            </program>

            <p>but:</p>

            <program language="r">
              <input>
setequal(1:5, 5:1)
              </input>
            </program>

            <p>The __dplyr__ version checks whether data frames are equal, regardless of order of rows <em>or</em> columns:</p>

            <program language="r">
              <input>
dplyr::setequal(tab_1, tab_2)
              </input>
            </program>

          </subsection>

        </section>

        <section xml:id="sec-joining-with-data-table">
          <title>Joining with data.table</title>

          <p>The <alert>data.table</alert> package includes <c>merge</c>, a very efficient function for joining tables.</p>

          <p>In <alert>tidyverse</alert> we joined two tables with <c>left_join</c>:</p>

          <program language="r">
            <input>
tab &lt;- left_join(murders, results_us_election_2016, by = "state") 
            </input>
          </program>

          <p>In <alert>data.table</alert> the <c>merge</c> functions works similarly:</p>

          <program language="r">
            <input>
#| message: false
#| warning: false
library(data.table)
tab &lt;- merge(murders, results_us_election_2016, by = "state", all.x = TRUE)
            </input>
          </program>

          <p>Instead of defining different functions for the different type of joins, <c>merge</c> uses the the logical arguments <c>all</c> (full join), <c>all.x</c> (left join), and <c>all.y</c> (right join).</p>

        </section>

        <section xml:id="sec-joining-tables-exercises">
          <title>Exercises</title>

          <ol>
            <li><p>Install and load the __Lahman__ library. This database includes data related to baseball teams. It includes summary statistics about how the players performed on offense and defense for several years. It also includes personal information about the players.</p></li>
          </ol>

          <p>The <c>Batting</c> data frame contains the offensive statistics for all players for many years. You can see, for example, the top 10 hitters by running this code:</p>

          <program language="r">
            <input>
library(Lahman)

top &lt;- Batting |&gt; 
  filter(yearID == 2016) |&gt;
  arrange(desc(HR)) |&gt;
  slice(1:10)

top |&gt; as_tibble()
            </input>
          </program>

          <p>But who are these players? We see an ID, but not the names. The player names are in this table</p>

          <program language="r">
            <input>
People |&gt; as_tibble()
            </input>
          </program>

          <p>We can see column names <c>nameFirst</c> and <c>nameLast</c>. Use the <c>left_join</c> function to create a table of the top home run hitters. The table should have <c>playerID</c>, first name, last name, and number of home runs (HR).  Rewrite the object <c>top</c> with this new table.</p>

          <ol>
            <li><p>Now use the <c>Salaries</c> data frame to add each player's salary to the table you created in exercise 1. Note that salaries are different every year so make sure to filter for the year 2016, then use <c>right_join</c>. This time show first name, last name, team, HR, and salary.</p></li>
            <li><p>In a previous exercise, we created a tidy version of the <c>co2</c> dataset:</p></li>
          <program language="r">
            <input>
co2_wide &lt;- data.frame(matrix(co2, ncol = 12, byrow = TRUE)) |&gt; 
  setNames(1:12) |&gt;
  mutate(year = 1959:1997) |&gt;
  pivot_longer(-year, names_to = "month", values_to = "co2") |&gt;
  mutate(month = as.numeric(month))
            </input>
          </program>

          </ol>

          <p>We want to see if the monthly trend is changing, so we are going to remove the year effects and then plot the results. We will first compute the year averages. Use the <c>group_by</c> and <c>summarize</c> to compute the average co2 for each year. Save in an object called <c>yearly_avg</c>.</p>

          <ol>
            <li><p>Now use the <c>left_join</c> function to add the yearly average to the <c>co2_wide</c> dataset. Then compute the residuals: observed co2 measure - yearly average.</p></li>
            <li><p>Make a plot of the seasonal trends by year but only after removing the year effect.</p></li>
          </ol>

        </section>
        
      </chapter>

      <chapter xml:id="ch-parsing-dates-and-times">
        <title>Parsing dates and times</title>
        
          <p>We have described three main types of vectors: numeric, character, and logical. When analyzing data, we often encounter variables that are dates. Although we can represent a date with a string, for example <c>November 2, 2017</c>, once we pick a reference day, referred to as the <em>epoch</em> by computer programmers, they can be converted to numbers by calculating the number of days since the epoch. In R and Unix, the epoch is defined as January 1, 1970. So, for example, January 2, 1970 is day 1, December 31, 1969 is day -1, and November 2, 2017, is day 17,204.</p>

          <p>Now how should we represent dates and times when analyzing data in R? We could just use days since the epoch, but then it is almost impossible to interpret. If I tell you it's November 2, 2017, you know what this means immediately. If I tell you it's day 17,204, you will be quite confused. Similar problems arise with times and even more complications can appear due to time zones. For this reason, R defines a data type just for dates and times.</p>

        <section xml:id="sec-the-date-data-type">
          <title>The date data type</title>

          <p>We can see an example of the data type R uses for data here:</p>

          <program language="r">
            <input>
library(tidyverse)
library(dslabs)
polls_us_election_2016$startdate |&gt; head()
            </input>
          </program>

          <p>The dates look like strings, but they are not:</p>

          <program language="r">
            <input>
class(polls_us_election_2016$startdate)
            </input>
          </program>

          <p>Look at what happens when we convert them to numbers:</p>

          <program language="r">
            <input>
as.numeric(polls_us_election_2016$startdate) |&gt; head()
            </input>
          </program>

          <p>It turns them into days since the epoch. The <c>as.Date</c> function can convert a character into a date. So to see that the epoch is day 0 we can type</p>

          <program language="r">
            <input>
as.Date("1970-01-01") |&gt; as.numeric()
            </input>
          </program>

          <p>Plotting functions, such as those in ggplot, are aware of the date format. This means that, for example, a scatterplot can use the numeric representation to decide on the position of the point, but include the string in the labels:</p>

          <program language="r">
            <input>
polls_us_election_2016 |&gt; filter(pollster == "Ipsos" &amp; state == "U.S.") |&gt;
  ggplot(aes(startdate, rawpoll_trump)) +
  geom_line()
            </input>
          </program>

          <p>Note in particular that the month names are displayed, a very convenient feature.</p>

        </section>

        <section xml:id="sec-lubridate">
          <title>The lubridate package</title>

          <p>The __lubridate__ package provides tools to work with date and times.</p>

          <program language="r">
            <input>
library(lubridate)
            </input>
          </program>

          <p>We will take a random sample of dates to show some of the useful things one can do:</p>

          <program language="r">
            <input>
set.seed(2002)
dates &lt;- sample(polls_us_election_2016$startdate, 10) |&gt; sort()
dates
            </input>
          </program>

          <p>The functions <c>year</c>, <c>month</c> and <c>day</c> extract those values:</p>

          <program language="r">
            <input>
tibble(date = dates, month = month(dates), day = day(dates), year = year(dates))
            </input>
          </program>

          <p>We can also extract the month labels:</p>

          <program language="r">
            <input>
month(dates, label = TRUE)
            </input>
          </program>

          <program language="r">
            <input>
lubridate::month(dates, label = TRUE)
            </input>
          </program>

          <p>Another useful set of functions are the <em>parsers</em> that convert strings into dates. The function <c>ymd</c> assumes the dates are in the format YYYY-MM-DD and tries to parse as well as possible.</p>

          <program language="r">
            <input>
x &lt;- c(20090101, "2009-01-02", "2009 01 03", "2009-1-4",
       "2009-1, 5", "Created on 2009 1 6", "200901 !!! 07")
ymd(x)
            </input>
          </program>

          <p>A further complication comes from the fact that dates often come in different formats in which the order of year, month, and day are different. The preferred format is to show year (with all four digits), month (two digits), and then day, or what is called the ISO 8601. Specifically we use YYYY-MM-DD so that if we order the string, it will be ordered by date. You can see the function <c>ymd</c> returns them in this format.</p>

          <p>But, what if you encounter dates such as "09/01/02"? This could be September 1, 2002 or January 2, 2009 or January 9, 2002. In these cases, examining the entire vector of dates will help you determine what format it is by process of elimination. Once you know, you can use the many parses provided by __lubridate__.</p>

          <p>For example, if the string is:</p>

          <program language="r">
            <input>
x &lt;- "09/01/02"
            </input>
          </program>

          <p>The <c>ymd</c> function assumes the first entry is the year, the second is the month, and the third is the day, so it converts it to:</p>

          <program language="r">
            <input>
ymd(x)
            </input>
          </program>

          <p>The <c>mdy</c> function assumes the first entry is the month, then the day, then the year:</p>

          <program language="r">
            <input>
mdy(x)
            </input>
          </program>

          <p>The <em>lubridate</em> package provides a function for every possibility. Here is the other common one:</p>

          <program language="r">
            <input>
dmy(x)
            </input>
          </program>

          <p>The __lubridate__ package is also useful for dealing with times. In base R, you can get the current time typing <c>Sys.time()</c>. The __lubridate__ package provides a slightly more advanced function, <c>now</c>, that permits you to define the time zone:</p>

          <program language="r">
            <input>
now()
now("GMT")
            </input>
          </program>

          <p>You can see all the available time zones with <c>OlsonNames()</c> function.</p>

          <p>We can also extract hours, minutes, and seconds:</p>

          <program language="r">
            <input>
now() |&gt; hour()
now() |&gt; minute()
now() |&gt; second()
            </input>
          </program>

          <p>The package also includes a function to parse strings into times as well as parsers for time objects that include dates:</p>

          <program language="r">
            <input>
x &lt;- c("12:34:56")
hms(x)
x &lt;- "Nov/2/2012 12:34:56"
mdy_hms(x)
            </input>
          </program>

          <p>This package has many other useful functions. We describe two of these here that we find particularly useful.</p>

          <p>The <c>make_date</c> function can be used to quickly create a date object. It can take up to seven arguments: year, month, day, hour, minute, seconds, and time zone defaulting to the epoch values on UTC time. To create an date object representing, for example, July 6, 2019 we write:</p>

          <program language="r">
            <input>
make_date(2019, 7, 6)
            </input>
          </program>

          <p>To make a vector of January 1 for the 80s we write:</p>

          <program language="r">
            <input>
make_date(1980:1989)
            </input>
          </program>

          <p>Another very useful function is <c>round_date</c>. It can be used to <em>round</em> dates to nearest year, quarter,  month, week, day, hour, minutes, or seconds. So if we want to group all the polls by week of the year we can do the following:</p>

          <program language="r">
            <input>
polls_us_election_2016 |&gt; 
  mutate(week = round_date(startdate, "week")) |&gt;
  group_by(week) |&gt;
  summarize(margin = mean(rawpoll_clinton - rawpoll_trump)) |&gt;
  ggplot(aes(week, margin)) +
  geom_point()
            </input>
          </program>

          <p>Finally, you should be aware the there are useful function for computing operations on time such a <c>difftime</c>, <c>time_length</c>, and <c>interval</c>.</p>

        </section>

        <section xml:id="sec-dates-and-times-with-data-table">
          <title>Dates and times with data.table</title>

          <p>The <alert>data.table</alert> package includes some of the same functionality as <alert>lubridate</alert>. For example, it includes the <c>month</c>, and <c>year</c> functions that are the same as those in <alert>lubridate</alert>. The equilvalent of <alert>lubridate</alert>'s <c>day</c> is <c>mday</c>:</p>

          <program language="r">
            <input>
library(data.table)
st &lt;- as.Date("2024-03-04")
day(st)
mday(st)
            </input>
          </program>

          <p>Other similar functions included in <alert>data.table</alert> are <c>second</c>, <c>minute</c>, <c>hour</c>, <c>yday</c>, <c>wday</c>, <c>week</c>, <c>isoweek</c> and <c>quarter</c>.</p>

          <p>The package also includes the classes <c>IDate</c> and <c>ITime</c>, which store dates and times more efficiently that <c>lubridate</c> and base R. This convenient for large files with date stamps. You can convert dates in the usual R format: using <c>as.IDate</c> and <c>as.ITime</c>. You can see this by using the <c>object.size</c> function:</p>

          <program language="r">
            <input>
object.size(polls_us_election_2016$startdate)
object.size(as.IDate(polls_us_election_2016$startdate))
            </input>
          </program>

        </section>

        <section xml:id="sec-parsing-dates-and-times-exercises">
          <title>Exercises</title>

          <p>For these exercises we will use the following dataset:</p>

          <program language="r">
            <input>
#| eval: false
library(dslabs)
head(pr_death_counts)
            </input>
          </program>

          <ol>
            <li><p>We want to make a plot of death counts versus date. Confirm that the <c>date</c> variable are in fact dates and not strings.</p></li>
            <li><p>Plot deaths versus date. </p></li>
            <li><p>What time period is represented in these data?</p></li>
            <li><p>Note that after May 31, 2018, the deaths are all 0. The data is probably not entered yet. We also see a drop off starting around May 1. Redefine <c>dat</c> to exclude observations taken on or after May 1, 2018. Then, remake the plot.</p></li>
            <li><p>Repeat the plot but use the day of the year on the x-axis instead of date.</p></li>
            <li><p>Compute the deaths per day by month.</p></li>
            <li><p>Show the deaths per days for July and for September. What do you notice?</p></li>
            <li><p>Compute deaths per week and make a plot.</p></li>
          </ol>

        </section>
        
      </chapter>

      <chapter xml:id="ch-locales">
        <title>Locales</title>
        
          <p>Computer settings change depending on language and location, and being unaware of this possibility can make certain data wrangling challenges difficult to overcome.</p>

          <p>The purpose of <em>locales</em> is to group together common settings that can affect:</p>

          <ol>
            <li><p>Month and day names, which are necessary for interpreting dates.</p></li>
            <li><p>The standard date format, also necessary for interpreting dates.</p></li>
            <li><p>The default time zone, essential for interpreting date-times.</p></li>
            <li><p>Character encoding, vital for reading non-ASCII characters. </p></li>
            <li><p>The symbols for decimals and number groupings, important for interpreting numerical values.</p></li>
          </ol>

          <p>In R, a <em>locale</em> refers to a suite of settings that dictate how the system should behave with respect to cultural conventions. These settings affect the way data is formatted and presented, encompassing details such as date formatting, currency symbols, decimal separators, and other related aspects.</p>

          <p>Locales in R affect several areas, including how character vectors are sorted, and date, number, and currency formatting. Additionally,  errors, warnings, and other messages might be translated into languages other than English based on the locale.</p>

        <section xml:id="sec-locales-in-r">
          <title>Locales in R</title>

          <p>To access the current locale settings in R, you can use the <c>Sys.getlocale()</c> function:</p>

          <program language="r">
            <input>
Sys.getlocale()
            </input>
          </program>

          <p>To set a specific locale, use the <c>Sys.setlocale()</c> function. For example, to set the locale to US English:</p>

          <program language="r">
            <input>
Sys.setlocale("LC_ALL", "en_US.UTF-8")
            </input>
          </program>

          <p>The exact string to use for setting the locale (like "en_US.UTF-8") can depend on your operating system and its configuration.</p>

          <p>The <c>LC_ALL</c> used in the above code refers to all locale categories. R, like many systems, breaks down the locale into categories, each responsible for different aspects listed below.</p>

          <p>- <c>LC_COLLATE</c>: for string collation - <c>LC_TIME</c>: date and time formatting - <c>LC_MONETARY</c>: currency formatting. - <c>LC_MESSAGES</c>: system message translations. - <c>LC_NUMERIC</c>: number formatting.</p>

          <p>You can set the locale for each category individually if you don't want to change everything with <c>LC_ALL</c>.</p>

          <p>We have shown tools to control locales. These settings are important because they affect how your data looks and behaves. However, not all of these settings are available on every computer; their availability depends on what kind of computer you have and how it's set up.</p>

          <p>Changing these settings, especially <c>LC_NUMERIC</c>, can lead to unexpected problems when you're working with numbers in R. For example, if you're used to using a period as a decimal point, but your locale uses a comma, this disparity can create issues when importing data.</p>

          <p>It is important to remember that these locale settings only last as long as one R session. If you change them while you're working, they will revert to the default settings when you close R and open it again.</p>

        </section>

        <section xml:id="sec-the-locale-function">
          <title>The `locale` function</title>

          <p>The <alert>readr</alert> package includes a <c>locale()</c> function that can be used to learn or change the current locale from within R:</p>

          <program language="r">
            <input>
library(readr)
locale()
            </input>
          </program>

          <program language="r">
            <input>
#| echo: false
options(readr.show_col_types = FALSE)
            </input>
          </program>

          <p>You can see all the locales available on your system by typing:</p>

          <program language="r">
            <input>
#| eval: false
system("locale -a")
            </input>
          </program>

          <p>Here is what you obtain if you change the dates locale to Spanish:</p>

          <program language="r">
            <input>
locale(date_names = "es")
            </input>
          </program>

        </section>

        <section xml:id="sec-example-wrangling-a-spanish-dataset">
          <title>Example: wrangling a Spanish dataset</title>

          <p>When reading the file:</p>

          <program language="r">
            <input>
fn &lt;- file.path(system.file("extdata", package = "dslabs"), "calificaciones.csv")
            </input>
          </program>

          <p>we note that it has an encoding different than UTF-8, the default. We can use <c>guess_encoding</c> to determine the correct one:</p>

          <program language="r">
            <input>
guess_encoding(fn)$encoding[1]
            </input>
          </program>

          <p>and used the <c>locale</c> function to change this and read in this encoding instead:</p>

          <program language="r">
            <input>
#| eval: false
dat &lt;- read_csv(fn, locale = locale(encoding = "ISO-8859-1"))
            </input>
          </program>

          <p>This file provides homework assignment scores for seven students. The columns represent the student name, their date of birth, the time they submitted their assignment, and the score they obtained, respectively. You can see the entire file using <c>read_lines</c>:</p>

          <program language="r">
            <input>
read_lines(fn, locale = locale(encoding = "ISO-8859-1"))
            </input>
          </program>

          <p>As an illustrative example, we will write code to compute the students age and check if they turned in their assignment by the deadline of September 21, 2023, before midnight.</p>

          <p>We can read in the file with correct encoding like this:</p>

          <program language="r">
            <input>
dat &lt;- read_csv(fn, locale = locale(encoding = "ISO-8859-1"))
            </input>
          </program>

          <p>However, notice that the last column, which is supposed to contain exam scores between 0 and 100, shows numbers larger than 800:</p>

          <program language="r">
            <input>
dat$puntuación
            </input>
          </program>

          <p>This happens because the scores in the file use the European decimal point, which confuses <c>read_csv</c>.</p>

          <p>To address this issue, we can also change the encoding to use European decimals, which fixes the problem:</p>

          <program language="r">
            <input>
dat &lt;- read_csv(fn, locale = locale(decimal_mark = ",",
                                    encoding = "ISO-8859-1"))
dat$puntuación
            </input>
          </program>

          <p>Now, to compute the student ages, let's try changing the submission times to date format:</p>

          <program language="r">
            <input>
library(lubridate)
dmy(dat$f.n.)
            </input>
          </program>

          <p>Nothing gets converted correctly. This is because the dates are in Spanish. We can change the locale to use Spanish as the language for dates:</p>

          <program language="r">
            <input>
parse_date(dat$f.n., format = "%d de %B de %Y", locale = locale(date_names = "es"))
            </input>
          </program>

          <p>We can also reread the file using the correct locales:</p>

          <program language="r">
            <input>
dat &lt;- read_csv(fn, locale = locale(date_names = "es",
                                    date_format = "%d de %B de %Y",
                                    decimal_mark = ",",
                                    encoding = "ISO-8859-1"))
            </input>
          </program>

          <p>Computing the students' ages is now straightforward:</p>

          <program language="r">
            <input>
time_length(today() - dat$f.n., unit = "years") |&gt; floor()
            </input>
          </program>

          <p>Finally, let's check which students turned in their homework past the deadline of September 22:</p>

          <program language="r">
            <input>
dat$estampa &gt;= make_date(2023, 9, 22)
            </input>
          </program>

          <p>We see that two students where late. However, with times we have to be particularly careful as some functions default to the UTC timezone:</p>

          <program language="r">
            <input>
tz(dat$estampa)
            </input>
          </program>

          <p>If we change to the timezone to Eastern Standard Time (EST), we see no one was late:</p>

          <program language="r">
            <input>
with_tz(dat$estampa, tz =  "EST") &gt;= make_date(2023, 9, 22)
            </input>
          </program>

        </section>

        <section xml:id="sec-locales-exercises">
          <title>Exercises</title>

          <ol>
            <li><p>Load the <alert>lubridate</alert> package and set the locale to French for this exercise. </p></li>
            <li><p>Create a numeric vector containing the following numbers: 12345.67, 9876.54, 3456.78, and 5432.10.</p></li>
            <li><p>Use the <c>format()</c> function to format the numeric vector as currency, displaying the values in Euros. Ensure that the decimal point is represented correctly according to the French locale. Print the formatted currency values.</p></li>
            <li><p>Create a date vector with three dates: July 14, 1789, January 1, 1803, and July 5, 1962. Use the <c>format()</c> function to format the date vector in the "dd Month yyyy" format, where "Month" should be displayed in the French language. Ensure that the month names are correctly translated according to the French locale. Print the formatted date values.</p></li>
            <li><p>Reset the locale to the default setting (e.g., "C" or "en_US.UTF-8") to revert to the standard formatting.</p></li>
            <li><p>Repeat steps 2-4 for the numeric vector, and steps 5-7 for the date vector to observe the standard formatting.</p></li>
          </ol>

        </section>
        
      </chapter>

      <chapter xml:id="ch-extracting-data-from-the-web">
        <title>Extracting data from the web</title>
        
          <p>In today's digital age, the internet serves as a treasure trove of data. This chapter describes approaches for retrieving this data and preparing for data analysis. We focus on two primary methodologies: scraping html and API integration. Scraping html allows us to programmatically navigate and extract data from web pages, transforming the unstructured content of the HTML pages into structured data ready for analysis. On the other hand, APIs provide a more direct and efficient and structured access to data provided by web services. This chapter aims to introduce the basics needed to starting leveraging the web's vast data resources.</p>

        <section xml:id="sec-scraping-html">
          <title>Scraping HTML</title>

          <p>The data we need to answer a question is not always in a spreadsheet ready for us to read. For example, the US murders dataset we used in the R Basics chapter originally comes from this Wikipedia page:</p>

          <program language="r">
            <input>
url &lt;- paste0("https://en.wikipedia.org/w/index.php?title=",
              "Gun_violence_in_the_United_States_by_state",
              "&amp;direction=prev&amp;oldid=810166167")
            </input>
          </program>

          <p>You can see the data table when you visit the webpage:</p>

          <figure>
            <image source="dataviz/img/murders-data-wiki-page.png"/>
          </figure>

          <p>(Web page courtesy of Wikipedia. CC-BY-SA-3.0 license. Screenshot of part of the page.)</p>

          <p><em>Web scraping</em>, or <em>web harvesting</em>, is the term we use to describe the process of extracting data from a website. The reason we can do this is because the information used by a browser to render webpages is received as a text file from a server. The text is code written in hyper text markup language (HTML). Every browser has a way to show the html source code for a page, each one different. On Chrome, you can use Control-U on a PC and command+alt+U on a Mac. You will see something like this:</p>

          <figure>
            <image source="dataviz/img/html-code.png"/>
          </figure>

          <subsection xml:id="subsec-html">
            <title>HTML</title>

            <p>Because this code is accessible, we can download the HTML file, import it into R, and then write programs to extract the information we need from the page. However, once we look at HTML code, this might seem like a daunting task. But we will show you some convenient tools to facilitate the process. To get an idea of how it works, here are a few lines of code from the Wikipedia page that provides the US murders data:</p>

            <program language="r">
              <input>
&lt;table class="wikitable sortable"&gt;
&lt;tr&gt;
&lt;th&gt;State&lt;/th&gt;
&lt;th&gt;&lt;a href="/wiki/List_of_U.S._states_and_territories_by_population" 
title="List of U.S. states and territories by population"&gt;Population&lt;/a&gt;&lt;br /&gt;
&lt;small&gt;(total inhabitants)&lt;/small&gt;&lt;br /&gt;
&lt;small&gt;(2015)&lt;/small&gt; &lt;sup id="cite_ref-1" class="reference"&gt;
&lt;a href="#cite_note-1"&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/th&gt;
&lt;th&gt;Murders and Nonnegligent
&lt;p&gt;Manslaughter&lt;br /&gt;
&lt;small&gt;(total deaths)&lt;/small&gt;&lt;br /&gt;
&lt;small&gt;(2015)&lt;/small&gt; &lt;sup id="cite_ref-2" class="reference"&gt;
&lt;a href="#cite_note-2"&gt;[2]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/th&gt;
&lt;th&gt;Murder and Nonnegligent
&lt;p&gt;Manslaughter Rate&lt;br /&gt;
&lt;small&gt;(per 100,000 inhabitants)&lt;/small&gt;&lt;br /&gt;
&lt;small&gt;(2015)&lt;/small&gt;&lt;/p&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="/wiki/Alabama" title="Alabama"&gt;Alabama&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;4,853,875&lt;/td&gt;
&lt;td&gt;348&lt;/td&gt;
&lt;td&gt;7.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="/wiki/Alaska" title="Alaska"&gt;Alaska&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;737,709&lt;/td&gt;
&lt;td&gt;59&lt;/td&gt;
&lt;td&gt;8.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
              </input>
            </program>

            <p>You can actually see the data, except data values are surrounded by html code such as <c>&lt;td&gt;</c>. We can also see a pattern of how it is stored. If you know HTML, you can write programs that leverage knowledge of these patterns to extract what we want. We also take advantage of a language widely used to make webpages look "pretty" called Cascading Style Sheets (CSS). We say more about this in <xref ref="sec-css-selectors"/>.</p>

            <p>Although we provide tools that make it possible to scrape data without knowing HTML, it is useful to learn some HTML and CSS. Not only does this improve your scraping skills, but it might come in handy if you are creating a webpage to showcase your work. There are plenty of online courses and tutorials for learning these. Two examples are Codeacademy and W3schools.</p>

          </subsection>

          <subsection xml:id="subsec-the-rvest-package">
            <title>The rvest package</title>

            <p>The __tidyverse__ provides a web harvesting package called __rvest__. The first step using this package is to import the webpage into R. The package makes this quite simple:</p>

            <program language="r">
              <input>
library(tidyverse)
library(rvest)
h &lt;- read_html(url)
              </input>
            </program>

            <p>Note that the entire Murders in the US Wikipedia webpage is now contained in <c>h</c>. The class of this object is:</p>

            <program language="r">
              <input>
class(h)
              </input>
            </program>

            <p>The __rvest__ package is actually more general; it handles XML documents. XML is a general markup language (that's what the ML stands for) that can be used to represent any kind of data. HTML is a specific type of XML specifically developed for representing webpages. Here we focus on HTML documents.</p>

            <p>Now, how do we extract the table from the object <c>h</c>? If you were to print <c>h</c>,  we would see information about the object that is not very informative. We can see all the code that defines the downloaded webpage using the <c>html_text</c> function like this:</p>

            <program language="r">
              <input>
html_text(h)
              </input>
            </program>

            <p>We don't show the output here because it includes thousands of characters. But if we look at it, we can see the data we are after are stored in an HTML table: you can see this in this line of the HTML code above <c>&lt;table class="wikitable sortable"&gt;</c>. The different parts of an HTML document, often defined with a message in between  <c>&lt;</c> and <c>&gt;</c>  are referred to as <em>nodes</em>. The __rvest__ package includes functions to extract nodes of an HTML document: <c>html_nodes</c> extracts all nodes of different types and <c>html_node</c> extracts the first one. To extract the tables from the html code we use:</p>

            <program language="r">
              <input>
tab &lt;- h |&gt; html_nodes("table")
              </input>
            </program>

            <p>Now, instead of the entire webpage, we just have the html code for the tables in the page:</p>

            <program language="r">
              <input>
tab
              </input>
            </program>

            <p>The table we are interested is the first one:</p>

            <program language="r">
              <input>
tab[[1]]
              </input>
            </program>

            <p>This is clearly not a tidy dataset, not even a data frame. In the code above, you can definitely see a pattern and writing code to extract just the data is very doable. In fact, __rvest__ includes a function just for converting HTML tables into data frames:</p>

            <program language="r">
              <input>
tab &lt;- tab[[1]] |&gt; html_table()
class(tab)
              </input>
            </program>

            <p>We are now much closer to having a usable data table:</p>

            <program language="r">
              <input>
tab &lt;- tab |&gt; setNames(c("state", "population", "total", "murder_rate")) 
head(tab)
              </input>
            </program>

            <p>We still have some wrangling to do. For example, we need to remove the commas and turn characters into numbers. Before continuing with this, we will learn a more general approach to extracting information from web sites.</p>

          </subsection>

          <subsection xml:id="sec-css-selectors">
            <title>CSS selectors</title>

            <p>The default look of a webpage made with the most basic HTML is quite unattractive. The aesthetically pleasing pages we see today are made using CSS to define the look and style of webpages. The fact that all pages for a company have the same style usually results from their use of the same CSS file to define the style. The general way these CSS files work is by defining how each of the elements of a webpage will look. The title, headings, itemized lists, tables, and links, for example, each receive their own style including font, color, size, and distance from the margin. CSS does this by leveraging patterns used to define these elements, referred to as <em>selectors</em>. An example of such a pattern, which we used above, is <c>table</c>, but there are many, many more.</p>

            <p>If we want to grab data from a webpage and we happen to know a selector that is unique to the part of the page containing this data, we can use the <c>html_nodes</c> function. However, knowing which selector can be quite complicated. In fact, the complexity of webpages has been increasing as they become more sophisticated. For some of the more advanced ones, it seems almost impossible to find the nodes that define a particular piece of data. However, selector gadgets actually make this possible.</p>

            <p>SelectorGadget is piece of software that allows you to interactively determine what CSS selector you need to extract specific components from the webpage. If you plan on scraping data other than tables from html pages, we highly recommend you install it. A Chrome extension is available which permits you to turn on the gadget and then, as you click through the page, it highlights parts and shows you the selector you need to extract these parts. There are various demos of how to do this including __rvest__ author Hadley Wickham's vignette and other tutorials based on the vignette.</p>

          </subsection>

        </section>

        <section xml:id="sec-json">
          <title>JSON</title>

          <p>Sharing data on the internet has become more and more common. Unfortunately, providers use different formats, which makes it harder for data analysts to wrangle data into R. Yet there are some standards that are also becoming more common. Currently, a format that is widely being adopted is the JavaScript Object Notation or JSON. Because this format is very general, it is nothing like a spreadsheet. This JSON file looks more like the code you use to define a list. Here is an example of information stored in a JSON format:</p>

          <program language="r">
            <input>
library(jsonlite)
example &lt;- data.frame(name = c("Miguel", "Sofia", "Aya", "Cheng"), 
                      student_id = 1:4, exam_1 = c(85, 94, 87, 90), exam_2 = c(86, 93, 88, 91))
json &lt;- toJSON(example, pretty = TRUE) 
json
            </input>
          </program>

          <p>The file above actually represents a data frame. To read it, we can use the function <c>fromJSON</c> from the __jsonlite__ package. Note that JSON files are often made available via the internet. Several organizations provide a JSON API or a web service that you can connect directly to and obtain data. Here is an example providing information Nobel prize winners:</p>

          <program language="r">
            <input>
library(jsonlite)
nobel &lt;- fromJSON("http://api.nobelprize.org/v1/prize.json")
            </input>
          </program>

          <p>This downloads a list. The first argument, named "prizes" is a table with information about Nobel prize winners. Each row holds corresponds to a particular year and category. The "laureates" column holds a list with a data frame for each winner with columns for id, firstname, surname, and motivation.</p>

          <program language="r">
            <input>
nobel$prizes |&gt;
  filter(category == "literature" &amp; year == "1971") |&gt; 
  pull(laureates) |&gt;
  first() |&gt;
  select(id, firstname, surname)
            </input>
          </program>

          <p>You can learn much more by examining tutorials and help files from the __jsonlite__ package. This package is intended for relatively simple tasks such as converting data into tables. For more flexibility, we recommend the __rjson__ package.</p>

        </section>

        <section xml:id="sec-data-apis">
          <title>Data APIs</title>

          <p>An Application Programming Interface (API) is a set of rules and protocols that allows different software entities to communicate with each other. It defines methods and data formats that software components should use when requesting and exchanging information. APIs play a crucial role in enabling the integration that make today's software so interconnected and versatile.</p>

          <subsection xml:id="subsec-api-types-and-concepts">
            <title>API types and concepts</title>

            <p>There are several types of APIs. The main ones related to retrieving data are:</p>

            <p>* <alert>Web Services</alert> - Often built using protocols like HTTP/HTTPS. Commonly used to enable applications to communicate with each other over the web. For instance, a weather application for a smartphone may use a web API to request weather data from a remote server.</p>

            <p>* <alert>Database APIs</alert> - Enable communication between an application and a database, SQL-based calls for example.</p>

            <p>Some key concepts associated with APIs:</p>

            <p>- <alert>Endpoints</alert>: Specific functions available through the API. For web APIs, an endpoint is usually a specific URL where the API can be accessed.</p>

            <p>- <alert>Methods</alert>: Actions that can be performed. In web APIs, these often correspond to HTTP methods like GET, POST, PUT, or DELETE.</p>

            <p>- <alert>Requests and Responses</alert>: The act of asking the API to perform its function is a <em>request</em>. The data it returns is the <em>response</em>.</p>

            <p>- <alert>Rate Limits</alert>: Restrictions on how often you can call the API, often used to prevent abuse or overloading of the service.</p>

            <p>- <alert>Authentication and Authorization</alert>: Mechanisms to ensure that only approved users or applications can use the API. Common methods include <em>API keys</em>, <em>OAuth</em>, or <em>Jason Web Tokens</em> (JWT).</p>

            <p>- <alert>Data Formats</alert>: Many web APIs exchange data in a specific format, often JSON or CSV.</p>

            <p>Here now describe the <alert>httr2</alert> package that facilitates interacionts between R and HTTP web services.</p>

          </subsection>

          <subsection xml:id="subsec-the-httr2-package">
            <title>The httr2 package</title>

            <p>HTTP is the most widely used protocol for data sharing through the internet. The <alert>httr2</alert> package provides functions to work with HTTP requests. One of the core functions in this package is <c>request</c>, which is used to form request to send to web services. The <c>req_perform</c> function sends the request.</p>

            <p>This <c>request</c> function forms an HTTP GET request to the specified URL. Typically, HTTP GET requests are used to retrieve information from a server based on the provided URL.</p>

            <p>The function returns an object of class <c>response</c>. This object contains all the details of the server's response, including status code, headers, and content. You can then use other <alert>httr2</alert> functions to extract or interpret information from this response.</p>

            <p>Let's say you want to retrieve COVID-19 deaths by state from the CDC. By visiting their data catalog you can search for datasets and find that the data is provided through this API:</p>

            <program language="r">
              <input>
url &lt;- "https://data.cdc.gov/resource/muzy-jte6.csv"
              </input>
            </program>

            <p>We can then make create and perform a request like this:</p>

            <program language="r">
              <input>
library(httr2)
response &lt;- request(url) |&gt; req_perform()
              </input>
            </program>

            <p>We can see the results of the request by looking at the returned object.</p>

            <program language="r">
              <input>
response
              </input>
            </program>

            <p>To extract the body, which is where the data are, we can use <c>resp_body_string</c> and send the result, a comma delimited string, to <c>read_csv</c></p>

            <program language="r">
              <input>
#| message: false
library(readr)
tab &lt;- response |&gt; resp_body_string() |&gt; read_csv()
              </input>
            </program>

            <p>We note that the returned object is only <c>nrow(tab)</c> entries. API often limit how much you can download. The documentation for this API explains that we can change this limit through the <c>$limit</c> parameters. We can use the <c>req_url_query</c> to add this to our request:</p>

            <program language="r">
              <input>
response &lt;- request(url) |&gt; 
  req_url_query(`$limit` = 100000) |&gt;
  req_perform() 
              </input>
            </program>

            <p>The CDC service returns data in csv format but a more common format used by web services is JSON. The CDC also provides data in json format through a the url:</p>

            <program language="r">
              <input>
url &lt;- "https://data.cdc.gov/resource/muzy-jte6.json"
              </input>
            </program>

            <p>To extract the data table we use the <c>fromJSON</c> function from the <alert>jsonlite</alert> package.</p>

            <program language="r">
              <input>
tab &lt;- request(url) |&gt; 
   req_perform() |&gt; 
   resp_body_string() |&gt; 
   fromJSON(flatten = TRUE)
              </input>
            </program>

            <p>When working with APIs, it's essential to check the API's documentation for rate limits, required headers, or authentication methods. The <c>httr2</c> package provides tools to handle these requirements, such as setting headers or authentication parameters.</p>

          </subsection>

        </section>

        <section xml:id="sec-extracting-data-from-web-exercises">
          <title>Exercises</title>

          <ol>
            <li><p>Visit the following web page: <url href="https://web.archive.org/web/20181024132313/http://www.stevetheump.com/Payrolls.htm">https://web.archive.org/web/20181024132313/http://www.stevetheump.com/Payrolls.htm</url></p></li>
          </ol>

          <p>Notice there are several tables. Say we are interested in comparing the payrolls of teams across the years. The next few exercises take us through the steps needed to do this.</p>

          <p>Start by applying what you learned to read in the website into an object called <c>h</c>.</p>

          <ol>
            <li><p>Note that, although not very useful, we can actually see the content of the page by typing:</p></li>
          <program language="r">
            <input>
html_text(h)
            </input>
          </program>

          </ol>

          <p>The next step is to extract the tables. For this, we can use the <c>html_nodes</c> function. We learned that tables in html are associated with the <c>table</c> node.  Use the <c>html_nodes</c> function to extract all tables. Store it in an object <c>nodes</c>.</p>

          <ol>
            <li><p>The <c>html_nodes</c> function returns a list of objects of class <c>xml_node</c>. We can see the content of each one using, for example, the <c>html_text</c> function. You can see the content for an arbitrarily picked component like this:</p></li>
          <program language="r">
            <input>
html_text(nodes[[8]])
            </input>
          </program>

          </ol>

          <p>If the content of this object is an html table, we can use the <c>html_table</c> function to convert it to a data frame. Use the <c>html_table</c> function to convert the 8th entry of <c>nodes</c> into a table.</p>

          <ol>
            <li><p>Repeat the above for the first 4 components of <c>nodes</c>. Which of the following are payroll tables:</p></li>
          </ol>

          <p>a. All of them. b. 1 c. 2 d. 2-4</p>

          <ol>
            <li><p>Repeat the above for the first __last__ 3 components of <c>nodes</c>. Which of the following is true:</p></li>
          </ol>

          <p>a. The last entry in <c>nodes</c> shows the average across all teams through time, not payroll per team. b. All three are payroll per team tables. c. All three are like the first entry, not a payroll table. d. All of the above.</p>

          <ol>
            <li><p>We have learned that the first and last entries of <c>nodes</c> are not payroll tables. Redefine <c>nodes</c> so that these two are removed.</p></li>
            <li><p>We saw in the previous analysis that the first table node is not actually a table. This happens sometimes in html because tables are used to make text look a certain way, as opposed to storing numeric values. </p></li>
          </ol>

          <p>Remove the first component and then use <c>sapply</c> and <c>html_table</c> to convert each node in <c>nodes</c> into a table. Note that in this case, <c>sapply</c> will return a list of tables. You can also use <c>lapply</c> to assure that a list is applied.</p>

          <ol>
            <li><p>Look through the resulting tables. Are they all the same? Could we just join them with <c>bind_rows</c>? </p></li>
            <li><p>Create two tables, call them <c>tab_1</c> and <c>tab_2</c> using the 10th and 19th tables in <c>nodes</c>.</p></li>
            <li><p>Use a <c>full_join</c> function to combine these two tables. Before you do this you will have to fix the missing header problem. You will also need to make the names match.</p></li>
            <li><p>After joining the tables, you see several <c>NA</c>s. This is because some teams are in one table and not the other. Use the <c>anti_join</c> function to get a better idea of why this is happening.</p></li>
            <li><p>We see see that one of the problems is that Yankees are listed as both <em>N.Y. Yankees</em> and <em>NY Yankees</em>. In the next section, we will learn efficient approaches to fixing problems like this. Here we can do it "by hand" as follows:</p></li>
          <program language="r">
            <input>
tab_1 &lt;- tab_1 |&gt;
  mutate(Team = ifelse(Team == "N.Y. Yankees", "NY Yankees", Team))
            </input>
          </program>

          </ol>

          <p>Now join the tables and show only Oakland and the Yankees and the payroll columns.</p>

          <ol>
            <li><p>Advanced: extract the titles of the movies that won Best Picture from IMDB.</p></li>
          </ol>

        </section>
        
      </chapter>

      <chapter xml:id="ch-string-processing">
        <title>String processing</title>
        
          <p>One of the most common data wrangling challenges involves extracting numeric data contained in character strings and converting them into the numeric representations required to make plots, compute summaries, or fit models in R. Also common is processing unorganized text into meaningful variable names or categorical variables. Many of the string processing challenges a data scientist faces are unique and often unexpected. It is therefore quite ambitious to write a comprehensive section on this topic. Here we use a series of case studies that help us demonstrate how string processing is a necessary step for many data wrangling challenges. Specifically, we describe the process of converting the original, <em>raw</em> data from which we extracted the <c>murders</c>, <c>heights</c>, and <c>research_funding_rates</c> examples into the data frames we have studied in this book.</p>

          <p>By going over these case studies, we will cover some of the most common tasks in string processing including extracting numbers from strings, removing unwanted characters from text, finding and replacing characters, extracting specific parts of strings, converting free form text to more uniform formats, and splitting strings into multiple values.</p>

          <p>Base R includes functions to perform many of these tasks. The <alert>stringi</alert> package adds significant functionality over what is available in base R, especially for complex and diverse text processing needs. The <alert>stringr</alert> package provides consistent, simple, and user friendly wrappers around the <alert>stringi</alert> package. For example, in <alert>stringr</alert>, all the string processing functions start with <c>str_</c>. This means that if you type <c>str_</c> and hit tab, R will auto-complete and show all the available functions. As a result, we don't necessarily have to memorize all the function names. Another advantage is that in the functions in this package the string being processed is always the first argument, which means we can more easily use the pipe. Therefore, we will start by describing how to use the functions in the <alert>stringr</alert> package.</p>

          <p>Most of the examples will come from the second case study which deals with self-reported heights by students, and most of the chapter is dedicated to learning regular expressions (regex) and functions in the <alert>stringr</alert> package.</p>

        <section xml:id="sec-stringr">
          <title>The stringr package</title>

          <program language="r">
            <input>
library(tidyverse)
library(stringr)
            </input>
          </program>

          <p>In general, string processing tasks can be divided into <alert>detecting</alert>, <alert>locating</alert>, <alert>extracting</alert>, or <alert>replacing</alert> patterns in strings. We will see several examples. The table below includes the functions available to you in the <alert>stringr</alert> package. We split them by task. We also include the base R equivalent when available.</p>

          <p>All these functions take a character vector as first argument. Also, for each function, operations are vectorized: the operation gets applied to each string in the vector.</p>

          <p>Finally, we mention <em>groups</em> in this table. These will be explained in <xref ref="sec-groups"/>.</p>

          <p>| stringr           | Task       | Description                                                                                      | Base R                         | |--------------|--------------|-------------------------------|--------------| | <c>str_detect</c>      | Detect     | Is the pattern in the string?                                                                    | <c>grepl</c>                        | | <c>str_which</c>       | Detect     | Returns the index of entries that contain the pattern.                                           | <c>grep</c>                         | | <c>str_subset</c>      | Detect     | Returns the subset of strings that contain the pattern.                                          | <c>grep</c> with <c>value = TRUE</c>     | | <c>str_locate</c>      | Locate     | Returns positions of first occurrence of the pattern in a string.                                    | <c>regexpr</c>                      | | <c>str_locate_all</c>  | Locate     | Returns position of all occurrences of the pattern in a string.                                      | <c>gregexpr</c>                     | | <c>str_view</c>        | Locate     | Show the first part of the string that matches the pattern.                                          |                                | | <c>str_view_all</c>    | Locate     | Show all the parts of the string that match the pattern.                                      |                                | | <c>str_extract</c>     | Extract    | Extract the first part of the string that matches the pattern.                                   |                                | | <c>str_extract_all</c> | Extract    | Extract all parts of the string that match the pattern.                                          |                                | | <c>str_match</c>       | Extract    | Extract first part of the string that matches the pattern and the groups defined by the pattern. |                                | | <c>str_match_all</c>   | Extract    | Extract all parts of the string that match the pattern and the groups defined by the pattern.  |                                | | <c>str_sub</c>         | Extract    | Extract a substring.                                                                             | <c>substring</c>                    | | <c>str_split</c>       | Extract    | Split a string into a list with parts separated by a pattern.                                      | <c>strsplit</c>                     | | <c>str_split_fixed</c> | Extract    | Split a string into a matrix with a fixed number of parts separated by a pattern.                                    | <c>strsplit</c> with <c>fixed = TRUE</c> | | <c>str_count</c>       | Describe   | Count number of times a pattern appears in a string.                                             |                                | | <c>str_length</c>      | Describe   | Number of character in string.                                                                   | <c>nchar</c>                        | | <c>str_replace</c>     | Replace    | Replace first part of a string matching a pattern with another.                                  |                                | | <c>str_replace_all</c> | Replace    | Replace all parts of a string matching a pattern with another.                                   | <c>gsub</c>                         | | <c>str_to_upper</c>    | Replace    | Change all characters to upper case.                                                             | <c>toupper</c>                      | | <c>str_to_lower</c>    | Replace    | Change all characters to lower case.                                                             | <c>tolower</c>                      | | <c>str_to_title</c>    | Replace    | Change first character of each word to upper and rest to lower case.                                               |                                | | <c>str_replace_na</c>  | Replace    | Replace all <c>NA</c>s with a new value.                                                                |                                | | <c>str_trim</c>        | Replace    | Remove white space from start and end of string.                                                 |                                | | <c>str_c</c>           | Manipulate | Join multiple strings.                                                                           | <c>paste0</c>                       | | <c>str_conv</c>        | Manipulate | Change the encoding of the string.                                                               |                                | | <c>str_sort</c>        | Manipulate | Sort the vector in alphabetical order.                                                           | <c>sort</c>                         | | <c>str_order</c>       | Manipulate | Provide index needed to order the vector in alphabetical order.                                          | <c>order</c>                        | | <c>str_trunc</c>       | Manipulate | Truncate a string to a fixed size.                                                               |                                | | <c>str_pad</c>         | Manipulate | Add white space to string to make it a fixed size.                                               |                                | | <c>str_dup</c>         | Manipulate | Repeat a string.                                                                                 | <c>rep</c> then <c>paste</c>             | | <c>str_wrap</c>        | Manipulate | Wrap things into formatted paragraphs.                                                           |                                | | <c>str_interp</c>      | Manipulate | String interpolation.                                                                            | <c>sprintf</c>                      |</p>

        </section>

        <section xml:id="sec-case-study-1-self-reported-heights">
          <title>Case study 1: self-reported heights</title>

          <p>The <alert>dslabs</alert> package includes the raw data from which the heights dataset was obtained. You can load it like this:</p>

          <program language="r">
            <input>
library(dslabs)
head(reported_heights)
            </input>
          </program>

          <p>These heights were obtained using a web form in which students were asked to enter their heights. They could enter anything, but the instructions asked for <em>height in inches</em>, a number. We compiled <c>prettyNum(nrow(reported_heights), big.mark=",")</c> submissions, but unfortunately the column vector with the reported heights had several non-numeric entries and as a result became a character vector:</p>

          <program language="r">
            <input>
class(reported_heights$height)
            </input>
          </program>

          <p>If we try to parse it into numbers, we get a warning:</p>

          <program language="r">
            <input>
x &lt;- as.numeric(reported_heights$height)
            </input>
          </program>

          <p>Although most values appear to be height in inches as requested we do end up with many <c>NA</c>s:</p>

          <program language="r">
            <input>
sum(is.na(x))
            </input>
          </program>

          <p>Here are some of the entries that are not successfully converted:</p>

          <program language="r">
            <input>
reported_heights |&gt; 
  mutate(new_height = as.numeric(height)) |&gt;
  filter(is.na(new_height)) |&gt; 
  head(n = 10)
            </input>
          </program>

          <p>We immediately see what is happening. Some of the students did not report their heights in inches as requested. We could discard these data and continue. However, many of the entries follow patterns that, in principle, we can easily convert to inches. For example, in the output above, we see various cases that use the format <c>x'y"</c> or <c>x'y''</c> with <c>x</c> and <c>y</c> representing feet and inches, respectively. Each one of these cases can be read and converted to inches by a human, for example <c>5'4"</c> is <c>5*12 + 4 = 64</c>. So we could fix all the problematic entries <em>by hand</em>. However, humans are prone to making mistakes, so an automated approach is preferable. Also, because we plan on continuing to collect data, it will be convenient to write code that automatically corrects entries entered in error.</p>

          <p>A first step in this type of task is to survey the problematic entries and try to define specific patterns followed by a large groups of entries. The larger these groups, the more entries we can fix with a single programmatic approach. We want to find patterns that can be accurately described with a rule, such as "a digit, followed by a feet symbol, followed by one or two digits, followed by an inches symbol".</p>

          <p>To look for such patterns, it helps to remove the entries that are consistent with being in inches and to view only the problematic entries. We thus write a function to automatically do this. We keep entries that either result in <c>NA</c>s when applying <c>as.numeric</c> or are outside a range of plausible heights. We permit a range that covers about 99.9999% of the adult population. We also use <c>suppressWarnings</c> to avoid the warning message we know <c>as.numeric</c> will gives us.</p>

          <program language="r">
            <input>
alpha &lt;- 1 / 10^6
qnorm(1 - alpha / 2, 69.1, 2.9)
qnorm(alpha / 2, 63.7, 2.7)
            </input>
          </program>

          <p>We apply this function and find the number of problematic entries:</p>

          <program language="r">
            <input>
problems &lt;- reported_heights |&gt; 
  mutate(inches = suppressWarnings(as.numeric(height))) |&gt;
  filter(is.na(inches) | inches &lt; 50 | inches &gt; 84) |&gt;
  pull(height)
length(problems)
            </input>
          </program>

          <p>We can now view all the cases by simply printing them. If we do, we see that three patterns can be used to define three large groups within these exceptions.</p>

          <ol>
            <li><p>A pattern of the form <c>x'y</c> or <c>x' y''</c> or <c>x'y"</c> with <c>x</c> and <c>y</c></p></li>
          </ol>

          <p>representing feet and inches, respectively. Here are ten examples:</p>

          <program language="r">
            <input>
pattern &lt;- "^\\d\\s*'\\s*\\d{1,2}\\.*\\d*'*\"*$"
str_subset(problems, pattern) |&gt; head(n = 10) |&gt; cat()
            </input>
          </program>

          <ol>
            <li><p>A pattern of the form <c>x.y</c> or <c>x,y</c> with <c>x</c> feet and <c>y</c> inches.</p></li>
          </ol>

          <p>Here are ten examples:</p>

          <program language="r">
            <input>
pattern &lt;- "^[4-6]\\s*[\\.|,]\\s*([0-9]|10|11)$"
str_subset(problems, pattern) |&gt; head(n = 10) |&gt; cat()
            </input>
          </program>

          <ol>
            <li><p>Entries that were reported in centimeters rather than inches. Here</p></li>
          </ol>

          <p>are ten examples:</p>

          <program language="r">
            <input>
ind &lt;- which(between(suppressWarnings(as.numeric(problems))/2.54, 54, 81) )
ind &lt;- ind[!is.na(ind)]
problems[ind] |&gt; head(n = 10) |&gt; cat()
            </input>
          </program>

          <p>Once we see these large groups following specific patterns, we can develop a plan of attack.</p>

          <ol>
            <li><p>Convert entries fitting the first two patterns into one standardized</p></li>
          </ol>

          <p>one.</p>

          <ol>
            <li><p>Leverage the standardization to extract the feet and inches and</p></li>
          </ol>

          <p>convert to inches.</p>

          <ol>
            <li><p>Define a procedure for identifying entries that are in centimeters</p></li>
          </ol>

          <p>and convert them to inches.</p>

          <ol>
            <li><p>Check again to see what entries were not fixed and see if we can</p></li>
          </ol>

          <p>tweak our approach to be more comprehensive.</p>

          <p>At the end, we hope to have a script that makes web-based data collection methods robust to the most common user mistakes.</p>

          <p>Remember that there is rarely just one way to perform these tasks. Here we pick one that helps us teach several useful techniques. But surely there is a more efficient way of performing the task.</p>

          <p>To achieve our goal, we will use a technique that enables us to accurately detect patterns and extract the parts we want: <em>regular expressions</em> (regex). But first, we quickly describe how to <em>escape</em> the function of certain characters so that they can be included in strings.</p>

        </section>

        <section xml:id="sec-escaping">
          <title>Escaping</title>

          <p>To define strings in R, we can use either double quotes or single quotes:</p>

          <program language="r">
            <input>
s &lt;- "Hello!"
s &lt;- 'Hello!' 
            </input>
          </program>

          <p>Make sure you choose the correct single quote, as opposed to the back quote `<c> </c> ``.</p>

          <p>Now, what happens if the string we want to define includes double quotes? For example, if we want to write 10 inches like this <c>10"</c>? In this case you can't use:</p>

          <program language="r">
            <input>
s &lt;- "10""
            </input>
          </program>

          <p>because this is just the string <c>10</c> followed by a double quote. If you type this into R, you get an error because you failed to close the double quote. To avoid this, we can use the single quotes:</p>

          <program language="r">
            <input>
s &lt;- '10"'
            </input>
          </program>

          <p>If we print out <c>s</c> we see that the double quotes are <em>escaped</em> with the backslash <c>\</c>.</p>

          <program language="r">
            <input>
s
            </input>
          </program>

          <p>In fact, escaping with the backslash provides a way to define the string while still using the double quotes to define strings:</p>

          <program language="r">
            <input>
s &lt;- "10\""
            </input>
          </program>

          <p>In R, the function <c>cat</c> lets us see what the string actually looks like:</p>

          <program language="r">
            <input>
cat(s)
            </input>
          </program>

          <p>Now, what if we want our string to be 5 feet written like this <c>5'</c>? In this case, we can use the double quotes or escape the single quote</p>

          <program language="r">
            <input>
s &lt;- "5'"
s &lt;- '5\''
            </input>
          </program>

          <p>So we've learned how to write 5 feet and 10 inches separately, but what if we want to write them together to represent <em>5 feet and 10 inches</em> like this <c>5'10"</c>? In this case, neither the single nor double quotes will work since <c>'5'10"'</c> closes the string after 5 and this <c>"5'10""</c> closes the string after 10. Keep in mind that if we type one of the above code snippets into R, it will get stuck waiting for you to close the open quote and you will have to exit the execution with the <em>esc</em> button.</p>

          <p>To achieve the desired result we need to escape both quotes with the backslash <c>\</c>. You can escape either character that can be confused with a closing quote. These are the two options:</p>

          <program language="r">
            <input>
s &lt;- '5\'10"'
s &lt;- "5'10\""
            </input>
          </program>

          <p>Escaping characters is something we often have to use when processing strings. Another characters that often needs escaping is the backslash character itself. We can do this with <c>\\</c>. When using regular expression, the topic of the next section, we often have to escape the <em>special characters</em> used in this approach.</p>

        </section>

        <section xml:id="sec-regex">
          <title>Regular expressions</title>

          <p>A regular expression (regex) is a way to describe specific patterns of characters of text. They can be used to determine if a given string matches the pattern. A set of rules has been defined to do this efficiently and precisely and here we show some examples. We can learn more about these rules by reading a detailed tutorials . The RStudio cheat sheet for __stringr__ and regular expression is also very useful.</p>

          <p>The patterns supplied to the <alert>stringr</alert> functions can be a regex rather than a standard string. We will learn how this works through a series of examples.</p>

          <p>Throughout this section you will see that we create strings to test out our regex. To do this, we define patterns that we know should match and also patterns that we know should not. We will call them <c>yes</c> and <c>no</c>, respectively. This permits us to check for the two types of errors: failing to match and incorrectly matching.</p>

          <subsection xml:id="subsec-strings-are-a-regex">
            <title>Strings are a regex</title>

            <p>Technically any string is a regex, perhaps the simplest example is a single character. So the comma <c>,</c> used in the next code example is a simple example of searching with regex.</p>

            <program language="r">
              <input>
pattern &lt;- ","
str_detect(c("1", "10", "100", "1,000", "10,000"), pattern) 
              </input>
            </program>

            <p>Above, we noted that an entry included a <c>cm</c>. This is also a simple example of a regex. We can show all the entries that used <c>cm</c> like this:</p>

            <program language="r">
              <input>
str_subset(reported_heights$height, "cm")
              </input>
            </program>

          </subsection>

          <subsection xml:id="subsec-special-characters">
            <title>Special characters</title>

            <p>Now let's consider a slightly more complicated example. Which of the following strings contain the pattern <c>cm</c> or <c>inches</c>?</p>

            <program language="r">
              <input>
yes &lt;- c("180 cm", "70 inches")
no &lt;- c("180", "70''")
s &lt;- c(yes, no)
              </input>
            </program>

            <p>We can do this with two searches:</p>

            <program language="r">
              <input>
str_detect(s, "cm") | str_detect(s, "inches")
              </input>
            </program>

            <p>However, we don't need to do this. The main feature that distinguishes the regex <em>language</em> from plain strings is that we can use special characters. These are characters with a meaning. We start by introducing <c>|</c> which means <em>or</em>. So if we want to know if either <c>cm</c> or <c>inches</c> appears in the strings, we can use the regex <c>cm|inches</c>:</p>

            <program language="r">
              <input>
str_detect(s, "cm|inches")
              </input>
            </program>

            <p>and obtain the correct answer.</p>

            <p>Another special character that will be useful for identifying feet and inches values is <c>\d</c> which means any digit: 0, 1, 2, 3, 4, 5, 6, 7, 8,</p>

            <ol>
              <li><p>The backslash is used to distinguish it from the character <c>d</c>. In R,</p></li>
            </ol>

            <p>we have to <em>escape</em> the backslash <c>\</c> so we actually have to use <c>\\d</c> to represent digits. Here is an example:</p>

            <program language="r">
              <input>
yes &lt;- c("5", "6", "5'10", "5 feet", "4'11")
no &lt;- c("", ".", "Five", "six")
s &lt;- c(yes, no)
pattern &lt;- "\\d"
str_detect(s, pattern)
              </input>
            </program>

            <p>We take this opportunity to introduce the <c>str_view</c> function, which is helpful for troubleshooting as it shows us all matches for each string that has matches. Each match is surrounded by the characters <c>&lt;</c> and <c>&gt;</c>. Below, we see that <c>5</c> has one match and <c>5'10</c> has three matches.</p>

            <program language="r">
              <input>
str_view(s, pattern)
              </input>
            </program>

            <figure>
              <image source="dataviz/img/str_view-1.png"/>
            </figure>

            <p>To view all strings, even if there wasn't a match, we can use the <c>match = NA</c> parameter.</p>

            <program language="r">
              <input>
str_view(s, pattern, match = NA)
              </input>
            </program>

            <figure>
              <image source="dataviz/img/str_view-2.png"/>
            </figure>

            <p>Another useful special character is <c>\w</c> which stands for <em>word character</em> and it matches any letter, number, or underscore.</p>

            <p>There are many other special characters. We will learn some others below, but you can see most or all of them in the cheat sheet mentioned earlier.</p>

          </subsection>

          <subsection xml:id="subsec-character-classes">
            <title>Character classes</title>

            <p>Character classes are used to define a series of characters that can be matched. We define character classes with square brackets <c>[]</c>. So, for example, if we want the pattern to match only if we have a <c>5</c> or a <c>6</c>, we use the regex <c>[56]</c>:</p>

            <program language="r">
              <input>
str_view(s, "[56]", match = NA)
              </input>
            </program>

            <figure>
              <image source="dataviz/img/str_view-3.png"/>
            </figure>

            <p>Suppose we want to match values between 4 and 7. A common way to define character classes is with ranges. So, for example, <c>[0-9]</c> is equivalent to <c>\\d</c>. The pattern we want is therefore <c>[4-7]</c>.</p>

            <program language="r">
              <input>
yes &lt;- as.character(4:7)
no &lt;- as.character(1:3)
s &lt;- c(yes, no)
str_detect(s, "[4-7]")
              </input>
            </program>

            <p>However, it is important to know that in regex everything is a character; there are no numbers. So <c>4</c> is the character <c>4</c> not the number four. Notice, for example, that <c>[1-20]</c> does <alert>not</alert> mean 1 through 20, it means the characters 1 through 2 or the character 0. So <c>[1-20]</c> simply means the character class composed of 0, 1, and 2.</p>

            <p>Keep in mind that characters do have an order and the digits do follow the numeric order. So <c>0</c> comes before <c>1</c> which comes before <c>2</c> and so on. For the same reason, we can define lower case letters as <c>[a-z]</c>, upper case letters as <c>[A-Z]</c>, and <c>[a-zA-z]</c> as both.</p>

            <p>Notice that <c>\w</c> is equivalent to <c>[a-zA-Z0-9_]</c>.</p>

          </subsection>

          <subsection xml:id="subsec-anchors">
            <title>Anchors</title>

            <p>What if we want a match when we have exactly 1 digit? This will be useful in our case study since feet are never more than 1 digit so a restriction will help us. One way to do this with regex is by using <em>anchors</em>, which let us define patterns that must start or end at a specific place. The two most common anchors are <c>^</c> and <c>$</c> which represent the beginning and end of a string, respectively. So the pattern <c>^\\d$</c> is read as "start of the string followed by one digit followed by end of string".</p>

            <p>This pattern now only detects the strings with exactly one digit:</p>

            <program language="r">
              <input>
pattern &lt;- "^\\d$"
yes &lt;- c("1", "5", "9")
no &lt;- c("12", "123", " 1", "a4", "b")
s &lt;- c(yes, no)
str_view(s, pattern, match = NA)
              </input>
            </program>

            <figure>
              <image source="dataviz/img/str_view-4.png"/>
            </figure>

            <p>The <c> 1</c> does not match because it does not start with the digit but rather with a space, which is not easy to see.</p>

          </subsection>

          <subsection xml:id="subsec-bounded-quantifiers">
            <title>Bounded quantifiers</title>

            <p>For the inches part, we can have one or two digits. This can be specified in regex with <em>quantifiers</em>. This is done by following the pattern with curly brackets containing the number of times the previous entry can be repeated. We call the <em>bounded</em> because the numbers in the quantifier are limited by the numbers in the curly brackets. Later we learn about <em>unbounded quantifiers</em>.</p>

            <p>We use an example to illustrate. The pattern for one or two digits is:</p>

            <program language="r">
              <input>
pattern &lt;- "^\\d{1,2}$"
yes &lt;- c("1", "5", "9", "12")
no &lt;- c("123", "a4", "b")
str_view(c(yes, no), pattern, match = NA)
              </input>
            </program>

            <figure>
              <image source="dataviz/img/str_view-5.png"/>
            </figure>

            <p>In this case, <c>123</c> does <alert>not</alert> match, but <c>12</c> does. To look for our feet and inches pattern, we can add the symbols for feet <c>'</c> and inches <c>"</c> after the digits.</p>

            <p>With what we have learned, we can now construct an example for the pattern <c>x'y"</c> with <c>x</c> feet and <c>y</c> inches.</p>

            <program language="r">
              <input>
pattern &lt;- "^[4-7]'\\d{1,2}\"$"
              </input>
            </program>

            <p>The pattern is now getting complex, but you can look at it carefully and break it down:</p>

            <p>-   <c>^</c> = start of the string -   <c>[4-7]</c> = one digit, either 4,5,6 or 7 -   <c>'</c> = feet symbol -   <c>\\d{1,2}</c> = one or two digits -   <c>\"</c> = inches symbol -   <c>$</c> = end of the string</p>

            <p>Let's test it out:</p>

            <program language="r">
              <input>
yes &lt;- c("5'7\"", "6'2\"",  "5'12\"")
no &lt;- c("6,2\"", "6.2\"","I am 5'11\"", "3'2\"", "64")
str_detect(yes, pattern)
str_detect(no, pattern)
              </input>
            </program>

            <p>For now, we are permitting the inches to be 12 or larger. We will add a restriction later as the regex for this is a bit more complex than we are ready to show.</p>

          </subsection>

          <subsection xml:id="subsec-white-space">
            <title>White space</title>

            <p>Another problem we have is spaces. For example, our pattern does not match <c>5' 4"</c> because there is a space between <c>'</c> and <c>4</c> which our pattern does not permit. Spaces are characters and R does not ignore them:</p>

            <program language="r">
              <input>
identical("Hi", "Hi ")
              </input>
            </program>

            <p>In regex, <c>\s</c> represents white space. To find patterns like <c>5' 4</c>, we can change our pattern to:</p>

            <program language="r">
              <input>
pattern_2 &lt;- "^[4-7]'\\s\\d{1,2}\"$"
str_subset(problems, pattern_2)
              </input>
            </program>

            <p>However, this will not match the patterns with no space. So do we need more than one regex pattern? It turns out we can use a quantifier for this as well.</p>

          </subsection>

          <subsection xml:id="subsec-unbounded-quantifiers">
            <title>Unbounded quantifiers: `*`, `?`, `+`</title>

            <p>We want the pattern to permit spaces but not require them. Even if there are several spaces, like in this example <c>5'   4</c>, we still want it to match. There is a quantifier for exactly this purpose. In regex, the character <c>*</c> means zero or more instances of the previous character. Here is an example:</p>

            <program language="r">
              <input>
yes &lt;- c("AB", "A1B", "A11B", "A111B", "A1111B")
no &lt;- c("A2B", "A21B")
str_detect(yes, "A1*B")
str_detect(no, "A1*B")
              </input>
            </program>

            <p>The above matches the first string which has zero 1s and all the strings with one or more 1s. We can then improve our pattern by adding the <c>*</c> after the space character <c>\s</c>.</p>

            <p>There are two other similar quantifiers. For none or once, we can use <c>?</c>, and for one or more, we can use <c>+</c>. You can see how they differ with this example:</p>

            <program language="r">
              <input>
data.frame(string = c("AB", "A1B", "A11B", "A111B", "A1111B"),
           none_or_more = str_detect(yes, "A1*B"),
           nore_or_once = str_detect(yes, "A1?B"),
           once_or_more = str_detect(yes, "A1+B"))
              </input>
            </program>

            <p>We will actually use all three in our reported heights example, but we will see these in a later section.</p>

          </subsection>

          <subsection xml:id="subsec-not">
            <title>Not</title>

            <p>To specify patterns that we do <alert>not</alert> want to detect, we can use the <c>^</c> symbol but only <alert>inside</alert> square brackets. Remember that outside the square bracket <c>^</c> means the start of the string. So, for example, if we want to detect digits that are preceded by anything except a letter we can do the following:</p>

            <program language="r">
              <input>
pattern &lt;- "[^a-zA-Z]\\d"
yes &lt;- c(".3", "+2", "-0","*4")
no &lt;- c("A3", "B2", "C0", "E4")
str_detect(yes, pattern)
str_detect(no, pattern)
              </input>
            </program>

            <p>Another way to generate a pattern that searches for <em>everything except</em> is to use the upper case of the special character. For example <c>\\D</c> means anything other than a digit, <c>\\S</c> means anything except a space, and so on.</p>

          </subsection>

          <subsection xml:id="sec-groups">
            <title>Groups</title>

            <p><em>Groups</em> are a powerful aspect of regex that permits the extraction of values. Groups are defined using parentheses. They don't affect the pattern matching per se. Instead, it permits tools to identify specific parts of the pattern so we can extract them.</p>

            <p>We want to change heights written like <c>5.6</c> to <c>5'6</c>.</p>

            <p>To avoid changing patterns such as <c>70.2</c>, we will require that the first digit be between 4 and 7 <c>[4-7]</c> and that the second be none or more digits <c>\\d*</c>. Let's start by defining a simple pattern that matches this:</p>

            <program language="r">
              <input>
pattern_without_groups &lt;- "^[4-7],\\d*$"
              </input>
            </program>

            <p>We want to extract the digits so we can then form the new version using a period. These are our two groups, so we encapsulate them with parentheses:</p>

            <program language="r">
              <input>
pattern_with_groups &lt;-  "^([4-7]),(\\d*)$"
              </input>
            </program>

            <p>We encapsulate the part of the pattern that matches the parts we want to keep for later use. Adding groups does not affect the detection, since it only signals that we want to save what is captured by the groups. Note that both patterns return the same result when using <c>str_detect</c>:</p>

            <program language="r">
              <input>
yes &lt;- c("5,9", "5,11", "6,", "6,1")
no &lt;- c("5'9", ",", "2,8", "6.1.1")
s &lt;- c(yes, no)
str_detect(s, pattern_without_groups)
str_detect(s, pattern_with_groups)
              </input>
            </program>

            <p>Once we define groups, we can use the function <c>str_match</c> to extract the values these groups define:</p>

            <program language="r">
              <input>
str_match(s, pattern_with_groups)
              </input>
            </program>

            <p>Notice that the second and third columns contain feet and inches, respectively. The first column is the part of the string matching the pattern. If no match occurred, we see an <c>NA</c>.</p>

            <p>Now we can understand the difference between the functions <c>str_extract</c> and <c>str_match</c>. <c>str_extract</c> extracts only strings that match a pattern, not the values defined by groups:</p>

            <program language="r">
              <input>
str_extract(s, pattern_with_groups)
              </input>
            </program>

          </subsection>

          <subsection xml:id="subsec-search-and-replace">
            <title>Search and replace</title>

            <p>Earlier we defined the object <c>problems</c> containing the strings that do not appear to be in inches. We can see that not too many of our problematic strings match the pattern:</p>

            <program language="r">
              <input>
pattern &lt;- "^[4-7]'\\d{1,2}\"$"
sum(str_detect(problems, pattern))
              </input>
            </program>

            <p>To see why this is, we show some examples that expose why we don't have more matches:</p>

            <program language="r">
              <input>
problems[c(2, 10, 11, 12, 15)] |&gt; str_view(pattern)
              </input>
            </program>

            <figure>
              <image source="dataviz/img/str_view-6.png"/>
            </figure>

            <p>An initial problem we see immediately is that some students wrote out the words "feet" and "inches". We can see the entries that did this with the <c>str_subset</c> function:</p>

            <program language="r">
              <input>
str_subset(problems, "inches")
              </input>
            </program>

            <p>We also see that some entries used two single quotes <c>''</c> instead of a double quote <c>"</c>.</p>

            <program language="r">
              <input>
str_subset(problems, "''")
              </input>
            </program>

            <p>To correct this, we can replace the different ways of representing inches and feet with a uniform symbol. We will use <c>'</c> for feet, whereas for inches we will simply not use a symbol since some entries were of the form <c>x'y</c>. Now, if we no longer use the inches symbol, we have to change our pattern accordingly:</p>

            <program language="r">
              <input>
pattern &lt;- "^[4-7]'\\d{1,2}$"
              </input>
            </program>

            <p>If we do this replacement before the matching, we get many more matches:</p>

            <program language="r">
              <input>
problems |&gt; 
  str_replace("feet|ft|foot", "'") |&gt; # replace feet, ft, foot with ' 
  str_replace("inches|in|''|\"", "") |&gt; # remove all inches symbols
  str_detect(pattern) |&gt; 
  sum()
              </input>
            </program>

            <p>However, we still have many cases to go.</p>

            <p>Note that in the code above, we leveraged the <alert>stringr</alert> consistency and used the pipe.</p>

            <p>For now, we improve our pattern by adding <c>\\s*</c> in front of and after the feet symbol <c>'</c> to permit space between the feet symbol and the numbers. Now we match a few more entries:</p>

            <program language="r">
              <input>
pattern &lt;- "^[4-7]\\s*'\\s*\\d{1,2}$"
problems |&gt; 
  str_replace("feet|ft|foot", "'") |&gt; # replace feet, ft, foot with ' 
  str_replace("inches|in|''|\"", "") |&gt; # remove all inches symbols
  str_detect(pattern) |&gt; 
  sum()
              </input>
            </program>

            <p>We might be tempted to avoid doing this by removing all the spaces with <c>str_replace_all</c>. However, when doing such an operation we need to make sure that it does not have unintended effects. In our reported heights examples, this will be a problem because some entries are of the form <c>x y</c> with space separating the feet from the inches. If we remove all spaces, we will incorrectly turn <c>x y</c> into <c>xy</c> which implies that a <c>6 1</c> would become <c>61</c> inches instead of <c>73</c> inches.</p>

            <p>The second large type of problematic entries were of the form <c>x.y</c>, <c>x,y</c> and <c>x y</c>. We want to change all these to our common format <c>x'y</c>. But we can't just do a search and replace because we would change values such as <c>70.5</c> into <c>70'5</c>. Our strategy will therefore be to search for a very specific pattern that assures us feet and inches are being provided and then, for those that match, replace appropriately.</p>

          </subsection>

          <subsection xml:id="subsec-search-and-replace-using-groups">
            <title>Search and replace using groups</title>

            <p>Another powerful aspect of groups is that you can refer to the extracted values in a regex when searching and replacing.</p>

            <p>The regex special character for the <c>i</c>-th group is <c>\\i</c>. So <c>\\1</c> is the value extracted from the first group, <c>\\2</c> the value from the second and so on. As a simple example, note that the following code will replace a comma with period, but only if it is after a digit between 4 and 7, and followed by zero or more digits:</p>

            <program language="r">
              <input>
pattern_with_groups &lt;-  "^([4-7]),(\\d*)$"
yes &lt;- c("5,9", "5,11", "6,", "6,1")
no &lt;- c("5'9", ",", "2,8", "6.1.1")
s &lt;- c(yes, no)
str_replace(s, pattern_with_groups, "\\1'\\2")
              </input>
            </program>

            <p>We can use this to convert cases in our reported heights.</p>

            <p>We are now ready to define a pattern that helps us convert all the <c>x.y</c>, <c>x,y</c> and <c>x y</c> to our preferred format. We need to adapt <c>pattern_with_groups</c> to be a bit more flexible and capture all the cases.</p>

            <program language="r">
              <input>
pattern_with_groups &lt;- "^([4-7])\\s*[,\\.\\s+]\\s*(\\d*)$"
              </input>
            </program>

            <p>Let's break this one down:</p>

            <p>-   <c>^</c> = start of the string -   <c>[4-7]</c> = one digit representing feet, either 4, 5, 6, or 7 -   <c>\\s*</c> = none or more white space -   <c>[,\\.\\s+]</c> = feet and inches are separated by either <c>,</c>, <c>.</c> or at least one space -   <c>\\s*</c> = none or more white space -   <c>\\d*</c> = none or more digits representing inches -   <c>$</c> = end of the string</p>

            <p>We can see that it appears to be working:</p>

            <program language="r">
              <input>
str_subset(problems, pattern_with_groups) |&gt; head()
              </input>
            </program>

            <p>and will be able to perform the search and replace:</p>

            <program language="r">
              <input>
str_subset(problems, pattern_with_groups) |&gt; 
  str_replace(pattern_with_groups, "\\1'\\2") |&gt; head()
              </input>
            </program>

            <p>Again, we will deal with the inches-larger-than-twelve challenge later.</p>

          </subsection>

          <subsection xml:id="subsec-lookarounds">
            <title>Lookarounds</title>

            <p>Lookarounds provide a way to ask for one or more conditions to be satisfied without moving the search forward or matching it. For example, you might want to check for multiple conditions and if they are matched, then return the pattern or part of the pattern that matched.</p>

            <p>There are four types of lookarounds: lookahead <c>(?=pattern)</c>, lookbehind <c>(?&lt;=pattern)</c>, negative lookahead <c>(?!pattern)</c>, and negative lookbehind <c>(?&lt;!pattern)</c>.</p>

            <p>The conventional example checking password that must satisfy several conditions such as 1) 8-16 word characters, 2) starts with a letter, and 3) has at least one digit. You can concatenate lookarounds to check for multiple conditions. For our example we can write</p>

            <program language="r">
              <input>
pattern &lt;- "(?=\\w{8,16})(?=^[a-z|A-Z].*)(?=.*\\d+.*)"
              </input>
            </program>

            <p>A simpler example is changing all <c>superman</c> to <c>supergirl</c> without changing all the men to girl. We could use a lookaround like this:</p>

            <program language="r">
              <input>
s &lt;- "Superman saved a man. The man thanked superman."
str_replace_all(s, "(?&lt;=[Ss]uper)man", "girl")
              </input>
            </program>

          </subsection>

          <subsection xml:id="sec-separate_regex">
            <title>Separating variables</title>

            <p>In <xref ref="sec-separate"/> we introduced functions that can split columns into new ones. The <c>separate_wider_regex</c> uses regex instead of delimiters to separate variables in data frames. It uses an approach similar to regex groups and turns each of groups into a new column.</p>

            <p>Suppose we have data frame like this:</p>

            <program language="r">
              <input>
tab &lt;- data.frame(x = c("5'10", "6' 1", "5 ' 9", "5'11\""))
              </input>
            </program>

            <p>Note that using <c>separate_wider_delim</c> won't work here because the delimiter can varies across entries. With <c>separate_wider_regex</c> we can define flexible patterns that are matched to define each column.</p>

            <program language="r">
              <input>
patterns &lt;- c(feet = "\\d", "\\s*'\\s*", inches = "\\d{1,2}", ".*")
tab |&gt; separate_wider_regex(x, patterns = patterns)
              </input>
            </program>

            <p>By not naming the second and fourth entries of <c>patterns</c> we tell the function not to keep the values that match that pattern.</p>

          </subsection>

        </section>

        <section xml:id="sec-trimming">
          <title>Trimming</title>

          <p>In general, spaces at the start or end of the string are uninformative. These can be particularly deceptive because sometimes they can be hard to see:</p>

          <program language="r">
            <input>
s &lt;- "Hi "
cat(s)
identical(s, "Hi")
            </input>
          </program>

          <p>This is a general enough problem that there is a function dedicated to removing them: <c>str_trim</c>.</p>

          <program language="r">
            <input>
str_trim("5 ' 9 ")
            </input>
          </program>

        </section>

        <section xml:id="sec-case-conversion">
          <title>Case conversion</title>

          <p>Notice that regex is case sensitive. Often we want to match a word regardless of case. One approach to doing this is to first change everything to lower case and then proceeding ignoring case. As an example, note that one of the entries writes out numbers as words <c>Five foot eight inches</c>. Although not efficient, we could add 13 extra <c>str_replace</c> calls to convert <c>zero</c> to <c>0</c>, <c>one</c> to <c>1</c>, and so on. To avoid having to write two separate operations for <c>Zero</c> and <c>zero</c>, <c>One</c> and <c>one</c>, etc., we can use the <c>str_to_lower</c> function to make all works lower case first:</p>

          <program language="r">
            <input>
s &lt;- c("Five feet eight inches")
str_to_lower(s)
            </input>
          </program>

          <p>Other related functions are <c>str_to_upper</c> and <c>str_to_title</c>. We are now ready to define a procedure that converts all the problematic cases to inches.</p>

        </section>

        <section xml:id="sec-case-study-1-continued-putting-it-all-together">
          <title>Case study 1 continued: Putting it all together</title>

          <p>We are now ready to put it all together and wrangle our reported heights data to try to recover as many heights as possible. The code is complex, but we will break it down into parts.</p>

          <p>Let's see how many problematic entries we can recover with the approaches we covered in <xref ref="sec-regex"/>. We will first define a function that detects entries that are not reported as inches or centimeters:</p>

          <program language="r">
            <input>
not_inches_or_cm &lt;- function(x, smallest = 50, tallest = 84){
  inches &lt;- suppressWarnings(as.numeric(x))
  is.na(inches) |
    !((inches &gt;= smallest &amp; inches &lt;= tallest) |
        (inches/2.54 &gt;= smallest &amp; inches/2.54 &lt;= tallest))
}
            </input>
          </program>

          <p>We can see how many entries are not inches or centimeters:</p>

          <program language="r">
            <input>
problems &lt;- reported_heights |&gt; 
  filter(not_inches_or_cm(height)) |&gt;
  pull(height)
length(problems)
            </input>
          </program>

          <p>Let's see how many feet<c>'</c>inches format we can recover applying the finding from <xref ref="sec-regex"/>. Specifically we replace feet/foot/ft with <c>'</c>, we remove the word inches and its abbreviations, then rewrite similar patterns into the desired feet<c>'</c>inches pattern. Once this is done we see what proportion don't fit the desired pattern</p>

          <program language="r">
            <input>
converted &lt;- problems |&gt; 
  str_replace("feet|foot|ft", "'") |&gt; 
  str_remove_all("inches|in|''|\"") |&gt;  
  str_replace("^([4-7])\\s*[,\\.\\s+]\\s*(\\d*)$", "\\1'\\2") 
index &lt;- str_detect(converted, "^[4-7]\\s*'\\s*\\d{1,2}$")
mean(!index)
            </input>
          </program>

          <p>We see that a substantial proportion has not yet been fixed. Trial and error is a common approach to finding the regex pattern that satisfies all desired conditions. We can examine the remaining cases to try to decipher if new patterns we can use to fix them:</p>

          <program language="r">
            <input>
converted[!index]
            </input>
          </program>

          <p>We noticed that two students added <c>cm</c> and some entries have space at the end so we write incorporate this into our cleanup stage. We also notice that at least one entry wrote out numbers such as <c>Five foot eight inches</c>. We can use  the <c>words()</c> function in the <alert>english</alert> package to change these to actual numbers. In preparation for our final product, we define a function that cleans up previously noticed problems and these new ones:</p>

          <program language="r">
            <input>
library(english)
cleanup &lt;- function(s){
  s &lt;- str_remove_all(s, "inches|in|''|\"|cm|and") |&gt; 
    str_trim() |&gt;
    str_to_lower()
  for (i in 0:11) {
    s &lt;- str_replace_all(s, words(i), as.character(i))
  }
  return(s)
}
            </input>
          </program>

          <p>Many also notice that students measuring exactly 5 or 6 feet did not enter any inches, for example <c>6'</c>, and our pattern requires that inches be included, and that some entries are in meters and some of these use European decimals, for example <c>1.6</c> and <c>1,70</c>. So we create a function that add these corrections to those already identified as needed to reformat the entry as feet<c>'</c>inches:</p>

          <program language="r">
            <input>
convert_format &lt;- function(s){
  s |&gt; str_replace("feet|foot|ft", "'") |&gt; 
    str_replace("^([4-7])\\s*[,\\.\\s+]\\s*(\\d*)$", "\\1'\\2") |&gt; 
    str_replace("^([56])'?$", "\\1'0") |&gt; 
    str_replace("^([12])\\s*,\\s*(\\d*)$", "\\1\\.\\2")
}
            </input>
          </program>

          <p>Now we are ready to wrangle our reported heights dataset. The strategy is as follows:</p>

          <ol>
            <li><p>We start by defining a variable to keep a copy of the original entry, we then clean up and covert the <c>height</c> entry using the functions described above. </p></li>
            <li><p>We then use the <c>separate_wider_regex_</c> function to extract feet and inches when the entry matches our feet<c>'</c>inches format. </p></li>
            <li><p>We use a lookaround to make sure that entries that have numbers with no <c>'</c> following them don't match and return an <c>NA</c>. </p></li>
          <program language="r">
            <input>
patterns &lt;- c(feet = "[4-7](?=\\s*'\\s*)", 
              "\\s*'\\s*", 
              inches = "\\d+\\.?\\d*")
smallest &lt;- 50
tallest &lt;- 84
new_heights &lt;- reported_heights |&gt; 
  mutate(original = height, 
         height = convert_format(cleanup(height))) |&gt;
  separate_wider_regex(height, patterns = patterns, 
                       too_few = "align_start", 
                       cols_remove = FALSE) |&gt; 
  mutate(across(c(height, feet, inches), as.numeric)) |&gt;
  mutate(guess = 12 * feet + inches) |&gt;
  mutate(height = case_when(
    is.na(height) ~ as.numeric(NA),
    between(height, smallest, tallest) ~ height,  #inches
    between(height/2.54, smallest, tallest) ~ height/2.54, #cm
    between(height*100/2.54, smallest, tallest) ~ height*100/2.54, #meters
    TRUE ~ as.numeric(NA))) |&gt;
  mutate(height = ifelse(is.na(height) &amp; 
                           inches &lt;= 12 &amp; between(guess, smallest, tallest),
                         guess, height)) |&gt;
  select(-feet, -inches, -guess)
            </input>
          </program>

          </ol>

          <p>We see that we fix all but <c>sum(is.na(new_heights$height))</c> entries. You can see that these are mostly un-fixable:</p>

          <program language="r">
            <input>
new_heights |&gt; filter(is.na(height)) |&gt; pull(original)
            </input>
          </program>

          <p>You can review the ones we did fix by typing:</p>

          <program language="r">
            <input>
#| eval: false
new_heights |&gt;
  filter(not_inches_or_cm(original)) |&gt;
  select(original, height) |&gt; 
  arrange(height) |&gt;
  View()
            </input>
          </program>

          <p>A final observation is that if we look at the shortest students in our course:</p>

          <program language="r">
            <input>
new_heights |&gt; arrange(height) |&gt; head(n = 6)
            </input>
          </program>

          <p>We see heights of 50, 51, 52, and so on. These short heights are rare and it is likely that the students actually meant 5'0,  5'1, 5'2 and so on. Because we are not completely sure, we will leave them as reported. The object new_heights contains our final solution for this case study.</p>

        </section>

        <section xml:id="sec-case-study-2-extracting-tables-from-a-pdf">
          <title>Case study 2: extracting tables from a PDF</title>

          <p>One of the datasets provided in <alert>dslabs</alert> shows scientific funding rates by gender in the Netherlands:</p>

          <program language="r">
            <input>
library(dslabs)
research_funding_rates |&gt; 
  select("discipline", "success_rates_men", "success_rates_women")
            </input>
          </program>

          <p>The data comes from a paper published in the Proceedings of the National Academy of Science (PNAS), a widely read scientific journal. However, the data is not provided in a spreadsheet; it is in a table in a PDF document. Here is a screenshot of the table:</p>

          <figure>
            <image source="dataviz/img/pnas-table-s1.png"/>
          </figure>

          <p>(Source: Romy van der Lee and Naomi Ellemers, PNAS 2015 112 (40) 12349-12353.)</p>

          <p>We could extract the numbers by hand, but this could lead to human error. Instead, we can try to wrangle the data using R. We start by downloading the pdf document, then importing into R:</p>

          <program language="r">
            <input>
library("pdftools")
temp_file &lt;- tempfile()
url &lt;- paste0("https://web.archive.org/web/20150927033124/",
              "https://www.pnas.org/content/suppl/2015/09/16/",
              "1510159112.DCSupplemental/pnas.201510159SI.pdf")
download.file(url, temp_file, mode = "wb")
txt &lt;- pdf_text(temp_file)
file.remove(temp_file)
            </input>
          </program>

          <note>
            <p>The <c>mode = "wb"</c> argument is only necessary if using Microsoft Windows. On MacOs or Linux the default <c>mode = "w"</c> works. To understand this difference please refer to the <c>download.file</c> help file.</p>
          </note>

          <p>If we examine the object text, we notice that it is a character vector with an entry for each page. So we keep the page we want:</p>

          <program language="r">
            <input>
raw_data_research_funding_rates &lt;- txt[2]
            </input>
          </program>

          <p>The steps above can actually be skipped because we include this raw data in the <alert>dslabs</alert> package as well.</p>

          <p>Examining the object <c>raw_data_research_funding_rates</c> we see that it is a long string and each line on the page, including the table rows, are separated by the symbol for newline: <c>\n</c>. A first step in converting this into a data frame is to store rows separately in a way that will make them easy to access. For this we use the <c>str_split</c> function:</p>

          <program language="r">
            <input>
tab &lt;- str_split(raw_data_research_funding_rates, "\n+")
            </input>
          </program>

          <note>
            <p>On MacOS or Linux you can simply use <c>\n</c> as the separator. Microsoft Windows and macOS (which is based on Unix) use different conventions for line endings in text files and a result <c>raw_data_research_funding_rates</c> has more <c>\n</c> when using Windows.</p>
          </note>

          <p>Because we start off with just one string, we end up with a list with just one entry.</p>

          <program language="r">
            <input>
tab &lt;- tab[[1]]
            </input>
          </program>

          <p>By examining <c>tab</c> we see that the information for the column names is the third and fourth entries:</p>

          <program language="r">
            <input>
the_names_1 &lt;- tab[3]
the_names_2 &lt;- tab[4]
            </input>
          </program>

          <p>The first of these rows looks like this:</p>

          <program language="r">
            <input>
cat(substr(the_names_1, 1, options()$width))
cat(substr(the_names_1, options()$width, nchar(the_names_1)))
            </input>
          </program>

          <p>We want to create one vector with one name for each column. Using some of the functions we have just learned, we do this.</p>

          <p>Let's start with <c>the_names_1</c>, shown above. We want to remove the leading space and anything following the comma. We use regex for the latter. Then we can obtain the elements by splitting strings separated by space. We want to split only when there are 2 or more spaces to avoid splitting <c>Success rates</c>. So we use the regex <c>\\s{2,}</c></p>

          <program language="r">
            <input>
the_names_1 &lt;- the_names_1 |&gt;
  str_trim() |&gt;
  str_replace_all(",\\s.", "") |&gt;
  str_split("\\s{2,}", simplify = TRUE)
the_names_1 
            </input>
          </program>

          <p>Now we will look at <c>the_names_2</c>:</p>

          <program language="r">
            <input>
cat(substr(the_names_2, 1, options()$width))
cat(substr(the_names_2, options()$width, nchar(the_names_2)))
            </input>
          </program>

          <p>Here we want to trim the leading space and then split by space as we did for the first line:</p>

          <program language="r">
            <input>
the_names_2 &lt;- the_names_2 |&gt;
  str_trim() |&gt;
  str_split("\\s+", simplify = TRUE)
the_names_2
            </input>
          </program>

          <p>We can then join these to generate one name for each column:</p>

          <program language="r">
            <input>
tmp_names &lt;- paste(rep(the_names_1, each = 3), the_names_2[-1], sep = "_")
the_names &lt;- c(the_names_2[1], tmp_names) |&gt;
  str_to_lower() |&gt;
  str_replace_all("\\s", "_")
the_names
            </input>
          </program>

          <p>Now we are ready to get the actual data. By examining the <c>tab</c> object, we notice that the information is in lines 6 through 14. We can use <c>str_split</c> again to achieve our goal:</p>

          <program language="r">
            <input>
new_research_funding_rates &lt;- tab[6:14] |&gt;
  str_trim() |&gt;
  str_split("\\s{2,}", simplify = TRUE) |&gt;
  data.frame() |&gt;
  setNames(the_names) |&gt;
  mutate(across(-1, parse_number))
new_research_funding_rates |&gt; as_tibble()
            </input>
          </program>

          <p>We can see that the objects are identical:</p>

          <program language="r">
            <input>
identical(research_funding_rates, new_research_funding_rates)
            </input>
          </program>

        </section>

        <section xml:id="sec-recode">
          <title>Renaming levels</title>

          <p>Another common operation involving strings is renaming the levels of  of a categorical variables. Let's say you have really long names for your levels. If you will be displaying them in plots, you might want to use shorter versions of these names. For example, in character vectors with country names, you might want to change "United States of America" to "USA" and "United Kingdom" to UK, and so on.</p>

          <p>Rather than changing each entry, a more efficient approach is to change the levels.</p>

          <p>Here is an example that shows how to rename countries with long names:</p>

          <program language="r">
            <input>
library(dslabs)
            </input>
          </program>

          <p>Suppose we want to show life expectancy time series by country for the Caribbean. If we make this plot</p>

          <program language="r">
            <input>
gapminder |&gt; 
  filter(region == "Caribbean") |&gt;
  ggplot(aes(year, life_expectancy, color = country)) +
  geom_line()
            </input>
          </program>

          <p>we see that the legend takes up much of the plot because we have four countries with names longer than 12 characters. We can rename these levels using the <c>case_when</c> function:</p>

          <program language="r">
            <input>
x &lt;- levels(gapminder$country)
levels(gapminder$country) &lt;- case_when(
  x == "Antigua and Barbuda" ~ "Barbuda",
  x == "Dominican Republic" ~ "DR",
  x == "St. Vincent and the Grenadines" ~ "St. Vincent",
  x == "Trinidad and Tobago" ~ "Trinidad",
  .default = x)
gapminder |&gt; 
  filter(region == "Caribbean") |&gt;
  ggplot(aes(year, life_expectancy, color = country)) +
  geom_line()
            </input>
          </program>

          <p>We can instead use the <c>fct_recode</c> function in the <alert>forcats</alert> package:</p>

          <program language="r">
            <input>
#| eval: false
library(forcats)
gapminder$country &lt;- 
  fct_recode(gapminder$country, 
             "Barbuda" = "Antigua and Barbuda",
             "DR" = "Dominican Republic",
             "St. Vincent" = "St. Vincent and the Grenadines",
             "Trinidad" = "Trinidad and Tobago")
            </input>
          </program>

        </section>

        <section xml:id="sec-string-processing-exercises">
          <title>Exercises</title>

          <ol>
            <li><p>Complete all lessons and exercises in the RegexOne</p></li>
          </ol>

          <p>online interactive tutorial.</p>

          <ol>
            <li><p>In the <c>extdata</c> directory of the <alert>dslabs</alert> package, you will find</p></li>
          </ol>

          <p>a PDF file containing daily mortality data for Puerto Rico from Jan 1, 2015 to May 31, 2018. You can find the file like this:</p>

          <program language="r">
            <input>
fn &lt;- system.file("extdata", "RD-Mortality-Report_2015-18-180531.pdf",
                  package="dslabs")
            </input>
          </program>

          <p>Find and open the file or open it directly from RStudio. On a Mac, you can type:</p>

          <program language="r">
            <input>
system2("open", args = fn)
            </input>
          </program>

          <p>and on Windows, you can type:</p>

          <program language="r">
            <input>
system("cmd.exe", input = paste("start", fn))
            </input>
          </program>

          <p>Which of the following best describes this file:</p>

          <p>a.  It is a table. Extracting the data will be easy. b.  It is a report written in prose. Extracting the data will be impossible. c.  It is a report combining graphs and tables. Extracting the data seems possible. d.  It shows graphs of the data. Extracting the data will be difficult.</p>

          <ol>
            <li><p>We are going to create a tidy dataset with each row representing one</p></li>
          </ol>

          <p>observation. The variables in this dataset will be year, month, day, and deaths. Start by installing and loading the <alert>pdftools</alert> package:</p>

          <program language="r">
            <input>
install.packages("pdftools")
library(pdftools)
            </input>
          </program>

          <p>Now read-in <c>fn</c> using the <c>pdf_text</c> function and store the results in an object called <c>txt</c>. Which of the following best describes what you see in <c>txt</c>?</p>

          <p>a.  A table with the mortality data. b.  A character string of length 12. Each entry represents the text in each page. The mortality data is in there somewhere. c.  A character string with one entry containing all the information in the PDF file. d.  An html document.</p>

          <ol>
            <li><p>Extract the ninth page of the PDF file from the object <c>txt</c>, then</p></li>
          </ol>

          <p>use the <c>str_split</c> from the <alert>stringr</alert> package so that you have each line in a different entry. Call this string vector <c>s</c>. Then look at the result and choose the one that best describes what you see.</p>

          <p>a.  It is an empty string. b.  I can see the figure shown in page 1. c.  It is a tidy table. d.  I can see the table! But there is a bunch of other stuff we need to get rid of.</p>

          <ol>
            <li><p>What kind of object is <c>s</c> and how many entries does it have?</p></li>
            <li><p>We see that the output is a list with one component. Redefine <c>s</c> to</p></li>
          </ol>

          <p>be the first entry of the list. What kind of object is <c>s</c> and how many entries does it have?</p>

          <ol>
            <li><p>When inspecting the string we obtained above, we see a common</p></li>
          </ol>

          <p>problem: white space before and after the other characters. Trimming is a common first step in string processing. These extra spaces will eventually make splitting the strings hard so we start by removing them. We learned about the command <c>str_trim</c> that removes spaces at the start or end of the strings. Use this function to trim <c>s</c>.</p>

          <ol>
            <li><p>We want to extract the numbers from the strings stored in <c>s</c>.</p></li>
          </ol>

          <p>However, there are many non-numeric characters that will get in the way. We can remove these, but before doing this we want to preserve the string with the column header, which includes the month abbreviation. Use the <c>str_which</c> function to find the rows with a header. Save these results to <c>header_index</c>. Hint: find the first string that matches the pattern <c>2015</c> using the <c>str_which</c> function.</p>

          <ol>
            <li><p>Now we are going to define two objects: <c>month</c> will store the month</p></li>
          </ol>

          <p>and <c>header</c> will store the column names. Identify which row contains the header of the table. Save the content of the row into an object called <c>header</c>, then use <c>str_split</c> to help define the two objects we need. Hints: the separator here is one or more spaces. Also, consider using the <c>simplify</c> argument.</p>

          <ol>
            <li><p>Notice that towards the end of the page you see a <em>totals</em> row</p></li>
          </ol>

          <p>followed by rows with other summary statistics. Create an object called <c>tail_index</c> with the index of the <em>totals</em> entry.</p>

          <ol>
            <li><p>Because our PDF page includes graphs with numbers, some of our rows</p></li>
          </ol>

          <p>have just one number (from the y-axis of the plot). Use the <c>str_count</c> function to create an object <c>n</c> with the number of numbers in each each row. Hint: you can write a regex for number like this <c>\\d+</c>.</p>

          <ol>
            <li><p>We are now ready to remove entries from rows that we know we don't</p></li>
          </ol>

          <p>need. The entry <c>header_index</c> and everything before it should be removed. Entries for which <c>n</c> is 1 should also be removed, and the entry <c>tail_index</c> and everything that comes after it should be removed as well.</p>

          <ol>
            <li><p>Now we are ready to remove all the non-numeric entries. Do this</p></li>
          </ol>

          <p>using regex and the <c>str_remove_all</c> function. Hint: remember that in regex, using the upper case version of a special character usually means the opposite. So <c>\\D</c> means "not a digit". Remember you also want to keep spaces.</p>

          <ol>
            <li><p>To convert the strings into a table, use the <c>str_split_fixed</c></p></li>
          </ol>

          <p>function. Convert <c>s</c> into a data matrix with just the day and death count data. Hints: note that the separator is one or more spaces. Make the argument <c>n</c> a value that limits the number of columns to the values in the 4 columns and the last column captures all the extra stuff. Then keep only the first four columns.</p>

          <ol>
            <li><p>Now you are almost ready to finish. Add column names to the matrix,</p></li>
          </ol>

          <p>including one called <c>day</c>. Also, add a column with the month. Call the resulting object <c>dat</c>. Finally, make sure the day is an integer not a character. Hint: use only the first five columns.</p>

          <ol>
            <li><p>Now finish it up by tidying <c>tab</c> with the <c>pivot_longer</c></p></li>
          </ol>

          <p>function.</p>

          <ol>
            <li><p>Make a plot of deaths versus day with color to denote year. Exclude</p></li>
            <li><p>Now that we have wrangled this data step-by-step, put it all</p></li>
          </ol>

          <p>together in one R chunk, using the pipe as much as possible. Hint: first define the indexes, then write one line of code that does all the string processing.</p>

          <ol>
            <li><p>Advanced: let's return to the MLB Payroll example from the web</p></li>
          </ol>

          <p>scraping section. Use what you have learned in the web scraping and string processing chapters to extract the payroll for the New York Yankees, Boston Red Sox, and Oakland A's and plot them as a function of time.</p>

        </section>
        
      </chapter>

      <chapter xml:id="ch-text-analysis">
        <title>Text analysis</title>
        
          <p>With the exception of labels used to represent categorical data, we have focused on numerical data. But in many applications, data starts as text. Well-known examples are spam filtering, cyber-crime prevention, counter-terrorism and sentiment analysis. In all these cases, the raw data is composed of free form text. Our task is to extract insights from these data. In this section, we learn how to generate useful numerical summaries from text data to which we can apply some of the powerful data visualization and analysis techniques we have learned.</p>

        <section xml:id="sec-case-study-trump-tweets">
          <title>Case study: Trump tweets</title>

          <p>During the 2016 US presidential election, then candidate Donald J. Trump used his twitter account as a way to communicate with potential voters. On August 6, 2016, Todd Vaziri tweeted about Trump that "Every non-hyperbolic tweet is from iPhone (his staff). Every hyperbolic tweet is from Android (from him)." David Robinson conducted an analysis to determine if data supported this assertion. Here, we go through David's analysis to learn some of the basics of text analysis. To learn more about text analysis in R, we recommend the Text Mining with R book by Julia Silge and David Robinson.</p>

          <program language="r">
            <input>
set.seed(2002)
            </input>
          </program>

          <p>We will use the following libraries:</p>

          <program language="r">
            <input>
library(tidyverse)
library(scales)
library(tidytext)
library(textdata)
library(dslabs)
            </input>
          </program>

          <p>X, formerly known as twitter, provides an API that permits downloading tweets. Brendan Brown runs the trump archive, which compiles tweet data from Trump's account. The <alert>dslabs</alert> package includes tweets from the following range:</p>

          <program language="r">
            <input>
range(trump_tweets$created_at)
            </input>
          </program>

          <p>The data frame includes the the following variables:</p>

          <program language="r">
            <input>
names(trump_tweets)
            </input>
          </program>

          <p>The help file <c>?trump_tweets</c> provides details on what each variable represents. The actual tweets are in the <c>text</c> variable:</p>

          <program language="r">
            <input>
trump_tweets$text[16413] |&gt; str_wrap(width = options()$width) |&gt; cat()
            </input>
          </program>

          <p>and the source variable tells us which device was used to compose and upload each tweet:</p>

          <program language="r">
            <input>
trump_tweets |&gt; count(source) |&gt; arrange(desc(n)) |&gt; head(5)
            </input>
          </program>

          <p>We are interested in what happened during the 2016 campaign, so for this analysis we will focus on what was tweeted between the day Trump announced his campaign and election day. We define the following table containing just the tweets from that time period. We remove the <c>Twitter for</c> part of the source, only keep tweets from Android or iPhone, and filter out retweets.</p>

          <program language="r">
            <input>
campaign_tweets &lt;- trump_tweets |&gt; 
  filter(source %in% paste("Twitter for", c("Android", "iPhone")) &amp;
           created_at &gt;= ymd("2015-06-17") &amp; 
           created_at &lt; ymd("2016-11-08")) |&gt;
  mutate(source = str_remove(source, "Twitter for ")) |&gt;
  filter(!is_retweet) |&gt;
  arrange(created_at) |&gt; 
  as_tibble()
            </input>
          </program>

          <p>We can now use data visualization to explore the possibility that two different groups were tweeting from these devices. For each tweet, we will extract the hour, Eastern Standard Time (EST), it was tweeted and then compute the proportion of tweets tweeted at each hour for each device:</p>

          <program language="r">
            <input>
campaign_tweets |&gt;
  mutate(hour = hour(with_tz(created_at, "EST"))) |&gt;
  count(source, hour) |&gt;
  group_by(source) |&gt;
  mutate(percent = n / sum(n)) |&gt;
  ungroup() |&gt;
  ggplot(aes(hour, percent, color = source)) +
  geom_line() +
  geom_point() +
  scale_y_continuous(labels = percent_format()) +
  labs(x = "Hour of day (EST)", y = "% of tweets", color = "")
            </input>
          </program>

          <p>We notice a big peak for the Android in the early hours of the morning, between 6 and 8 AM. There seems to be a clear difference in these patterns. We will therefore assume that two different entities are using these two devices.</p>

          <p>We will now study how the text of the tweets differ when we compare Android to iPhone. To do this, we introduce the <alert>tidytext</alert> package.</p>

        </section>

        <section xml:id="sec-text-as-data">
          <title>Text as data</title>

          <p>The <alert>tidytext</alert> package helps us convert free form text into a tidy table. Having the data in this format greatly facilitates data visualization and the use of statistical techniques.</p>

          <p>The main function needed to achieve this is <c>unnest_tokens</c>. A <em>token</em> refers to a unit that we are considering to be a data point. The most common <em>token</em> will be words, but they can also be single characters, n-grams, sentences, lines, or a pattern defined by a regex. The function will take a vector of strings and extract the tokens so that each one gets a row in the new table. Here is a simple example:</p>

          <program language="r">
            <input>
poem &lt;- c("Roses are red,", "Violets are blue,", 
          "Sugar is sweet,", "And so are you.")
example &lt;- tibble(line = c(1, 2, 3, 4),
                      text = poem)
example
example |&gt; unnest_tokens(word, text)
            </input>
          </program>

          <p>Now let's look at Trump's tweets. We will look at tweet number 3008 because it will later permit us to illustrate a couple of points:</p>

          <program language="r">
            <input>
i &lt;- 3008
campaign_tweets$text[i] |&gt; str_wrap(width = 65) |&gt; cat()
campaign_tweets[i,] |&gt; 
  unnest_tokens(word, text) |&gt;
  pull(word) 
            </input>
          </program>

          <p>Note that the function tries to convert tokens into words. A minor adjustment is to remove the links to pictures:</p>

          <program language="r">
            <input>
links_to_pics &lt;- "https://t.co/[A-Za-z\\d]+|&amp;amp;"
campaign_tweets[i,] |&gt; 
  mutate(text = str_remove_all(text, links_to_pics))  |&gt;
  unnest_tokens(word, text) |&gt;
  pull(word)
            </input>
          </program>

          <p>Now we are now ready to extract the words from all our tweets.</p>

          <program language="r">
            <input>
tweet_words &lt;- campaign_tweets |&gt; 
  mutate(text = str_remove_all(text, links_to_pics))  |&gt;
  unnest_tokens(word, text)
            </input>
          </program>

          <p>And we can now answer questions such as "what are the most commonly used words?":</p>

          <program language="r">
            <input>
tweet_words |&gt; 
  count(word) |&gt;
  arrange(desc(n))
            </input>
          </program>

          <p>It is not surprising that these are the top words, which are not informative. The <em>tidytext</em> package has a database of these commonly used words, referred to as <em>stop words</em>, in text analysis:</p>

          <program language="r">
            <input>
head(stop_words)
            </input>
          </program>

          <p>If we filter out rows representing stop words with <c>filter(!word %in% stop_words$word)</c>:</p>

          <program language="r">
            <input>
tweet_words &lt;- campaign_tweets |&gt; 
  mutate(text = str_remove_all(text, links_to_pics))  |&gt;
  unnest_tokens(word, text) |&gt;
  filter(!word %in% stop_words$word ) 
            </input>
          </program>

          <p>we end up with a much more informative set of top 10 tweeted words:</p>

          <program language="r">
            <input>
tweet_words |&gt; 
  count(word) |&gt;
  slice_max(n, n = 10) |&gt;
  arrange(desc(n))
            </input>
          </program>

          <p>Some exploration of the resulting words (not shown here) reveals a couple of unwanted characteristics in our tokens. First, some of our tokens are just numbers (years, for example). We want to remove these and we can find them using the regex <c>^\d+$</c>. Second, some of our tokens come from a quote and they start with <c>'</c>. We want to remove the <c>'</c> when it is at the start of a word so we will just <c>str_replace</c>. We add these two lines to the code above to generate our final table:</p>

          <program language="r">
            <input>
tweet_words &lt;- campaign_tweets |&gt; 
  mutate(text = str_remove_all(text, links_to_pics))  |&gt;
  unnest_tokens(word, text) |&gt;
  filter(!word %in% stop_words$word &amp;
           !str_detect(word, "^\\d+$")) |&gt;
  mutate(word = str_replace(word, "^'", ""))
            </input>
          </program>

          <p>Now that we have all our words in a table, along with information about what device was used to compose the tweet they came from, we can start exploring which words are more common when comparing Android to iPhone.</p>

          <p>For each word, we want to know if it is more likely to come from an Android tweet or an iPhone tweet. We therefore compute, for each word, its frequency among words tweeted from Android and iPhone, respectively and then derive the ratio of these proportions (Android proportion divided by iPhone proportion). Because some words are infrequent, we apply the continuity correction described in <xref ref="sec-log-transform"/>:</p>

          <program language="r">
            <input>
android_vs_iphone &lt;- tweet_words |&gt;
  count(word, source) |&gt;
  pivot_wider(names_from = "source", values_from = "n", values_fill = 0) |&gt;
  mutate(p_a = (Android + 0.5)/(sum(Android) + 0.5), 
         p_i = (iPhone + 0.5)/(sum(iPhone) + 0.5),  
         ratio = p_a / p_i)
            </input>
          </program>

          <p>For words appearing at least 100 times in total, here are the highest percent differences for Android</p>

          <program language="r">
            <input>
android_vs_iphone |&gt; filter(Android + iPhone &gt;= 100) |&gt; arrange(desc(ratio))
            </input>
          </program>

          <p>and the top for iPhone:</p>

          <program language="r">
            <input>
android_vs_iphone |&gt; filter(Android + iPhone &gt;= 100) |&gt;  arrange(ratio)
            </input>
          </program>

          <p>We already see somewhat of a pattern in the types of words that are being tweeted more from one device versus the other. However, we are not interested in specific words but rather in the tone. Vaziri's assertion is that the Android tweets are more hyperbolic. So how can we check this with data? <em>Hyperbolic</em> is a hard sentiment to extract from words as it relies on interpreting phrases. However, words can be associated to more basic sentiment such as anger, fear, joy, and surprise. In the next section, we demonstrate basic sentiment analysis.</p>

        </section>

        <section xml:id="sec-sentiment-analysis">
          <title>Sentiment analysis</title>

          <p>In sentiment analysis, we assign a word to one or more "sentiments". Although this approach will miss context-dependent sentiments, such as sarcasm, when performed on large numbers of words, summaries can provide insights.</p>

          <p>The first step in sentiment analysis is to assign a sentiment to each word. As we demonstrate, the <alert>tidytext</alert> package includes several maps or lexicons. The <alert>textdata</alert> package includes several of these lexicons.</p>

          <p>The <c>bing</c> lexicon divides words into <c>positive</c> and <c>negative</c> sentiments. We can see this using the <em>tidytext</em> function <c>get_sentiments</c>:</p>

          <program language="r">
            <input>
get_sentiments("bing")
            </input>
          </program>

          <p>The <c>AFINN</c> lexicon assigns a score between -5 and 5, with -5 the most negative and 5 the most positive. Note that this lexicon needs to be downloaded the first time you call the function <c>get_sentiment</c>:</p>

          <program language="r">
            <input>
get_sentiments("afinn")
            </input>
          </program>

          <p>The <c>nrc</c> lexicon provide several different sentiments. Note that this also has to be downloaded the first time you use it.</p>

          <program language="r">
            <input>
get_sentiments("nrc") |&gt; count(sentiment)
            </input>
          </program>

          <p>For our analysis, we are interested in exploring the different sentiments of each tweet so we will use the <c>nrc</c> lexicon:</p>

          <program language="r">
            <input>
nrc &lt;- get_sentiments("nrc") |&gt; select(word, sentiment)
            </input>
          </program>

          <p>We can combine the words and sentiments using <c>inner_join</c>, which will only keep words associated with a sentiment. Here are 5 random words extracted from the tweets:</p>

          <program language="r">
            <input>
tweet_words |&gt; inner_join(nrc, by = "word", relationship = "many-to-many") |&gt; 
  select(source, word, sentiment) |&gt; 
  sample_n(5)
            </input>
          </program>

          <note>
            <p><c>relationship = "many-to-many"</c> is added to address a warning that arises from <c>left_join</c> detecting an "unexpected many-to-many relationship". However, this behavior is actually expected in this context because many words have multiple sentiments associated with them.</p>
          </note>

          <p>Now we are ready to perform a quantitative analysis comparing Android and iPhone by comparing the sentiments of the tweets posted from each device. Here we could perform a tweet-by-tweet analysis, assigning a sentiment to each tweet. However, this will be challenging since each tweet will have several sentiments attached to it, one for each word appearing in the lexicon. For illustrative purposes, we will perform a much simpler analysis: we will count and compare the frequencies of each sentiment appearing in each device.</p>

          <program language="r">
            <input>
sentiment_counts &lt;- tweet_words |&gt;
  left_join(nrc, by = "word", relationship = "many-to-many") |&gt;
  count(source, sentiment) |&gt;
  pivot_wider(names_from = "source", values_from = "n") |&gt;
  mutate(sentiment = replace_na(sentiment, replace = "none"))
            </input>
          </program>

          <p>For each sentiment, we calculate its proportion relative to the total responses for  Android and iPhone, respectively, and derive the ratio of these proportions (Android proportion divided by iPhone proportion).</p>

          <program language="r">
            <input>
sentiment_counts &lt;- sentiment_counts |&gt;
  mutate(p_a = Android/sum(Android), p_i = iPhone/sum(iPhone), ratio = p_a/p_i) |&gt; 
  arrange(desc(ratio))
sentiment_counts
            </input>
          </program>

          <p>So we do see some differences and the order is interesting: the largest three sentiments are disgust, anger, and negative!</p>

          <p>If we are interested in exploring which specific words are driving these differences, we can refer back to our <c>android_vs_iphone</c> object. For each sentiment we show the 10 largest ratios, in either direction. We exclude words appearing less than 10 times total.</p>

          <program language="r">
            <input>
ordered_levels &lt;- sentiment_counts$sentiment

android_vs_iphone |&gt;
  filter(Android + iPhone &gt;= 10) |&gt;
  inner_join(nrc, by = "word") |&gt;
  mutate(sentiment = factor(sentiment, levels = sentiment_counts$sentiment)) |&gt;
  group_by(sentiment) |&gt;
  slice_max(abs(log(ratio)), n = 10) |&gt;
  ungroup() |&gt; 
  mutate(word = reorder(word, -ratio)) |&gt;
  ggplot(aes(word, ratio, fill = ratio &lt; 1)) +
  geom_col(show.legend = FALSE) +
  scale_y_log10() +
  facet_wrap(~sentiment, scales = "free_x", nrow = 2) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) 
            </input>
          </program>

          <p>This is just a simple example of the many analyses one can perform with tidytext. To learn more, we again recommend the Tidy Text Mining book.</p>

        </section>

        <section xml:id="sec-text-analysis-exercises">
          <title>Exercises</title>

          <p>Project Gutenberg is a digital archive of public domain books. The R package <alert>gutenbergr</alert> facilitates the importation of these texts into R.</p>

          <p>You can install and load by typing:</p>

          <program language="r">
            <input>
install.packages("gutenbergr")
library(gutenbergr)
            </input>
          </program>

          <p>You can see the books that are available like this:</p>

          <program language="r">
            <input>
gutenberg_metadata
            </input>
          </program>

          <ol>
            <li><p>Use <c>str_detect</c> to find the ID of the novel <em>Pride and Prejudice</em>.</p></li>
            <li><p>We notice that there are several versions. The <c>gutenberg_works()</c> function filters this table to remove replicates and include only English language works. Read the help file and use this function to find the ID for <em>Pride and Prejudice</em>.</p></li>
            <li><p>Use the <c>gutenberg_download</c> function to download the text for Pride and Prejudice. Save it to an object called <c>book</c>.</p></li>
            <li><p>Use the <alert>tidytext</alert> package to create a tidy table with all the words in the text. Save the table in an object called <c>words</c></p></li>
            <li><p>We will later make a plot of sentiment versus location in the book. For this, it will be useful to add a column with the word number to the table.</p></li>
            <li><p>Remove the stop words and numbers from the <c>words</c> object. Hint: use the <c>anti_join</c>.</p></li>
            <li><p>Now use the <c>AFINN</c> lexicon to assign a sentiment value to each word.</p></li>
            <li><p>Make a plot of sentiment score versus location in the book and add a smoother.</p></li>
            <li><p>Assume there are 300 words per page. Convert the locations to pages and then compute the average sentiment in each page. Plot that average score by page. Add a smoother that appears to go through data.</p></li>
          </ol>

        </section>
        
      </chapter>

    </part>

    <!-- Part 4: Productivity Tools -->
    <part xml:id="part-productivity-tools">
      <title>Productivity Tools</title>

      <chapter xml:id="ch-organizing-with-unix">
        <title>Organizing with Unix</title>
        
                <p>Unix is the operating system of choice in data science. We will introduce you to the Unix way of thinking using an example: how to keep a data analysis project organized. We will learn some of the most commonly used commands along the way. However, we won't go into advanced details. We highly encourage you to learn more, especially when you find yourself using the mouse or performing a repetitive task often. In those cases, there is probably a more efficient way to do it in Unix. Here are some basic courses to get you started:</p>

                <p>-   "Learn the Command Line" through Codecademy -   "LinuxFoundationX: Introduction to Linux" through edX -   "The Unix Workbench" through Coursera</p>

                <p>There are many reference books as well. Bite Size Linux and Bite Size Command Line are two particularly clear, succinct, and complete examples.</p>

                <p>When searching for Unix resources, keep in mind that other terms used to describe what we will learn here are <em>Linux</em>, <em>the shell</em>, and <em>the command line</em>. Basically, what we are learning is a series of commands and a way of thinking that facilitates the organization of files without using the mouse.</p>

                <p>To serve as motivation, we are going to start constructing a directory using Unix tools and RStudio.</p>

              <section xml:id="sec-naming-convention">
                <title>Naming convention</title>

                <p>Before you start organizing projects with Unix you want to pick a name convention that you will use to systematically name your files and directories. This will help you find files and know what is in them.</p>

                <p>In general you want to name your files in a way that is related to their contents and specifies how they relate to other files. The Smithsonian Data Management Best Practices has "five precepts of file naming and organization" and they are:</p>

                <blockquote>
                  <p>-   Have a distinctive, human-readable name that gives an indication of the content.</p>
                </blockquote>

                <blockquote>
                  <p>-   Follow a consistent pattern that is machine-friendly.</p>
                </blockquote>

                <blockquote>
                  <p>-   Organize files into directories (when necessary) that follow a consistent pattern.</p>
                </blockquote>

                <blockquote>
                  <p>-   Avoid repetition of semantic elements among file and directory names.</p>
                </blockquote>

                <blockquote>
                  <p>-   Have a file extension that matches the file format (no changing extensions!)</p>
                </blockquote>

                <p>For specific recommendations we highly recommend you follow The Tidyverse Style Guide.</p>

              </section>

              <section xml:id="sec-the-terminal">
                <title>The terminal</title>

                <p>Instead of clicking, dragging, and dropping to organize our files and folders, we will be typing Unix commands into the terminal. The way we do this is similar to how we type commands into the R console, but instead of generating plots and statistical summaries, we will be organizing files on our system.</p>

                <p>The terminal is integrated into Mac and Linux systems, but Windows users will have to install an <em>emulator</em>. Once you have a terminal open, you can start typing commands. You should see a blinking cursor at the spot where what you type will show up. This position is called the <em>command line</em>. Once you type something and hit enter on Windows or return on the Mac, Unix will try to execute this command. If you want to try out an example, type this command:</p>

                <program language="r">
                  <input>
      echo "hello world"
                  </input>
                </program>

                <p>The command <c>echo</c> is similar to <c>cat</c> in R. Executing this line should print out <c>hello world</c>, then return back to the command line.</p>

                <p>Notice that you can't use the mouse to move around in the terminal. You have to use the keyboard. To go back to a command you previously typed, you can use the up arrow.</p>

                <p>Note that above we included a chunk of code showing Unix commands in the same way we have previously shown R commands. We will make sure to distinguish when the command is meant for R and when it is meant for Unix.</p>

              </section>

              <section xml:id="sec-filesystem">
                <title>The filesystem</title>

                <p>We refer to all the files, folders, and programs on your computer as <em>the filesystem</em>. Keep in mind that folders and programs are also files, but this is a technicality we rarely think about and ignore in this book. We will focus on files and folders for now and discuss programs, or <em>executables</em>, in a later section.</p>

                <subsection xml:id="subsec-directories-and-subdirectories">
                  <title>Directories and subdirectories</title>

                  <p>The first concept you need to grasp to become a Unix user is how your filesystem is organized. You should think of it as a series of nested folders, each containing files, folders, and executables.</p>

                  <p>Here is a visual representation of the structure we are describing:</p>

                  <figure>
                    <image source="dataviz/img/unix/filesystem.png"/>
                  </figure>

                  <p>In Unix, we refer to folders as <em>directories</em>. Directories that are inside other directories are often referred to as <em>subdirectories</em>. So, for example, in the figure above, the directory <em>docs</em> has two subdirectories: <em>reports</em> and <em>resumes</em>, and <em>docs</em> is a subdirectory of <em>home</em>.</p>

                </subsection>

                <subsection xml:id="subsec-the-home-directory">
                  <title>The home directory</title>

                  <p>The <em>home</em> directory is where all your stuff is kept, as opposed to the system files that come with your computer, which are kept elsewhere. In the figure above, the directory called <em>home</em> represents your home directory, but that is rarely the name used. On your system, the name of your home directory is likely the same as your username on that system. Below are an example on Windows and Mac showing a home directory, in this case, named <em>rafa</em>:</p>

                  <figure>
                    <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_53_13.png"/>
                  </figure>

                  <figure>
                    <image source="dataviz/img/mac-screenshots/Screen-Shot-2018-04-13-at-4.34.01-PM.png"/>
                  </figure>

                  <p>Now, look back at the figure showing a filesystem. Suppose you are using a point-and-click system and you want to remove the file <em>cv.tex</em>. Imagine that on your screen you can see the <em>home</em> directory. To erase this file, you would double click on the <em>home</em> directory, then <em>docs</em>, then <em>resumes</em>, and then drag <em>cv.tex</em> to the trash. Here you are experiencing the hierarchical nature of the system: <em>cv.tex</em> is a file inside the <em>resumes</em> directory, which is a subdirectory inside the <em>docs</em> directory, which is a subdirectory of the <em>home</em> directory.</p>

                  <p>Now suppose you can't see your home directory on your screen. You would somehow need to make it appear on your screen. One way to do this is to navigate from what is called the <em>root</em> directory all the way to your home directory. Any filesystem will have what is called a <em>root</em> directory, which is the directory that contains all directories. The <em>home</em> directory shown in the figure above will usually be two or more levels from the root. On Windows, you will have a structure like this:</p>

                  <figure>
                    <image source="dataviz/img/unix/windows-filesystem-from-root.png"/>
                  </figure>

                  <p>while on the Mac, it will be like this:</p>

                  <figure>
                    <image source="dataviz/img/unix/mac-filesystem-from-root.png"/>
                  </figure>

                  <p>On Windows, the typical R installation will make your <em>Documents</em> directory your home directory in R. This will likely be different from your home directory in Git Bash. Generally, when we discuss home directories, we refer to the Unix home directory which for Windows, in this book, is the Git Bash Unix directory.</p>

                </subsection>

                <subsection xml:id="sec-working-directory">
                  <title>Working directory</title>

                  <p>The concept of a <em>current location</em> is part of the point-and-click experience: at any given moment we are <em>in a folder</em> and see the content of that folder. As you search for a file, as we did above, you are experiencing the concept of a current location: once you double click on a directory, you change locations and are now <em>in that folder</em>, as opposed to the folder you were in before.</p>

                  <p>In Unix, we don't have the same visual cues, but the concept of a <em>current location</em> is indispensable. We refer to this as the <em>working directory</em>. Each terminal window you have open has a working directory associated with it.</p>

                  <p>How do we know what is our working directory? To answer this, we learn our next Unix command: <c>pwd</c>, which stands for <em>print working directory</em>. This command returns the working directory.</p>

                  <p>Open a terminal and type:</p>

                  <program language="r">
                    <input>
      pwd
                    </input>
                  </program>

                  <p>We do not show the result of running this command because it will be quite different on your system compared to others. If you open a terminal and type <c>pwd</c> as your first command, you should see something like <c>/Users/yourusername</c> on a Mac or something like <c>/c/Users/yourusername</c> on Windows. The character string returned by calling <c>pwd</c> represents your working directory. When we first open a terminal, it will start in our home directory so in this case the working directory is the home directory.</p>

                  <p>Notice that the forward slashes <c>/</c> in the strings above separate directories. So, for example, the location <c>/c/Users/rafa</c> implies that our working directory is called <c>rafa</c> and it is a subdirectory of <c>Users</c>, which is a subdirectory of <c>c</c>, which is a subdirectory of the root directory. The root directory is therefore represented by just a forward slash: <c>/</c>.</p>

                </subsection>

                <subsection xml:id="sec-paths">
                  <title>Paths</title>

                  <p>We refer to the string returned by <c>pwd</c> as the <em>full path</em> of the working directory. The name comes from the fact that this string spells out the <em>path</em> you need to follow to get to the directory in question from the root directory. Every directory has a full path. Later, we will about <em>relative paths</em>, which tell us how to get to a directory from the working directory.</p>

                  <p>In Unix, we use the shorthand <c>~</c> as a nickname for your home directory. So, for example, if <c>docs</c> is a directory in your home directory, the full path for <em>docs</em> can be written like this <c>~/docs</c>.</p>

                  <p>Most terminals will show the path to your working directory right on the command line. If you are using default settings and open a terminal on the Mac, you will see that right at the command line you have something like <c>computername:~ username</c> with <c>~</c> representing your working directory, which in this example is the home directory <c>~</c>. The same is true for the Git Bash terminal where you will see something like <c>username@computername MINGW64 ~</c>, with the working directory at the end. When we change directories, we will see this change on both Macs and Windows.</p>

                </subsection>

              </section>

              <section xml:id="sec-unix-commands">
                <title>Unix commands</title>

                <p>We will now learn a series of Unix commands that will permit us to prepare a directory for a data science project. We also provide examples of commands that, if you type into your terminal, will return an error. This is because we are assuming the filesystem in the earlier diagram. Your filesystem is different. In the next section, we will provide examples that you can type in.</p>

                <subsection xml:id="subsec-ls-listing-directory-content">
                  <title>`ls`: Listing directory content</title>

                  <p>In a point-and-click system, we know what is in a directory because we see it. In the terminal, we do not see the icons. Instead, we use the command <c>ls</c> to list the directory content.</p>

                  <p>To see the content of your home directory, open a terminal and type:</p>

                  <program language="r">
                    <input>
      ls
                    </input>
                  </program>

                  <p>We will see more examples soon.</p>

                </subsection>

                <subsection xml:id="subsec-mkdir-and-rmdir-make-and-remove-a-directory">
                  <title>`mkdir` and `rmdir`: make and remove a directory</title>

                  <p>When we are preparing for a data science project, we will need to create directories. In Unix, we can do this with the command <c>mkdir</c>, which stands for <em>make directory</em>.</p>

                  <p>Because you will soon be working on several projects, we highly recommend creating a directory called <em>projects</em> in your home directory.</p>

                  <p>You can try this particular example on your system. Open a terminal and type:</p>

                  <program language="r">
                    <input>
      mkdir projects
                    </input>
                  </program>

                  <p>If you do this correctly, nothing will happen: no news is good news. If the directory already exists, you will get an error message and the existing directory will remain untouched.</p>

                  <p>To confirm that you created the directory, you can list the contents of the current working directory:</p>

                  <program language="r">
                    <input>
      ls
                    </input>
                  </program>

                  <p>You should see the directory we just created listed. Perhaps you can also see many other directories that were already on your computer.</p>

                  <p>For illustrative purposes, let's make a few more directories. You can list more than one directory name like this:</p>

                  <program language="r">
                    <input>
      mkdir docs teaching
                    </input>
                  </program>

                  <p>You can check to see if the three directories were created:</p>

                  <program language="r">
                    <input>
      ls
                    </input>
                  </program>

                  <p>If you made a mistake and need to remove the directory, you can use the command <c>rmdir</c> to remove it.</p>

                  <program language="r">
                    <input>
      mkdir junk
      rmdir junk
                    </input>
                  </program>

                  <p>This will remove the directory as long as it is empty. If it is not empty, you will get an error message and the directory will remain untouched. To remove directories that are not empty, we will learn about the command <c>rm</c> later.</p>

                </subsection>

                <subsection xml:id="subsec-cd-navigating-the-filesystem-by-changing-directories">
                  <title>`cd`: navigating the filesystem by changing directories</title>

                  <p>Next we want to create directories inside directories that we have already created. We also want to avoid pointing and clicking our way through the filesystem. We explain how to do this in Unix, using the command line.</p>

                  <p>Suppose we open a terminal and our working directory is our home directory. We want to change our working directory to <c>projects</c>. We do this using the <c>cd</c> command, which stands for <em>change directory</em>:</p>

                  <program language="r">
                    <input>
      cd projects
                    </input>
                  </program>

                  <p>To check that the working directory changed, we can use a command we previously learned to see our location:</p>

                  <program language="r">
                    <input>
      pwd
                    </input>
                  </program>

                  <p>Our working directory should now be <c>~/projects</c>. Note that on your computer the home directory <c>~</c> will be spelled out to something like <c>/c/Users/yourusername</c>.</p>

                  <p>In Unix you can auto-complete by hitting tab. This means that we can type <c>cd d</c> then hit tab. Unix will either auto-complete if <c>docs</c> is the only directory/file starting with <c>d</c> or show you the options. Try it out! Using Unix without auto-complete can make it unbearable.</p>

                  <p>When using <c>cd</c>, we can either type a full path, which will start with <c>/</c> or <c>~</c>, or a <em>relative path</em>. In the example above, in which we typed <c>cd projects</c>, we used a relative path. If the path you type does not start with <c>/</c> or <c>~</c>, Unix will assume you are typing a relative path, meaning that it will look for the directory in your current working directory. So something like this will give you an error:</p>

                  <program language="r">
                    <input>
      cd Users
                    </input>
                  </program>

                  <p>because there is no <c>Users</c> directory in your working directory.</p>

                  <p>Now suppose we want to move back to the directory in which <c>projects</c> is a subdirectory, referred to as the <em>parent directory</em>. We could use the full path of the parent directory, but Unix provides a shortcut for this: the parent directory of the working directory is represented with two dots: <c>..</c> so to move back we simply type:</p>

                  <program language="r">
                    <input>
      cd ..
                    </input>
                  </program>

                  <p>You should now be back in your home directory which you can confirm using <c>pwd</c>.</p>

                  <p>Because we can use full paths with <c>cd</c>, the following command:</p>

                  <program language="r">
                    <input>
      cd ~
                    </input>
                  </program>

                  <p>will always take us back to the home directory, no matter where we are in the filesystem.</p>

                  <p>The working directory also has a nickname, which is a single <c>.</c> so if you type</p>

                  <program language="r">
                    <input>
      cd .
                    </input>
                  </program>

                  <p>you will not move. Although this particular use of <c>.</c> is not useful, this nickname does come in handy sometimes. The reasons are not relevant for this section, but you should still be aware of this fact.</p>

                  <p>In summary, we have learned that when using <c>cd</c> we either stay put, move to a new directory using the desired directory name, or move back to the parent directory using <c>..</c>.</p>

                  <p>When typing directory names, we can concatenate directories with the forward-slashes. So if we want a command that takes us to the <c>projects</c> directory no matter where we are in the filesystem, we can type:</p>

                  <program language="r">
                    <input>
      cd ~/projects
                    </input>
                  </program>

                  <p>which is equivalent to writing the entire path out. For example, in Windows we would write something like</p>

                  <program language="r">
                    <input>
      cd /c/Users/yourusername/projects
                    </input>
                  </program>

                  <p>The last two commands are equivalent and in both cases we are typing the full path.</p>

                  <p>We can also concatenate directory names for relative paths. For instance, if we want to move back to the parent directory of the parent directory of the working directory, we can type:</p>

                  <program language="r">
                    <input>
      cd ../..
                    </input>
                  </program>

                  <p>Here are a couple of final tips related to the <c>cd</c> command. First, you can go back to whatever directory you just left by typing:</p>

                  <program language="r">
                    <input>
      cd -
                    </input>
                  </program>

                  <p>This can be useful if you type a very long path and then realize you want to go back to where you were, and that too has a very long path.</p>

                  <p>Second, if you just type:</p>

                  <program language="r">
                    <input>
      cd
                    </input>
                  </program>

                  <p>you will be returned to your home directory.</p>

                </subsection>

                <subsection xml:id="subsec-examples">
                  <title>Examples</title>

                  <p>Let's explore some examples of using <c>cd</c>. To help visualize, we will show the graphical representation of our filesystem vertically:</p>

                  <figure>
                    <image source="dataviz/img/unix/filesystem-vertical.png"/>
                  </figure>

                  <p>Suppose our working directory is <c>~/projects</c> and we want to move to <c>figs</c> in <c>project-1</c>.</p>

                  <p>Here it is convenient to use relative paths:</p>

                  <program language="r">
                    <input>
      cd project-1/figs
                    </input>
                  </program>

                  <p>Now suppose our working directory is <c>~/projects</c> and we want to move to <c>reports</c> in <c>docs</c>, how can we do this?</p>

                  <p>One way is to use relative paths:</p>

                  <program language="r">
                    <input>
      cd ../docs/reports
                    </input>
                  </program>

                  <p>Another is to use the full path:</p>

                  <program language="r">
                    <input>
      cd ~/docs/reports
                    </input>
                  </program>

                  <p>If you are trying this out on your system, remember to use auto-complete.</p>

                  <p>Let's examine one more example. Suppose we are in <c>~/projects/project-1/figs</c> and want to change to <c>~/projects/project-2</c>. Again, there are two ways.</p>

                  <p>With relative paths:</p>

                  <program language="r">
                    <input>
      cd ../../project-2
                    </input>
                  </program>

                  <p>and with full paths:</p>

                  <program language="r">
                    <input>
      cd ~/projects/project-2
                    </input>
                  </program>

                </subsection>

              </section>

              <section xml:id="sec-more-unix-commands">
                <title>More Unix commands</title>

                <subsection xml:id="subsec-mv-moving-files">
                  <title>`mv`: moving files</title>

                  <p>In a point-and-click system, we move files from one directory to another by dragging and dropping. In Unix, we use the <c>mv</c> command.</p>

                  <p><c>mv</c> will not ask "are you sure?" if your move results in overwriting a file.</p>

                  <p>Now that you know how to use full and relative paths, using <c>mv</c> is relatively straightforward. The general form is:</p>

                  <program language="r">
                    <input>
      mv path-to-file path-to-destination-directory
                    </input>
                  </program>

                  <p>For example, if we want to move the file <c>cv.tex</c> from <c>resumes</c> to <c>reports</c>, you could use the full paths like this:</p>

                  <program language="r">
                    <input>
      mv ~/docs/resumes/cv.tex ~/docs/reports/
                    </input>
                  </program>

                  <p>You can also use relative paths. You could do this:</p>

                  <program language="r">
                    <input>
      cd ~/docs/resumes
      mv cv.tex ../reports/
                    </input>
                  </program>

                  <p>or this:</p>

                  <program language="r">
                    <input>
      cd ~/docs/reports/
      mv ../resumes/cv.tex ./
                    </input>
                  </program>

                  <p>Notice that in the last one we used the working directory shortcut <c>.</c> to give a relative path as the destination directory.</p>

                  <p>We can also use <c>mv</c> to change the name of a file. To do this, instead of the second argument being the destination directory, it also includes a filename. So, for example, to change the name from <c>cv.tex</c> to <c>resume.tex</c>, we simply type:</p>

                  <program language="r">
                    <input>
      cd ~/docs/resumes
      mv cv.tex resume.tex
                    </input>
                  </program>

                  <p>We can also combine the move and a rename. For example:</p>

                  <program language="r">
                    <input>
      cd ~/docs/resumes
      mv cv.tex ../reports/resume.tex
                    </input>
                  </program>

                  <p>And we can move entire directories. To move the <c>resumes</c> directory into <c>reports</c>, we do as follows:</p>

                  <program language="r">
                    <input>
      mv ~/docs/resumes ~/docs/reports/
                    </input>
                  </program>

                  <p>It is important to add the last <c>/</c> to make it clear you do not want to rename the <c>resumes</c> directory to <c>reports</c>, but rather move it into the <c>reports</c> directory.</p>

                </subsection>

                <subsection xml:id="subsec-cp-copying-files">
                  <title>`cp`: copying files</title>

                  <p>The command <c>cp</c> behaves similar to <c>mv</c> except instead of moving, we copy the file, meaning that the original file stays untouched.</p>

                  <p>So in all the <c>mv</c> examples above, you can switch <c>mv</c> to <c>cp</c> and they will copy instead of move with one exception: we can't copy entire directories without learning about arguments, which we do later.</p>

                </subsection>

                <subsection xml:id="subsec-rm-removing-files">
                  <title>`rm`: removing files</title>

                  <p>In point-and-click systems, we remove files by dragging and dropping them into the trash or using a special click on the mouse. In Unix, we use the <c>rm</c> command.</p>

                  <p>Unlike throwing files into the trash, <c>rm</c> is permanent. Be careful!</p>

                  <p>The general way it works is as follows:</p>

                  <program language="r">
                    <input>
      rm filename
                    </input>
                  </program>

                  <p>You can actually list files as well like this:</p>

                  <program language="r">
                    <input>
      rm filename-1 filename-2 filename-3
                    </input>
                  </program>

                  <p>You can use full or relative paths. To remove non-empty directories, you will have to learn about arguments, which we do later.</p>

                </subsection>

                <subsection xml:id="subsec-less-looking-at-a-file">
                  <title>`less`: looking at a file</title>

                  <p>Often you want to quickly look at the content of a file. If this file is a text file, the quickest way to do is by using the command <c>less</c>. To look a the file <c>cv.tex</c>, you do this:</p>

                  <program language="r">
                    <input>
      cd ~/docs/resumes
      less cv.tex 
                    </input>
                  </program>

                  <p>To exit the viewer, you type <c>q</c>. If the files are long, you can use the arrow keys to move up and down. There are many other keyboard commands you can use within <c>less</c> to, for example, search or jump pages.</p>

                  <p>If you are wondering why the command is called <c>less</c>, it is because the original was called <c>more</c>, as in "show me more of this file". The second version was called <c>less</c> because of the saying "less is more".</p>

                </subsection>

              </section>

              <section xml:id="sec-prep-project">
                <title>Case study: Preparing for a project</title>

                <p>We are now ready to prepare a directory for a project. We will use the US murders project as an example.</p>

                <p>You should start by creating a directory where you will keep all your projects. We recommend a directory called <em>projects</em> in your home directory. To do this you would type:</p>

                <program language="r">
                  <input>
      cd ~
      mkdir projects
                  </input>
                </program>

                <p>Our project relates to gun violence murders so we will call the directory for our project <c>murders</c>. It will be a subdirectory in our projects directories. In the <c>murders</c> directory, we will create two subdirectories to hold the raw data and intermediate data. We will call these <c>data</c> and <c>rda</c>, respectively.</p>

                <p>Open a terminal and make sure you are in the home directory:</p>

                <program language="r">
                  <input>
      cd ~
                  </input>
                </program>

                <p>Now run the following commands to create the directory structure we want. At the end, we use <c>ls</c> and <c>pwd</c> to confirm we have generated the correct directories in the correct working directory:</p>

                <program language="r">
                  <input>
      cd projects
      mkdir murders
      cd murders
      mkdir data rdas 
      ls
      pwd
                  </input>
                </program>

                <p>Note that the full path of our <c>murders</c> dataset is <c>~/projects/murders</c>.</p>

                <p>So if we open a new terminal and want to navigate into that directory we type:</p>

                <program language="r">
                  <input>
      cd projects/murders
                  </input>
                </program>

                <p>In <xref ref="sec-organizing"/> we will describe how we can use RStudio to organize a data analysis project, once these directories have been created.</p>

              </section>

              <section xml:id="sec-advanced-unix">
                <title>Advanced Unix</title>

                <p>Most Unix implementations include a large number of powerful tools and utilities. We have just learned the very basics here. We recommend that you use Unix as your main file management tool. It will take time to become comfortable with it, but as you struggle, you will find yourself learning just by looking up solutions on the internet. In this section, we superficially cover slightly more advanced topics. The main purpose of the section is to make you aware of what is available rather than explain everything in detail.</p>

                <subsection xml:id="subsec-arguments">
                  <title>Arguments</title>

                  <p>Most Unix commands can be run with arguments. Arguments are typically defined by using a dash <c>-</c> or two dashes <c>--</c> (depending on the command) followed by a letter or a word. An example of an argument is the <c>-r</c> behind <c>rm</c>. The <c>r</c> stands for recursive, and the result is that files and directories are removed recursively, which means that if you type:</p>

                  <program language="r">
                    <input>
      rm -r directory-name
                    </input>
                  </program>

                  <p>all files, subdirectories, files in subdirectories, subdirectories in subdirectories, and so on, will be removed. This is equivalent to throwing a folder in the trash, except you can't recover it. Once you remove it, it is deleted for good. Often, when you are removing directories, you will encounter files that are protected. In such cases, you can use the argument <c>-f</c> which stands for <c>force</c>.</p>

                  <p>You can also combine arguments. For instance, to remove a directory regardless of protected files, you type:</p>

                  <program language="r">
                    <input>
      rm -rf directory-name
                    </input>
                  </program>

                  <p>Remember that once you remove there is no going back, so use this command very carefully.</p>

                  <p>A command that is often called with argument is <c>ls</c>. Here are some examples:</p>

                  <program language="r">
                    <input>
      ls -a 
                    </input>
                  </program>

                  <p>The <c>a</c> stands for all. This argument makes <c>ls</c> show you all files in the directory, including hidden files. In Unix, all files starting with a <c>.</c> are hidden. Many applications create hidden directories to store important information without getting in the way of your work. An example is <c>git</c>. Once you initialize a directory as a git directory with <c>git init</c>, a hidden directory called <c>.git</c> is created. Another hidden file is the <c>.gitignore</c> file.</p>

                  <p>Another example of using an argument is:</p>

                  <program language="r">
                    <input>
      ls -l 
                    </input>
                  </program>

                  <p>The <c>l</c> stands for long and the result is that more information about the files is shown.</p>

                  <p>It is often useful to see files in chronological order. For that we use:</p>

                  <program language="r">
                    <input>
      ls -t 
                    </input>
                  </program>

                  <p>and to reverse the order of how files are shown you can use:</p>

                  <program language="r">
                    <input>
      ls -r 
                    </input>
                  </program>

                  <p>We can combine all these arguments to show more information for all files in reverse chronological order:</p>

                  <program language="r">
                    <input>
      ls -lart 
                    </input>
                  </program>

                  <p>Each command has a different set of arguments. In the next section, we learn how to find out what they each do.</p>

                </subsection>

                <subsection xml:id="subsec-getting-help">
                  <title>Getting help</title>

                  <p>As you may have noticed, Unix uses an extreme version of abbreviations. This makes it very efficient, but hard to guess how to call commands. To make up for this weakness, Unix includes complete help files or <em>man pages</em> (man is short for manual). In most systems, you can type <c>man</c> followed by the command name to get help. So for <c>ls</c>, we would type:</p>

                  <program language="r">
                    <input>
      man ls
                    </input>
                  </program>

                  <p>This command is not available in some of the compact implementations of Unix, such as Git Bash. An alternative way to get help that works on Git Bash is to type the command followed by <c>--help</c>. So for <c>ls</c>, it would be as follows:</p>

                  <program language="r">
                    <input>
      ls --help
                    </input>
                  </program>

                </subsection>

                <subsection xml:id="subsec-pipes">
                  <title>Pipes</title>

                  <p>The help pages are typically long and if you type the commands above to see the help, it scrolls all the way to the end. It would be useful if we could save the help to a file and then use <c>less</c> to see it. The <c>pipe</c>, written like this <c>|</c>, does something similar. It <em>pipes</em> the results of a command to the command after the <c>pipe</c>. This is similar to the pipe <c>|&gt;</c> that we use in R. To get more help we thus can type:</p>

                  <program language="r">
                    <input>
      man ls | less
                    </input>
                  </program>

                  <p>or in Git Bash:</p>

                  <program language="r">
                    <input>
      ls --help | less 
                    </input>
                  </program>

                  <p>This is also useful when listing files with many files. We can type:</p>

                  <program language="r">
                    <input>
      ls -lart | less 
                    </input>
                  </program>

                </subsection>

                <subsection xml:id="subsec-wild-cards">
                  <title>Wild cards</title>

                  <p>Some of the most powerful aspects of Unix are the <em>wild cards</em>. Suppose we want to remove all the temporary html files produced while trouble shooting for a project. Imagine there are dozens of files. It would be quite painful to remove them one by one. In Unix, we can actually write an expression that means all the files that end in <c>.html</c>. To do this we type <em>wild card</em>: <c>*</c>. As discussed in the data wrangling part of this book, this character means any number of any combination of characters. Specifically, to list all html files, we would type:</p>

                  <program language="r">
                    <input>
      ls *.html
                    </input>
                  </program>

                  <p>To remove all html files in a directory, we would type:</p>

                  <program language="r">
                    <input>
      rm *.html
                    </input>
                  </program>

                  <p>The other useful wild card is the <c>?</c> symbol. This means any single character. So if all the files we want to erase have the form <c>file-001.html</c> with the numbers going from 1 to 999, we can type:</p>

                  <program language="r">
                    <input>
      rm file-???.html
                    </input>
                  </program>

                  <p>This will only remove files with that format.</p>

                  <p>We can combine wild cards. For example, to remove all files with the form <c>file-001</c> up to <c>file-999</c> regardless of suffix, we can type:</p>

                  <program language="r">
                    <input>
      rm file-???.* 
                    </input>
                  </program>

                  <p>Combining rm with the <c>*</c> wild card can be dangerous. There are combinations of these commands that will erase your entire filesystem without asking "are you sure?". So make sure you understand how it works before using this wild card with the <c>rm</c> command. We recommend always checking what files will match the wild card first by using the <c>ls</c> command.</p>

                </subsection>

                <subsection xml:id="subsec-environment-variables">
                  <title>Environment variables</title>

                  <p>Unix has settings that affect your command line <em>environment</em>. These are called environment variables. The home directory is one of them. We can actually change some of these. In Unix, variables are distinguished from other entities by adding a <c>$</c> in front. The home directory is stored in <c>$HOME</c>.</p>

                  <p>Earlier we saw that <c>echo</c> is the Unix command for print. So we can see our home directory by typing:</p>

                  <program language="r">
                    <input>
      echo $HOME 
                    </input>
                  </program>

                  <p>You can see them all by typing:</p>

                  <program language="r">
                    <input>
      env
                    </input>
                  </program>

                  <p>You can change some of these environment variables. But their names vary across different <em>shells</em>. We describe shells in the next section.</p>

                </subsection>

                <subsection xml:id="subsec-shells">
                  <title>Shells</title>

                  <p>Much of what we use in this chapter is part of what is called the <em>Unix shell</em>. There are actually different shells, but the differences are almost unnoticeable. They are also important, although we do not cover those here. You can see what shell you are using by typing:</p>

                  <program language="r">
                    <input>
      echo $SHELL
                    </input>
                  </program>

                  <p>The most common one is <c>bash</c>.</p>

                  <p>Once you know the shell, you can change environmental variables. In Bash Shell, we do it using <c>export variable value</c>. To change the path, described in more detail soon, you would type:</p>

                  <program language="r">
                    <input>
      export PATH = /usr/bin/
                    </input>
                  </program>

                  <p>Don't actually run this command though!</p>

                  <p>There is a program that is run before each terminal starts where you can edit variables so they change whenever you call the terminal. This changes in different implementations, but if using bash, you can create a file called <c>.bashrc</c>, <c>.bash_profile</c>,<c>.bash_login</c>, or <c>.profile</c>. You might already have one.</p>

                </subsection>

                <subsection xml:id="subsec-executables">
                  <title>Executables</title>

                  <p>In Unix, all programs are files. They are called executables. So <c>ls</c>, <c>mv</c> and <c>git</c> are all files. But where are these program files? You can find out using the command <c>which</c>:</p>

                  <program language="bash">
                    <input>
      which git
                    </input>
                  </program>

                  <p>That directory is probably full of program files. The directory <c>/usr/bin</c> usually holds many program files. If you type:</p>

                  <program language="r">
                    <input>
      ls /usr/bin
                    </input>
                  </program>

                  <p>in your terminal, you will see several executable files.</p>

                  <p>There are other directories that usually hold program files. The Application directory in the Mac or Program Files directory in Windows are examples.</p>

                  <p>When you type <c>ls</c>, Unix knows to run a program which is an executable that is stored in some other directory. So how does Unix know where to find it? This information is included in the environmental variable <c>$PATH</c>. If you type:</p>

                  <program language="r">
                    <input>
      echo $PATH
                    </input>
                  </program>

                  <p>you will see a list of directories separated by <c>:</c>. The directory <c>/usr/bin</c> is probably one of the first ones on the list.</p>

                  <p>Unix looks for program files in those directories in that order. Although we don't teach it here, you can actually create executables yourself. However, if you put it in your working directory and this directory is not on the path, you can't run it just by typing the command. You get around this by typing the full path. So if your command is called my-ls, you can type:</p>

                  <program language="r">
                    <input>
      ./my-ls
                    </input>
                  </program>

                  <p>Once you have mastered the basics of Unix, you should consider learning to write your own executables as they can help alleviate repetitive work.</p>

                </subsection>

                <subsection xml:id="subsec-permissions-and-file-types">
                  <title>Permissions and file types</title>

                  <p>If you type:</p>

                  <program language="r">
                    <input>
      ls -l
                    </input>
                  </program>

                  <p>At the beginning, you will see a series of symbols like this <c>-rw-r--r--</c>. This string indicates the type of file: regular file <c>-</c>, directory <c>d</c>, or executable <c>x</c>. This string also indicates the permission of the file: is it readable? writable? executable? Can other users on the system read the file? Can other users on the system edit the file? Can other users execute if the file is executable? This is more advanced than what we cover here, but you can learn much more in a Unix reference book.</p>

                </subsection>

                <subsection xml:id="subsec-commands-you-should-learn">
                  <title>Commands you should learn</title>

                  <p>There are many commands that we do not teach in this book, but we want to make you aware of them and what they do. They are:</p>

                  <p>-   open/start - On the Mac, <c>open filename</c> tries to figure out the right application of the filename and open it with that application. This is a very useful command. On Git Bash, you can try <c>start filename</c>. Try opening an <c>R</c> or <c>Rmd</c> file with <c>open</c> or <c>start</c>: it should open them with RStudio.</p>

                  <p>-   nano - Opens a bare-bones text editor.</p>

                  <p>-   tar - Archives files and subdirectories of a directory into one file.</p>

                  <p>-   ssh - Connects to another computer.</p>

                  <p>-   find - Finds files by filename on your system.</p>

                  <p>-   grep - Searches for patterns in a file.</p>

                  <p>-   awk/sed - These are two very powerful commands that permit you to find specific strings in files and change them.</p>

                  <p>-   ln - Creates a symbolic link. We do not recommend its use, but you should be familiar with it.</p>

                </subsection>

                <subsection xml:id="subsec-file-manipulation-in-r">
                  <title>File manipulation in R</title>

                  <p>We can also perform file management from within R. The key functions to learn about can be seen by looking at the help file for <c>?files</c>. Another useful function is <c>unlink</c>.</p>

                  <p>Although not generally recommended, you can run Unix commands in R using <c>system</c>.</p>

                  <program language="r">
                    <input>
      knitr::opts_chunk$set(out.width = NULL, out.extra = NULL)
                    </input>
                  </program>

                </subsection>

              </section>
      
      </chapter>

      <chapter xml:id="ch-git-and-github">
        <title>Git and GitHub</title>
        
                <p>Here we provide a brief introduction Git and GitHub. We are only scratching the surface. To learn more about Git, we highly recommend the following resources:</p>

                <ul>
                  <li>"Learn Git &amp; GitHub" on Codecademy</li>
                  <li>"Hello World" exercises GitHub Guides</li>
                </ul>

                <p>If you plan to use Git and Github frequently in conjunction with R, we highly recommend reading Happy Git and GitHub for the useR to learn about the details we don't cover here.</p>

              <section xml:id="sec-why-use-git-and-github">
                <title>Why use Git and GitHub?</title>

                <p>Three primary reasons to use Git and GitHub are:</p>

                <ol>
                  <li><p><alert>Version Control:</alert> Git allows you to track changes in your code, revert to previous file versions, and work on multiple branches simultaneously. Once changes are finalized, different branches can be merged.</p></li>
                  <li><p><alert>Collaboration:</alert> GitHub offers a central storage solution for projects and lets you add collaborators. These collaborators can make changes, keeping all versions synchronized. Moreover, the <em>pull request</em> feature on GitHub enables others to suggest modifications to your code, which you can then approve or reject.</p></li>
                  <li><p><alert>Sharing:</alert> Beyond its powerful version control and collaboration tools, Git and GitHub serve as a platform to easily share your code with others.</p></li>
                </ol>

                <p>We primarily emphasize the sharing capabilities here. For a deeper dive into its other functionality, please refer to the provided resources above. One major advantage of hosting code on GitHub is the ease with which you can showcase it to potential employers seeking samples of your work. Given that numerous companies and organizations employ version control systems like Git for project collaboration, they may find it commendable that you possess some knowledge of the tool.</p>

              </section>

              <section xml:id="sec-git-overview">
                <title>Overview of Git</title>

                <p>To effectively permit version control and collaboration with Git we need to understand the concept of a <em>repository</em>, often simply called a <em>repo</em>. A repo is a digital storage space where you can save, edit, and track versions of files for a specific project. Think of it as a project folder combined with a detailed logbook. It holds all the files and directories related to the project and also records of every change made, who made it, and when. This allows multiple people to collaborate on a project without overwriting contributions from others. You can also easily revert to previous versions if needed.</p>

                <p>Note that Git permits the creation of different <em>branches</em> within a repository. This permits working on files in parallel which is particularly useful for testing ideas that involve big changes before incorporating with a stable version. In this book we provide only examples with just one branch. To learn more about how to define and use multiple branches please consult the resources provided above.</p>

                <p>A common practice involves hosting central <em>main branch</em>  on a GitHub repository that all collaborators can access remotely. The main branch is considered the stable official version. Each collaborator also maintains a <em>local repository</em> on their computer, allowing them to edit and test changes before committing them to the main repository.</p>

                <p>We're going to explore how Git works by following these step:</p>

                <ol>
                  <li><p>First, you'll learn how to make changes on your computer in what's called the <em>working directory</em>. </p></li>
                  <li><p>From there, you'll save these changes to your <em>local repo</em>, this is like your personal save point on your computer and will generate a new version of the repository in the log.</p></li>
                  <li><p>After saving locally, you'll then send, or <em>push</em>, these changes to the main storage space where everyone can see them. In our examples, this main storage space is hosted on GitHub, and Git calls it the <em>upstream repo</em>.</p></li>
                <figure>
                  <image source="dataviz/img/git/git-layout.png"/>
                </figure>

                </ol>

                <p>Now, to work with this strategy, you'll need an account on GitHub. In the next two sections, we'll guide you on how to set up an account and create repos on GitHub.</p>

              </section>

              <section xml:id="sec-github-accounts">
                <title>GitHub accounts</title>

                <p>Basic GitHub accounts are free. To create one, go to GitHub where you will see a box in which you can sign up.</p>

                <p>You want to pick a name carefully. It should be short, easy to remember and to spell, somehow related to your name, and professional. This last one is important since you might be sending potential employers a link to your GitHub account. Your initials and last name are usually a good choice.</p>

              </section>

              <section xml:id="sec-github-repos">
                <title>GitHub repositories</title>

                <p>Once you have an account, you are now ready to create a GitHub repository that will serve as the main or upstream repo for a project. Collaborators you add to this project will be able to manage a local repository on their computer and push changes. Git will help you keep all the different copies synced.</p>

                <p>To create a repo, first log in to your account by clicking the <em>Sign In</em> button on GitHub. You might already be signed in, in which case the <em>Sign In</em> button will not show up. If signing in, you will have to enter your username and password. We recommend you set up your browser to remember this to avoid typing it in each time.</p>

                <p>Once on your account, you can click on <em>Repositories</em> and then click on <em>New</em> to create a new repo. You will be prompted for a name:</p>

                <figure>
                  <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_23_40.png"/>
                </figure>

                <figure>
                  <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_23_42.png"/>
                </figure>

                <p>When naming your project, pick a descriptive name that clearly tells what the project is about. Keep in mind that as you work on more projects, you'll accumulate many repositories. As an illustration, we will use the name <c>homework-0</c>.</p>

                <p>You will also be prompted to decide whether your repo should be public or private. To decide, know that this is the difference:</p>

                <p>- <alert>Public repositories</alert>: Anyone on the internet can see these. Only collaborators can make changes.</p>

                <p>- <alert>Private repositories</alert>: Only people you grant access to can view them.</p>

                <p>While there are other settings to consider, we typically stick with the default options provided by GitHub.</p>

                <p>After creating your repo, GitHub will show you steps to link your local repo (the one on your computer) to the new one you've set up on GitHub. They'll provide some code that you can directly copy and paste into your terminal. We will break down that code so you'll know exactly what each command does.</p>

              </section>

              <section xml:id="sec-connecting-git-github">
                <title>Connecting Git and GitHub</title>

                <p>When accessing GitHub you need credentials to verify your identity. There are two ways to connect: HTTPS or SSH, each requiring different credentials. We recommend using HTTPS, which uses a Personal Access Token (PAT). Note that <alert>your GitHub website password isn't your access token</alert>.</p>

                <p>GitHub provides a detailed guide on obtaining an access token which can be found by searching "Managing your personal access tokens" on the GitHub Docs website. To generate a token:</p>

                <ol>
                  <li><p>Carefully follow the instructions provided by GitHub.</p></li>
                  <li><p>When setting permissions for the token, choose <em>non-expiring</em> and select the <em>repo</em> option in the <em>scopes</em> section.</p></li>
                </ol>

                <p>Once you complete these steps, GitHub will display your token—a lengthy string of characters. You should then:</p>

                <ol>
                  <li><p>Immediately copy this token to your clipboard. Remember, this is the only time GitHub will show it to you.</p></li>
                  <li><p>For security, save this token in a password manager. This ensures you can access it if needed later on.</p></li>
                </ol>

                <p>In some of the procedures outlined below, you'll be prompted to enter your password. Instead, paste the token you've copied. After this, password prompts should no longer appear. If you ever need the token again, retrieve it from your password manager.</p>

                <p>For a much more detailed explanation, including how to use SSH instead of HTTPS, please consult Happy Git and GitHub for the useR.</p>

                <p>The next step is to let Git know who we are. This will make it easier to connect with GitHub. To to this type the following two commands in our terminal window:</p>

                <program language="r">
                  <input>
      git config --global user.name "Your Name"
      git config --global user.email "your@email.com"
                  </input>
                </program>

                <p>This will change the Git configuration in way that anytime you use Git, it will know this information. Note that <alert>you need to use the email account that you used to open your GitHub account</alert>.</p>

              </section>

              <section xml:id="sec-init">
                <title>Initial setup</title>

                <p>In a terminal, move to the directory you want to store the local repository. We recommend naming the directory the same as the GitHub repo. In our example we would use:</p>

                <program language="r">
                  <input>
      mkdir homework-0
      cd homework-0
                  </input>
                </program>

                <p>We then initialize the directory as a Git repository, starting the version control process.</p>

                <program language="r">
                  <input>
      git init
                  </input>
                </program>

                <note>
                  <p>## main verus master</p>
                  <p>GitHub now uses <c>main</c> as the default branch name. In the past, both Git and GitHub used <c>master</c> as the default. As a result, many older repositories or older versions of Git might still use <c>master</c> as their primary branch.</p>
                  <p>To ensure your local branch aligns with the GitHub repository's branch name:</p>
                  <p>1. Visit the GitHub repository page.</p>
                  <p>2. Check the dropdown menu on the left that lists branches. This will display the default branch name.</p>
                  <p>To verify your local branch name, use:</p>
                  <p>```</p>
                  <p>git branch</p>
                  <p>```</p>
                  <p>If you see a branch name other than <c>main</c> but want it to be <c>main</c>, rename it with:</p>
                  <program language="bash">
                    <input>
      git branch -M main
                    </input>
                  </program>
                  <p>The <c>-M</c> stands for move. Note that this is different from changing branches, it is renaming the current branch.</p>
                </note>

                <p>To link your local repository to its counterpart on GitHub, you'll need the GitHub repository's URL. To find this, go to the repository's webpage. Click the green <em>Code</em> button to quickly copy the URL, which in our example is <c>https://github.com/rairizarry/homework-0.git</c>.</p>

                <figure>
                  <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_24_19.png"/>
                </figure>

                <p>Once you have this you can type</p>

                <program language="r">
                  <input>
      git remote add origin https://github.com/rairizarry/homework-0.git
                  </input>
                </program>

                <p>To understand this command note that <c>git remote add</c> adds a new remote reference. A <em>remote</em> in Git refers to another place where your code repository is stored, usually on the internet or another network. <c>origin</c> is the conventional name given to the remote repository or the central repository that other people will treat as an main project source. It's essentially a shorthand alias for the repository's URL. You could technically name it anything you want, but <c>origin</c> is the convention most use. Finally, <c>https://github.com/rairizarry/homework-0.git</c>  is the URL of the remote repository. It tells Git where the repository is hosted. Together, these commands set up a new local Git repository and link it to a remote repository on GitHub.</p>

              </section>

              <section xml:id="sec-git-basics">
                <title>Git basics</title>

                <p>Now that you have initialized a directory to store your local repository, we can learn how to move files from our <em>working directory</em> all the way to the upstream repo.</p>

                <subsection xml:id="subsec-the-working-directory">
                  <title>The working directory</title>

                  <figure>
                    <image source="dataviz/img/git/git-status.png"/>
                  </figure>

                  <p>The working directory is the same as your Unix working directory. In our example, if we create a file in the <c>homework-0</c> directory, it is considered to be in the working directory. Git can tell you how the files in the working directory relate to the versions of the files in other areas with the command</p>

                  <program language="r">
                    <input>
      git status
                    </input>
                  </program>

                  <p>Because we have not done anything yet, you should receive a message such as</p>

                  <program language="r">
                    <input>
      On branch main

      No commits yet

      nothing to commit (create/copy files and use "git add" to track)
                    </input>
                  </program>

                  <p>If we add a file, say <c>code.R</c>, you will see a message like:</p>

                  <program language="r">
                    <input>
      Untracked files:
        (use "git add &lt;file&gt;..." to include in what will be committed)
      	code.R
                    </input>
                  </program>

                </subsection>

                <subsection xml:id="subsec-add">
                  <title>add</title>

                  <figure>
                    <image source="dataviz/img/git/git-add.png"/>
                  </figure>

                  <p>Now we are going to make changes to these files. Eventually, we want these new versions of the files to be tracked and synced with the upstream repo. But we don't want to keep track of every little change: we don't want to sync until we are sure these versions are final enough to share as a new version. For this reason, edits in the staging area are not kept by the version control system.</p>

                  <p>To demonstrate, we add <c>code.R</c> to the staging area:</p>

                  <program language="r">
                    <input>
      git add code.R
                    </input>
                  </program>

                  <p>Running <c>git status</c> now shows</p>

                  <program language="r">
                    <input>
      Changes to be committed:
        (use "git rm --cached &lt;file&gt;..." to unstage)
      	new file:   code.R
                    </input>
                  </program>

                  <p>Note that it is not a problem to have other files in the working directory that are not in the staging area. For example, if we create files <c>test-1.R</c> and <c>test-2.R</c>, <c>git status</c> reminds us these are not staged:</p>

                  <program language="r">
                    <input>
      On branch main

      No commits yet

      Changes to be committed:
        (use "git rm --cached &lt;file&gt;..." to unstage)
      	new file:   code.R

      Untracked files:
        (use "git add &lt;file&gt;..." to include in what will be committed)
      	test-1.R
      	test-2.R
                    </input>
                  </program>

                </subsection>

                <subsection xml:id="subsec-commit">
                  <title>commit</title>

                  <figure>
                    <image source="dataviz/img/git/git-commit.png"/>
                  </figure>

                  <p>If we are now ready to make a first version of our repository, which only includes <c>code.R</c>, we can use the following command:</p>

                  <program language="r">
                    <input>
      git commit -m "Adding a new file." 
                    </input>
                  </program>

                  <p>Note that <c>commit</c> requires us to add a message. Making these informative will help us remember why this change was made. After running <c>commit</c> we will receive a message letting us know it was committed:</p>

                  <program language="r">
                    <input>
      [main (root-commit) 1735c25] adding a new file
       1 file changed, 0 insertions(+), 0 deletions(-)
       create mode 100644 code.R
                    </input>
                  </program>

                  <p>Note that  if we edit <c>code.R</c>, it changes only in the working directory. <c>git status</c> shows us</p>

                  <program language="r">
                    <input>
      Changes not staged for commit:
       (use "git add &lt;file&gt;..." to update what will be committed)
        (use "git restore &lt;file&gt;..." to discard changes in working directory)
      	modified:   code.R
                    </input>
                  </program>

                  <p>To add the edited file to the local repo, we need to stage the edited file and commit the changes</p>

                  <program language="r">
                    <input>
      git add code.R
      git commit -m "Added some lines of code."
                    </input>
                  </program>

                  <p>which gives us a message letting us know a change was made:</p>

                  <program language="r">
                    <input>
      [main 8843673] added some lines of code
       1 file changed, 1 insertion(+)
                    </input>
                  </program>

                  <p>Note that we can achieve the same results with just one line by following the commit command with the files we want committed:</p>

                  <program language="r">
                    <input>
      git commit -m "Added some lines of code." code.R
                    </input>
                  </program>

                  <p>This is convenient when the number of files that change is small and we can list them at the end.</p>

                  <p>To see version control in action note what happens when we type</p>

                  <program language="r">
                    <input>
      git log code.R
                    </input>
                  </program>

                  <p>we get a list of the version that have been stored in our log:</p>

                  <program language="r">
                    <input>
      commit 88436739dcbd57d8ad27a23663d30fd2c06034ca (HEAD -&gt; main)
      Author: Rafael A Irizarry 
      Date:   Sun Sep 3 15:32:03 2023 -0400

          Added some lines of code.

      commit 1735c25c675d23790df1f9cdb3a215a13c8ae5d6
      Author: Rafael A Irizarry 
      Date:   Sun Sep 3 15:27:19 2023 -0400

          Adding a new file.
                    </input>
                  </program>

                </subsection>

                <subsection xml:id="subsec-push">
                  <title>push</title>

                  <figure>
                    <image source="dataviz/img/git/git-push.png"/>
                  </figure>

                  <p>Once we are ready to sync our local repo with the upstream GitHub repo, we can use</p>

                  <program language="r">
                    <input>
      git push -u origin main
                    </input>
                  </program>

                  <note>
                    <p>If this is your first time pushing to your GitHub account, you will be asked for a password and you have to enter the personal access token we described in <xref ref="sec-connecting-git-github"/>. You should only need to do this once.</p>
                  </note>

                  <p>The <c>-u</c> flag, short for <c>--set-upstream</c> will make Git remember that in this repository you want to push to the <c>main</c> branch in the remote repo <c>origin</c> defined in the initialization. This is beneficial because the next time you want to push or pull from this branch, you can simply use</p>

                  <program language="r">
                    <input>
      git push
                    </input>
                  </program>

                  <p>If you need a reminder of where you are pushing to you can type</p>

                  <program language="r">
                    <input>
      git remote -v
                    </input>
                  </program>

                  <p>The <c>v</c> stands for <c>verbose</c>. In our example we will get</p>

                  <program language="r">
                    <input>
      origin  https://github.com/username/homework-0.git (fetch)
      origin  https://github.com/username/homework-0.git (push)
                    </input>
                  </program>

                  <p>We describe <c>fetch</c> next. If you don't get anything back it means you have not defined your remote as we did in <xref ref="sec-init"/>.</p>

                </subsection>

                <subsection xml:id="subsec-fetch-and-merge">
                  <title>fetch and merge</title>

                  <figure>
                    <image source="dataviz/img/git/git-fetch.png"/>
                  </figure>

                  <figure>
                    <image source="dataviz/img/git/git-merge.png"/>
                  </figure>

                  <p>If this is a collaborative project, the upstream repo may change and become different than your version. To update your local repository to be like the upstream repo, we use the command <c>fetch</c>:</p>

                  <program language="r">
                    <input>
      git fetch
                    </input>
                  </program>

                  <p>And then to make these copies to our working directory, we use the command:</p>

                  <program language="r">
                    <input>
      git merge
                    </input>
                  </program>

                </subsection>

                <subsection xml:id="subsec-git-pull">
                  <title>pull</title>

                  <figure>
                    <image source="dataviz/img/git/git-pull.png"/>
                  </figure>

                  <p>We very often just want to fetch and merge without checking. For this, we use:</p>

                  <program language="r">
                    <input>
      git pull
                    </input>
                  </program>

                </subsection>

                <subsection xml:id="subsec-clone">
                  <title>clone</title>

                  <p>You can easily download all the code and version control logs from an existing public repository using <c>git clone</c>. When you clone you are essentially making a complete copy of the entire directory. For example, you can download all the code used to create this book using:</p>

                  <program language="r">
                    <input>
      git clone https://github.com/rafalab/dsbook-part-1.git
                    </input>
                  </program>

                  <p>You can see a simple example with the murders directory created in the Unix chapter by cloning this repository:</p>

                  <program language="r">
                    <input>
      git clone https://github.com/rairizarry/murders.git
                    </input>
                  </program>

                  <p>If you use <c>git clone</c>, you do not need to initialize as the branch and remote will already be defined. Now, to push changes you need to be added as a collaborator. Otherwise you will have to follow the more complex process of a <em>pull request</em>, which we don't cover here.</p>

                </subsection>

              </section>

              <section xml:id="sec-gitignore">
                <title>.gitignore</title>

                <p>When we use <c>git status</c> we obtain information about all files in our local repo. But we don't necessarily need to add all the files in our working directory to the Git repo, only the ones we want to keep track of or the ones we want to share. If our work is producing files of a certain type that we do not want to keep track of, we can add the suffix that defines these files to the .gitignore file. More details on using .gitignore are included on the git-scm website. These files will stop appearing when you type <c>git status</c>.</p>

              </section>

              <section xml:id="sec-rstudio-git">
                <title>Git in RStudio</title>

                <p>While command line Git is a powerful and flexible tool, it can be somewhat daunting when we are getting started. RStudio provides a graphical interface that facilitates the use of Git in the context of a data analysis project.</p>

                <p>To do this, we start a project but, instead of <em>New Directory</em>, or <em>Existing Directory</em>, we select <em>Version Control</em> and then we will select <em>Git</em> as our version control system:</p>

                <figure>
                  <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_30_35.png"/>
                </figure>

                <figure>
                  <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_30_43.png"/>
                </figure>

                <p>The repository URL is the link you used as <c>origin</c> or to clone. We used <c>https://github.com/username/homework-0.git</c> as an example. In the project directory name, you need to put the name of the folder that was generated, which in our example will be the name of the repo <c>homework-0</c>. This will create a folder called <c>homework-0</c> on your local system. Note you will need to remove the folder if it already exists or chose a different name. Once you do this, the project is created and it is aware of the connection to a GitHub repo. You will see on the top right corner the name and type of project as well as a new tab on the upper right pane titled <em>Git</em>.</p>

                <figure>
                  <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_31_10.png"/>
                </figure>

                <figure>
                  <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_31_11.png"/>
                </figure>

                <p>If you select this tab, it will show you the files in your project, excluding those in <c>.gitignore</c>, with some icons that give you information about these files and their relationship to the repo. In the example below, we already added a file to the folder, called <em>code.R</em> which you can see in the editing pane.</p>

                <figure>
                  <image source="dataviz/img//windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_34_06.png"/>
                </figure>

                <p>We now need to pay attention to the Git pane. It is important to know that <alert>your local files and the GitHub repo will not be synced automatically</alert>. You have to sync using git push when you are ready. We show how you can do this through RStudio rather than the terminal below.</p>

                <p>Before we start working on a collaborative project, usually the first thing we do is <em>pull</em> in the changes from the remote repo, in our case the one on GitHub. However, for the example shown here, since we are starting with an empty repo and we are the only ones making changes, we don't need to start by pulling.</p>

                <p>In RStudio, the status of the file as it relates to the remote and local repos are represented in the status symbols with colors. A yellow square means that Git knows nothing about this file. To sync with the GitHub repo, we need to <em>add</em> the file, then <em>commit</em> the change to our local Git repo, then <em>push</em> the change to the GitHub repo. Right now, the file is just on our computer. To add the file using RStudio, we click the <em>Stage</em> box. You will see that the status icon now changes to a green A.</p>

                <figure>
                  <image source="dataviz/img//windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_51_31.png"/>
                </figure>

                <p>Now we are ready to commit the file to our local repo. In RStudio, we can use the <em>Commit</em> button. This will open a new dialog window. With Git, whenever we commit a change, we are required to enter a message describing the changes being <em>committed</em>.</p>

                <figure>
                  <image source="dataviz/img//windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_51_54.png"/>
                </figure>

                <p>In this case, we will simply describe that we are adding a new script. In this dialog box, RStudio also gives you a summary of what you are changing to the GitHub repo. In this case, because it is a new file, the entire file is highlighted as green, which highlights the changes.</p>

                <p>Once we hit the commit button, we should see a message from Git with a summary of the changes that were committed. Now we are ready to <em>push</em> these changes to the GitHub repo. We can do this by clicking on the <em>Push</em> button on the top right corner:</p>

                <figure>
                  <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_52_05.png"/>
                </figure>

                <figure>
                  <image source="dataviz/img//windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_52_17.png"/>
                </figure>

                <p>We now see a message from Git letting us know that the push has succeeded. In the pop-up window we no longer see the <c>code.R</c> file. This is because no new changes have been performed since we last pushed. We can exit this pop-up window now and continue working on our code.</p>

                <figure>
                  <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_52_35.png"/>
                </figure>

                <figure>
                  <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_52_44.png"/>
                </figure>

                <p>If we now visit our repo on the web, we will see that it matches our local copy.</p>

                <figure>
                  <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_53_09.png"/>
                </figure>

                <p>Congratulations, you have successfully shared code on a GitHub repository!</p>

                <note>
                  <p>For the example shown here, we only added <em>code.R</em>. But, in general, for an RStudio project, we recommend adding a README.md file and both the .gitignore and .Rproj files.</p>
                </note>

              </section>
      
      </chapter>

      <chapter xml:id="ch-reproducible-projects">
        <title>Reproducible projects</title>
        
                <p>The final product of a data analysis project is often a report. Many scientific publications can be thought of as a final report of a data analysis. The same is true for news articles based on data, an analysis report for your company, or lecture notes for a class on how to analyze data. The reports are often on paper or in a PDF that includes a textual description of the findings along with some figures and tables resulting from the analysis.</p>

                <p>Imagine that after you finish the analysis and the report, you are told that you were given the wrong dataset, you are sent a new one and you are asked to run the same analysis. Or what if you realize that a mistake was made and you need to re-examine the code, fix the error, and re-run the analysis? Or imagine that someone you are training wants to see your code and be able to reproduce the results to learn about your approach?</p>

                <p>Situations like the ones just described are actually quite common for a data analyst. Here, we describe how you can keep your projects organized with RStudio so that re-running an analysis is straight-forward. We then demonstrate how to generate reproducible reports with quarto or R markdown. The <alert>knitR</alert> package will greatly help with recreating reports with minimal work. This is possible due to the fact that markdown documents permit code and textual descriptions to be combined into the same document, and the figures and tables produced by the code are automatically added to the document.</p>

                <program language="r">
                  <input>
      img_path &lt;- "productivity/img"
      screenshots &lt;- list.files(file.path(img_path, "windows-screenshots"))
      screenshots &lt;- file.path(img_path, "windows-screenshots", screenshots)
      mac_screenshots &lt;- list.files(file.path(img_path, "mac-screenshots"))
      mac_screenshots &lt;- file.path(img_path,"mac-screenshots", mac_screenshots)
                  </input>
                </program>

              <section xml:id="sec-rstudio-projects">
                <title>RStudio projects</title>

                <p>RStudio provides a way to keep all the components of a data analysis project organized into one folder and to keep track of information about this project, such as the Git status of files, in one place. RStudio facilitates the use of Git and GitHub through RStudio projects. In this section we quickly demonstrate how to start a new a project and some recommendations on how to keep these organized. RStudio projects also permit you to have several RStudio sessions open and keep track of which is which.</p>

                <p>To start a project, click on <em>File</em> and then <em>New Project</em>. Often we have already created a folder to save the work, and we select <em>Existing Directory</em>. Here we show an example in which we have not yet created a folder and select the <em>New Directory</em> option.</p>

                <figure>
                  <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_09_20_21.png"/>
                </figure>

                <figure>
                  <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_09_20_28.png"/>
                </figure>

                <p>Then, for a data analysis project, you usually select the <em>New Project</em> option:</p>

                <figure>
                  <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_09_20_35.png"/>
                </figure>

                <p>Now you will have to decide on the location of the folder that will be associated with your project, as well as the name of the folder. When choosing a folder name, just like with file names, make sure it is a meaningful name that will help you remember what the project is about. As with files, we recommend using lower case letters, no spaces, and hyphens to separate words. We will call the folder for this project <c>my-first-project</c>. This will then generate a <em>Rproj</em> file called <c>my-first-project.Rproj</c> in the folder associated with the project. We will see how this is useful a few lines below.</p>

                <figure>
                  <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_09_21_09.png"/>
                </figure>

                <p>You will be given options on where this folder should be on your filesystem. In this example, we will place it in our home folder, but this is generally not good practice. In the Unix chapter, we discussed organizing your filesystem following a hierarchical approach and with a folder called <em>projects</em> where you keep a folder for each project.</p>

                <figure>
                  <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_09_21_56.png"/>
                </figure>

                <p>When you start using RStudio with a project, you will see the project name in the upper right corner. This will remind you what project this particular RStudio session belongs to. When you open an RStudio session with no project, it will say <em>Project: (None)</em>.</p>

                <p>When working on a project, all files will be saved and searched for in the folder associated with the project. Below, we show an example of a script that we wrote and saved with the name <c>code.R</c>. Because we used a meaningful name for the project, we can be a bit less informative when we name the files. Although we do not do it here, you can have several scripts open at once. You simply need to click <em>File</em>, then <em>New File</em> and pick the type of file you want to edit.</p>

                <figure>
                  <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_09_23_26.png"/>
                </figure>

                <p>One of the main advantages of using Projects is that after closing RStudio, if we wish to continue where we left off on the project, we simply double click or open the file saved when we first created the RStudio project. In this case, the file is called <c>my-first-project.Rproj</c>. If we open this file, RStudio will start up and open the scripts we were editing.</p>

                <figure>
                  <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_09_24_08.png"/>
                </figure>

                <figure>
                  <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_09_24_21.png"/>
                </figure>

                <p>Another advantage is that if you click on two or more different Rproj files, you start new RStudio and R sessions for each.</p>

              </section>

              <section xml:id="sec-markdown">
                <title>Markdown</title>

                <p>Markdown is a format for <em>literate programming</em> documents that is widely used to generate html pages or pdf documents. Literate programming weaves instructions, documentation, and detailed comments in between machine executable code, producing a document that describes the program that is best for human understanding. You can learn more about markdown with online tutorials.</p>

                <p>Unlike a word processor, such as Microsoft Word, where what you see is what you get, with markdown, you need to <em>compile</em> the document into the final report. The markdown document looks different than the final product. This approach seems like a disadvantage at first, but it can save you time in the long run. For example, instead of producing plots and inserting them one by one into the word processing document, the plots are automatically added when the document is compiled. If you need to change the plots, you just recompile the document after editing the code that produces the plot.</p>

                <p>In R, we can produce literate programming documents using Quarto or R markdown. We recommend using Quarto because it is a newer and more flexible version of R markdown that permits the use of languages other than R. Because R markdown preceded Quarto by several years, many public and educational literate programming documents are written in R markdown. However, because the format is similar and both use the <alert>knitr</alert> package to execute the R code (details in <xref ref="sec-knitr"/>), most existing R markdown files can be rendered with Quarto without modification.</p>

                <p>In RStudio, you can start either a Quarto or R markdown document by clicking on <em>File</em>, <em>New File</em>, then <em>Quarto Document</em> or <em>R Markdown</em>, respectively. You will then be asked to enter a title and author for your document. We are going to prepare a report on gun murders so we will give it an appropriate name. You can also decide what format you would like the final report to be in: HTML, PDF, or Microsoft Word. Later, we can easily change this, but here we select html as it is the preferred format for debugging purposes:</p>

                <figure>
                  <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_53_18.png"/>
                </figure>

                <figure>
                  <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_53_19.png"/>
                </figure>

                <p>This will generate a template file:</p>

                <figure>
                  <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_53_20.png"/>
                </figure>

                <p>As a convention, we use <c>qmd</c> and <c>Rmd</c> suffixes for Quarto and R markdown files, respectively.</p>

                <p>Once you gain experience with markdown, you will be able to do this without the template and can simply start from a blank template.</p>

                <p>In the template, you will see several things to note.</p>

                <subsection xml:id="subsec-the-header">
                  <title>The header</title>

                  <p>At the top you see:</p>

                  <program language="r">
                    <input>
      ---
      title: "Report on Gun Murders"
      author: "Rafael Irizarry"
      format: html
      ---
                    </input>
                  </program>

                  <p>The things between the <c>---</c> is the <em>YAML</em> header. YAML is a widely used language mainly used for providing configuration data. With Quarto and R markdown it is mainly used to define options for the document. You can define many other things in the header than what is included in the template. We don't discuss those here, but much information is available from the quarto guide. The one parameter that we will highlight is <c>format</c>. By changing this to, say, <c>pdf</c>, we can control the type of output that is produced when we compile. The title and author parameters are automatically filled because we filled in the blanks in the RStudio dialog box that pops up when creating a new document.</p>

                </subsection>

                <subsection xml:id="subsec-r-code-chunks">
                  <title>R code chunks</title>

                  <p>In various places in the document, we see something like this:</p>

                  <program language="r">
                    <input>
      1 + 1
                    </input>
                  </program>

                  <p>These are the code chunks. When you compile the document, the R code inside the chunk, in this case <c>1+1</c>, will be evaluated and the result included in that position in the final document.</p>

                  <p>To add your own R chunks, you can type the characters above quickly with the key binding command-option-I on the Mac and Ctrl-Alt-I on Windows.</p>

                  <p>This applies to plots as well; the plot will be placed in that position. We can write something like this:</p>

                  <program language="r">
                    <input>
      plot(1)
                    </input>
                  </program>

                  <p>By default, the code will show up as well. To avoid having the code show up, you can use an argument, which are annotated with <c>#|</c> To avoid showing code in the final document, you can use the argument <c>echo: FALSE</c>. For example:</p>

                  <program language="r">
                    <input>
      #| echo: false

      1+1
                    </input>
                  </program>

                  <p>We recommend getting into the habit of adding a label to the R code chunks. This will be very useful when debugging, among other situations. You do this by adding a descriptive word like this:</p>

                  <program language="r">
                    <input>
      #| label: one-plus-one

      1+1
                    </input>
                  </program>

                </subsection>

                <subsection xml:id="subsec-global-execution-options">
                  <title>Global execution options</title>

                  <p>If you want to apply an option globally, you can include in the header, under <c>execute</c>. For example adding the following line to the header make code not show up, by default:</p>

                  <program language="r">
                    <input>
      execute:
        echo: false
                    </input>
                  </program>

                  <p>We will not cover more details here, but as you become more experienced with R Markdown, you will learn the advantages of setting global options for the compilation process.</p>

                </subsection>

                <subsection xml:id="sec-knitr">
                  <title>knitR</title>

                  <p>We use the <alert>knitR</alert> package to compile Quarto or R markdown documents. The specific function used to compile is the <c>knit</c> function, which takes a filename as input. RStudio provides a button that makes it easier to compile the document. For the screenshot below, we have edited the document so that a report on gun murders is produced. You can see the file on GitHub. You can now click on the <c>Render</c> button:</p>

                  <figure>
                    <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_53_21.0.png"/>
                  </figure>

                  <p>Note that the first time you click on the <em>Render</em> button, a dialog box may appear asking you to install packages you need. Once you have installed the packages, clicking <em>Render</em> will compile your Quarto file and the resulting document will pop up.</p>

                  <p>This particular example produces an html document which you can see in your working directory. To view it, open a terminal and list the files. You can open the file in a browser and use this to present your analysis. You can also produce a PDF or Microsoft document by changing: <c>format: html</c> to <c>format: pdf</c> or <c>format: docx</c>. Note this is one difference between Quarto and R markdown. With R markdown we use <c>output: html_document</c>, <c>output: pdf_document</c>, or <c>output: word_document</c>.</p>

                  <p>We can also produce documents that render on GitHub using <c>format: gfm</c>, which stands for GitHub flavored markdown. This will produce a markdown file, with suffix <c>md</c>, that renders nicely on GitHub. Because we have uploaded these files to GitHub, you can click on the <c>md</c> file and you will see the report as a webpage:</p>

                  <figure>
                    <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_53_38.png"/>
                  </figure>

                  <p>This is a convenient way to share your reports.</p>

                </subsection>

                <subsection xml:id="subsec-learning-more">
                  <title>Learning more</title>

                  <p>There is a lot more you can do with R markdown. We highly recommend you continue learning as you gain more experience writing reports in R. There are many free resources on the internet including:</p>

                  <p>-   The Quarto Guide -   Hello, Quarto tutorial -   Dynamic Documents with R and knitr textbook</p>

                </subsection>

              </section>

              <section xml:id="sec-organizing">
                <title>Organizing a data science project</title>

                <p>In this section we put it all together to create the US murders project and share it on GitHub.</p>

                <subsection xml:id="subsec-create-directories-in-unix">
                  <title>Create directories in Unix</title>

                  <p>We demonstrated how to use Unix to prepare for a data science project using an example. Here we continue this example and show how to use RStudio. We created the following directories using Unix:</p>

                  <program language="bash">
                    <input>
      cd ~
      cd projects
      mkdir murders
      cd murders
      mkdir data rdas 
                    </input>
                  </program>

                </subsection>

                <subsection xml:id="subsec-create-an-rstudio-project">
                  <title>Create an RStudio project</title>

                  <p>In the next section we will use create an RStudio project. In RStudio we go to <em>File</em> and then <em>New Project...</em> and when given the options we pick <em>Existing Directory</em>. We then write the full path of the <c>murders</c> directory created above.</p>

                  <figure>
                    <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_53_14.png"/>
                  </figure>

                  <figure>
                    <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_53_15.png"/>
                  </figure>

                  <p>Once you do this, you will see the <c>rdas</c> and <c>data</c> directories you created in the RStudio <em>Files</em> tab.</p>

                  <figure>
                    <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_53_16.png"/>
                  </figure>

                  <p>Keep in mind that when we are in this project, our default working directory will be <c>~/projects/murders</c>. You can confirm this by typing <c>getwd()</c> into your R session. This is important because it will help us organize the code when we need to write file paths.</p>

                  <p>Try to always use relative paths in code for data analysis projects. These should be relative to the default working directory. The problem with using full paths, including using the home directory <c>~</c> as part of your path, is that your code is unlikely to work on file systems other than yours since the directory structures will be different.</p>

                </subsection>

                <subsection xml:id="subsec-editting-r-scripts">
                  <title>Editting R scripts</title>

                  <p>Let's now write a script that downloads a file into the data directory. We will call this file <c>download-data.R</c>.</p>

                  <p>The content of this file will be:</p>

                  <program language="r">
                    <input>
      url &lt;- "https://raw.githubusercontent.com/rafalab/dslabs/master/inst/
      extdata/murders.csv"
      dest_file &lt;- "data/murders.csv"
      download.file(url, destfile = dest_file)
                    </input>
                  </program>

                  <p>Notice that we are using the relative path <c>data/murders.csv</c>.</p>

                  <p>Run this code in R and you will see that a file is added to the <c>data</c> directory.</p>

                  <p>Now we are ready to write a script to read this data and prepare a table that we can use for analysis. Call the file <c>wrangle-data.R</c>. The content of this file will be:</p>

                  <program language="r">
                    <input>
      library(tidyverse)
      murders &lt;- read_csv("data/murders.csv")
      murders &lt;- murders |&gt; mutate(region = factor(region),
                                   rate = total / population * 10^5)
      save(murders, file = "rdas/murders.rda")
                    </input>
                  </program>

                  <p>Again note that we use relative paths exclusively.</p>

                </subsection>

                <subsection xml:id="subsec-saving-processed-data">
                  <title>Saving processed data</title>

                  <p>In this file, we introduce an R command we have not seen: <c>save</c>. The <c>save</c> command in R saves objects into what is called an <em>rda file</em>: <em>rda</em> is short for R data. We recommend using the <c>.rda</c> suffix on files saving R objects. You will see that <c>.RData</c> is also used.</p>

                  <p>If you run this code above, the processed data object will be saved in a file in the <c>rda</c> directory. You can then restore the object using <c>load</c>. Although not the case here, this approach is often practical because generating the data object we use for final analyses and plots can be a complex and time-consuming process. So we run this process once and save the file. But we still want to be able to generate the entire analysis from the raw data.</p>

                  <p>While <c>save</c> let's you save several objects that then get loaded with the same names used when saving, the function <c>saveRDS</c> lets you save one object, without the name. To bring it back you use the <c>readRDS</c> function. An example of how this is used is you save it in one session:</p>

                  <program language="r">
                    <input>
      #| eval: false
      saveRDS(murders, file = "rdas/murders.rda")
                    </input>
                  </program>

                  <p>Then read it in in another session, using whatever object name you want:</p>

                  <program language="r">
                    <input>
      #| eval: false
      dat &lt;- readRDS("rdas/murders.rda")
                    </input>
                  </program>

                </subsection>

                <subsection xml:id="subsec-the-main-analysis-file">
                  <title>The main analysis file</title>

                  <p>Now we are ready to write the analysis file. Let's call it <c>analysis.R</c>. The content should be the following:</p>

                  <program language="r">
                    <input>
      library(tidyverse)
      load("rdas/murders.rda")

      murders |&gt; mutate(abb = reorder(abb, rate)) |&gt;
        ggplot(aes(abb, rate)) +
        geom_bar(width = 0.5, stat = "identity", color = "black") +
        coord_flip()
                    </input>
                  </program>

                  <p>If you run this analysis, you will see that it generates a plot.</p>

                </subsection>

                <subsection xml:id="subsec-other-directories">
                  <title>Other directories</title>

                  <p>Now suppose we want to save the generated plot for use in a report or presentation. We can do this with the <alert>ggplot</alert> command <c>ggsave</c>. But where do we put the graph? We should be systematically organized so we will save plots to a directory called <c>figs</c>. Start by creating a directory by typing the following in the terminal:</p>

                  <program language="bash">
                    <input>
      mkdir figs
                    </input>
                  </program>

                  <p>and then you can add the line:</p>

                  <program language="r">
                    <input>
      ggsave("figs/barplot.png")
                    </input>
                  </program>

                  <p>to your R script. If you run the script now, a png file will be saved into the <c>figs</c> directory. If we wanted to copy that file to some other directory where we are developing a presentation, we can avoid using the mouse by using the <c>cp</c> command in our terminal.</p>

                </subsection>

                <subsection xml:id="subsec-the-readme-file">
                  <title>The README file</title>

                  <p>You now have a self-contained analysis in one directory. One final recommendation is to create a <c>README.txt</c> file describing what each of these files does for the benefit of others reading your code, including your future self. This would not be a script but just some notes. One of the options provided when opening a new file in RStudio is a text file. You can save something like this into the text file:</p>

                  <program language="r">
                    <input>
      We analyze US gun murder data collected by the FBI.

      download-data.R - Downloads csv file to data directory

      wrangle-data.R - Creates a derived dataset and saves as R object in rdas
      directory

      analysis.R - A plot is generated and saved in the figs directory.
                    </input>
                  </program>

                </subsection>

                <subsection xml:id="subsec-initializing-a-git-directory">
                  <title>Initializing a Git directory</title>

                  <p>In <xref ref="sec-init"/> we demonstrated how to initialize a Git directory and connect it to the upstream repository on GitHub, which we already created in that section.</p>

                  <p>We can do this in the Unix terminal:</p>

                  <program language="bash">
                    <input>
      cd ~/projects/murders
      git init
      git add README.txt
      git commit -m "First commit. Adding README.txt file just to get started"
      git remote add origin `https://github.com/rairizarry/murders.git`
      git push -u origin remote
                    </input>
                  </program>

                </subsection>

                <subsection xml:id="subsec-add-commit-and-push-files-using-rstudio">
                  <title>Add, commit, and push files using RStudio</title>

                  <p>We can continue adding and committing each file, but it might be easier to use RStudio. To do this, start the project by opening the Rproj file. The git icons should appear and you can add, commit and push using these.</p>

                  <figure>
                    <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_53_32.png"/>
                  </figure>

                  <figure>
                    <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_53_34.png"/>
                  </figure>

                  <figure>
                    <image source="dataviz/img/windows-screenshots/VirtualBox_Windows-7-Enterprise_23_03_2018_14_53_35.png"/>
                  </figure>

                  <p>We can now go to GitHub and confirm that our files are there. You can see a version of this project, organized with Unix directories, on GitHub. You can download a copy to your computer by using the <c>git clone</c> command on your terminal. This command will create a directory called <c>murders</c> in your working directory, so be careful where you call it from.</p>

                  <program language="r">
                    <input>
      git clone https://github.com/rairizarry/murders.git
                    </input>
                  </program>

                </subsection>

              </section>
      
      </chapter>

    </part>

  </book>

</pretext>
